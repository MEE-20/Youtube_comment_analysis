{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "35d53a224f054e5d952ccbb7da2b2b04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_adba1a34eac64e81b34591746dbe2a4c",
              "IPY_MODEL_72171e8278264a86891af06ccfac8cbb",
              "IPY_MODEL_f57399bb4cf74f6b8f400efac096f2e2"
            ],
            "layout": "IPY_MODEL_cdf1f2ac461147f6a6a3bd25e1cf35d5"
          }
        },
        "adba1a34eac64e81b34591746dbe2a4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_524122b1141d4d218dc49228d335e466",
            "placeholder": "​",
            "style": "IPY_MODEL_c55a6197ddf346489021b9d1db0cda3c",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "72171e8278264a86891af06ccfac8cbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb5b4c01d54c4b968a9759299bd96b45",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ae85408a3dae4452b77c8083e0c8cdcf",
            "value": 48
          }
        },
        "f57399bb4cf74f6b8f400efac096f2e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93b6abcbbe6946659c21dd30fab2b7fa",
            "placeholder": "​",
            "style": "IPY_MODEL_56779223e2664c089f76915a022fcfd5",
            "value": " 48.0/48.0 [00:00&lt;00:00, 5.17kB/s]"
          }
        },
        "cdf1f2ac461147f6a6a3bd25e1cf35d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "524122b1141d4d218dc49228d335e466": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c55a6197ddf346489021b9d1db0cda3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb5b4c01d54c4b968a9759299bd96b45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae85408a3dae4452b77c8083e0c8cdcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "93b6abcbbe6946659c21dd30fab2b7fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56779223e2664c089f76915a022fcfd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42436d0931be40869d209b5fd98d227f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e2789592977e42b19b70e68254a013ed",
              "IPY_MODEL_54fa29c3a9934b98bac22b82e21b4cff",
              "IPY_MODEL_c5d5c786c4474d1eb13c96d6d60ba7fb"
            ],
            "layout": "IPY_MODEL_0a4db4c759234e898089614b7735ae06"
          }
        },
        "e2789592977e42b19b70e68254a013ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d059add83a84ba6ab0631b544ec720e",
            "placeholder": "​",
            "style": "IPY_MODEL_14c8544db7954dcf81ef27e98e58904d",
            "value": "vocab.txt: 100%"
          }
        },
        "54fa29c3a9934b98bac22b82e21b4cff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8c7467d85bf4150b8dccc6663c8af34",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a457b91259ef4d8585404339073a5e9f",
            "value": 231508
          }
        },
        "c5d5c786c4474d1eb13c96d6d60ba7fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1af602b6f2d0437bb17fbe3b0bb1cd4e",
            "placeholder": "​",
            "style": "IPY_MODEL_6edd6d3c8ce34abf9ed60e9e8d105159",
            "value": " 232k/232k [00:00&lt;00:00, 2.59MB/s]"
          }
        },
        "0a4db4c759234e898089614b7735ae06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d059add83a84ba6ab0631b544ec720e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14c8544db7954dcf81ef27e98e58904d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8c7467d85bf4150b8dccc6663c8af34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a457b91259ef4d8585404339073a5e9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1af602b6f2d0437bb17fbe3b0bb1cd4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6edd6d3c8ce34abf9ed60e9e8d105159": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9135956a473e44eba9fc29aa72ba7609": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4cc17942ba4f4d7abe67e96adfa406f0",
              "IPY_MODEL_2be784c08e3443a9b20e073265388abd",
              "IPY_MODEL_3c9726c21f864a95b2eb7ef8ed56e2f4"
            ],
            "layout": "IPY_MODEL_e9b6690cd30a4a12bbbe69f7fb2c90a1"
          }
        },
        "4cc17942ba4f4d7abe67e96adfa406f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a815af9870d64484b08c6cd7d62e9e6e",
            "placeholder": "​",
            "style": "IPY_MODEL_76400cf2088e49cd8006840e1088bf97",
            "value": "tokenizer.json: 100%"
          }
        },
        "2be784c08e3443a9b20e073265388abd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c8d3ef58fd546e0b0fbd11510ec3b76",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_58c5538e6f014528b596a685c4e607b4",
            "value": 466062
          }
        },
        "3c9726c21f864a95b2eb7ef8ed56e2f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4c4883d53b144c4a1ebdb9745a5bea9",
            "placeholder": "​",
            "style": "IPY_MODEL_96a00fd4550c46bc8f3984c452bd12a5",
            "value": " 466k/466k [00:00&lt;00:00, 3.12MB/s]"
          }
        },
        "e9b6690cd30a4a12bbbe69f7fb2c90a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a815af9870d64484b08c6cd7d62e9e6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76400cf2088e49cd8006840e1088bf97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c8d3ef58fd546e0b0fbd11510ec3b76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58c5538e6f014528b596a685c4e607b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d4c4883d53b144c4a1ebdb9745a5bea9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96a00fd4550c46bc8f3984c452bd12a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "178f4294aeeb4c3a8e924f8a3304edd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd6cfcee0f39498692d5266b08f1ea7e",
              "IPY_MODEL_644747de0af8455d8a8be979a1c341ba",
              "IPY_MODEL_d242c884c1a345e9959ecf97939a11b4"
            ],
            "layout": "IPY_MODEL_4bde855a4c5443399f083625dd217da7"
          }
        },
        "bd6cfcee0f39498692d5266b08f1ea7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c52fb824b535402380af4eb638e243d6",
            "placeholder": "​",
            "style": "IPY_MODEL_95eedf56edf846029fcdce5743b28f38",
            "value": "config.json: 100%"
          }
        },
        "644747de0af8455d8a8be979a1c341ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb17b016d9584639a9d1a99110095c9f",
            "max": 483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_021964a087ed4abba0ef1ace713b8904",
            "value": 483
          }
        },
        "d242c884c1a345e9959ecf97939a11b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc6061b41a3e4cf984efc3675776025c",
            "placeholder": "​",
            "style": "IPY_MODEL_20955f92174d40808eb692e646dc4013",
            "value": " 483/483 [00:00&lt;00:00, 51.3kB/s]"
          }
        },
        "4bde855a4c5443399f083625dd217da7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c52fb824b535402380af4eb638e243d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95eedf56edf846029fcdce5743b28f38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb17b016d9584639a9d1a99110095c9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "021964a087ed4abba0ef1ace713b8904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc6061b41a3e4cf984efc3675776025c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20955f92174d40808eb692e646dc4013": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30dff45ef1bf4726b58665b33d0ee7cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db4bfb1ecc654a80bad282c9fcbcf469",
              "IPY_MODEL_724fb734869d415b8e73f447386ca2c5",
              "IPY_MODEL_bf31b4dafb974153be6560c4a4eae753"
            ],
            "layout": "IPY_MODEL_c0bf2f6df94342f39dbe60dd3fd20fd8"
          }
        },
        "db4bfb1ecc654a80bad282c9fcbcf469": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23bfb7d5d39b45fa8e107316b8c4ed52",
            "placeholder": "​",
            "style": "IPY_MODEL_8284d4f3589143eca715cbda33abb87e",
            "value": "model.safetensors: 100%"
          }
        },
        "724fb734869d415b8e73f447386ca2c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8af93053770a44fdaf9f31c404589776",
            "max": 267954768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3de12666bd6b4256b967daac43351561",
            "value": 267954768
          }
        },
        "bf31b4dafb974153be6560c4a4eae753": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07bad4d8e7ee4ed9a4a9c53df2fc0b0b",
            "placeholder": "​",
            "style": "IPY_MODEL_fcfa268aa39648449de91bb160757567",
            "value": " 268M/268M [00:06&lt;00:00, 15.3MB/s]"
          }
        },
        "c0bf2f6df94342f39dbe60dd3fd20fd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23bfb7d5d39b45fa8e107316b8c4ed52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8284d4f3589143eca715cbda33abb87e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8af93053770a44fdaf9f31c404589776": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3de12666bd6b4256b967daac43351561": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "07bad4d8e7ee4ed9a4a9c53df2fc0b0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcfa268aa39648449de91bb160757567": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas torch transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLQHXkctNk-m",
        "outputId": "0e4684ea-b4ae-421e-f583-c548a8138aab"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFMNoZ8rNk7K",
        "outputId": "cdbe1a0f-c86a-4d6b-ffdc-88350f3a6ce7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SxpJHNK7NeCy"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Define the MultiTaskDataset class\n",
        "class MultiTaskDataset(Dataset):\n",
        "    def __init__(self, dataframe, encodings, max_length, tasks):\n",
        "        self.data = dataframe\n",
        "        self.encodings = encodings\n",
        "        self.max_length = max_length\n",
        "        self.tasks = tasks\n",
        "        for task, info in tasks.items():\n",
        "            if info['type'] == 'multi-class':\n",
        "                info['label_map'] = {label: idx for idx, label in enumerate(info['classes'])}\n",
        "                info['num_classes'] = len(info['classes'])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        inputs = {\n",
        "            'input_ids': self.encodings['input_ids'][idx],\n",
        "            'attention_mask': self.encodings['attention_mask'][idx]\n",
        "        }\n",
        "        labels = {}\n",
        "        masks = {}\n",
        "        for task, info in self.tasks.items():\n",
        "            if info['type'] == 'binary':\n",
        "                label_col = info['column']\n",
        "                label = self.data.iloc[idx][label_col]\n",
        "                labels[task] = torch.tensor(label if pd.notna(label) else -1, dtype=torch.float)\n",
        "                masks[task] = 1 if pd.notna(label) else 0\n",
        "            elif info['type'] == 'multi-class':\n",
        "                label_col = info['column']\n",
        "                label = self.data.iloc[idx][label_col]\n",
        "                if pd.notna(label) and label != 'NaN':\n",
        "                    labels[task] = torch.tensor(info['label_map'][label], dtype=torch.long)\n",
        "                else:\n",
        "                    labels[task] = torch.tensor(-1, dtype=torch.long)\n",
        "                masks[task] = 1 if pd.notna(label) and label != 'NaN' else 0\n",
        "            elif info['type'] == 'multi-label':\n",
        "                label_cols = info['columns']\n",
        "                label = [self.data.iloc[idx][col] for col in label_cols]\n",
        "                if all(pd.notna(l) for l in label):\n",
        "                    labels[task] = torch.tensor(label, dtype=torch.float)\n",
        "                    masks[task] = 1\n",
        "                else:\n",
        "                    labels[task] = torch.tensor([-1] * len(label_cols), dtype=torch.float)\n",
        "                    masks[task] = 0\n",
        "        return inputs, labels, masks\n",
        "\n",
        "# Define the MultiTaskDistilBERT model\n",
        "class MultiTaskDistilBERT(nn.Module):\n",
        "    def __init__(self, distilbert_model, tasks):\n",
        "        super().__init__()\n",
        "        self.distilbert = distilbert_model\n",
        "        self.tasks = tasks\n",
        "        self.heads = nn.ModuleDict()\n",
        "        for task, info in tasks.items():\n",
        "            if info['type'] == 'binary':\n",
        "                self.heads[task] = nn.Linear(distilbert_model.config.dim, 1)\n",
        "            elif info['type'] == 'multi-class':\n",
        "                self.heads[task] = nn.Linear(distilbert_model.config.dim, info['num_classes'])\n",
        "            elif info['type'] == 'multi-label':\n",
        "                self.heads[task] = nn.Linear(distilbert_model.config.dim, len(info['columns']))\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.distilbert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.last_hidden_state[:, 0, :]  # Use [CLS] token representation\n",
        "        task_outputs = {}\n",
        "        for task, head in self.heads.items():\n",
        "            task_outputs[task] = head(pooled_output)\n",
        "        return task_outputs\n",
        "\n",
        "# Define tasks based on dataset structure\n",
        "tasks = {\n",
        "    'spam': {'type': 'binary', 'column': 'spam'},\n",
        "    'sentiment': {'type': 'multi-class', 'column': 'sentiment', 'classes': ['Positive', 'Neutral', 'Negative', 'Irrelevant']},\n",
        "    'toxicity': {'type': 'multi-label', 'columns': ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']},\n",
        "    'hate_speech': {'type': 'multi-class', 'column': 'hate_speech', 'classes': ['normal', 'offensive', 'hatespeech']}\n",
        "}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/MLBD_Project/final_comment_analysis_data.csv')\n",
        "df['text'] = df['text'].fillna('')\n",
        "binary_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate', 'spam']\n",
        "for col in binary_cols:\n",
        "    df[col] = df[col].fillna(0).astype(int)\n",
        "df['sentiment'] = df['sentiment'].fillna('NaN')\n",
        "df['hate_speech'] = df['hate_speech'].fillna('NaN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4MPul-pN3VZ",
        "outputId": "25ceae2c-a313-4b70-8984-d0388740e916"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-039f5ceba395>:2: DtypeWarning: Columns (7,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('/content/drive/MyDrive/MLBD_Project/final_comment_analysis_data.csv')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-tokenize dataset\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "encodings = tokenizer(df['text'].tolist(), max_length=128, padding='max_length', truncation=True, return_tensors='pt')\n",
        "torch.save(encodings, '/content/drive/MyDrive/MLBD_Project/tokenized_dataset.pt')\n",
        "print(f\"Length of encodings['input_ids']: {len(encodings['input_ids'])}\")\n",
        "print(f\"Length of dataframe: {len(df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304,
          "referenced_widgets": [
            "35d53a224f054e5d952ccbb7da2b2b04",
            "adba1a34eac64e81b34591746dbe2a4c",
            "72171e8278264a86891af06ccfac8cbb",
            "f57399bb4cf74f6b8f400efac096f2e2",
            "cdf1f2ac461147f6a6a3bd25e1cf35d5",
            "524122b1141d4d218dc49228d335e466",
            "c55a6197ddf346489021b9d1db0cda3c",
            "fb5b4c01d54c4b968a9759299bd96b45",
            "ae85408a3dae4452b77c8083e0c8cdcf",
            "93b6abcbbe6946659c21dd30fab2b7fa",
            "56779223e2664c089f76915a022fcfd5",
            "42436d0931be40869d209b5fd98d227f",
            "e2789592977e42b19b70e68254a013ed",
            "54fa29c3a9934b98bac22b82e21b4cff",
            "c5d5c786c4474d1eb13c96d6d60ba7fb",
            "0a4db4c759234e898089614b7735ae06",
            "4d059add83a84ba6ab0631b544ec720e",
            "14c8544db7954dcf81ef27e98e58904d",
            "f8c7467d85bf4150b8dccc6663c8af34",
            "a457b91259ef4d8585404339073a5e9f",
            "1af602b6f2d0437bb17fbe3b0bb1cd4e",
            "6edd6d3c8ce34abf9ed60e9e8d105159",
            "9135956a473e44eba9fc29aa72ba7609",
            "4cc17942ba4f4d7abe67e96adfa406f0",
            "2be784c08e3443a9b20e073265388abd",
            "3c9726c21f864a95b2eb7ef8ed56e2f4",
            "e9b6690cd30a4a12bbbe69f7fb2c90a1",
            "a815af9870d64484b08c6cd7d62e9e6e",
            "76400cf2088e49cd8006840e1088bf97",
            "4c8d3ef58fd546e0b0fbd11510ec3b76",
            "58c5538e6f014528b596a685c4e607b4",
            "d4c4883d53b144c4a1ebdb9745a5bea9",
            "96a00fd4550c46bc8f3984c452bd12a5",
            "178f4294aeeb4c3a8e924f8a3304edd8",
            "bd6cfcee0f39498692d5266b08f1ea7e",
            "644747de0af8455d8a8be979a1c341ba",
            "d242c884c1a345e9959ecf97939a11b4",
            "4bde855a4c5443399f083625dd217da7",
            "c52fb824b535402380af4eb638e243d6",
            "95eedf56edf846029fcdce5743b28f38",
            "fb17b016d9584639a9d1a99110095c9f",
            "021964a087ed4abba0ef1ace713b8904",
            "bc6061b41a3e4cf984efc3675776025c",
            "20955f92174d40808eb692e646dc4013"
          ]
        },
        "id": "t96TcGrzN-tI",
        "outputId": "c3135f8a-f079-40e1-81eb-e787e7a3700f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35d53a224f054e5d952ccbb7da2b2b04"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "42436d0931be40869d209b5fd98d227f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9135956a473e44eba9fc29aa72ba7609"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "178f4294aeeb4c3a8e924f8a3304edd8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of encodings['input_ids']: 246378\n",
            "Length of dataframe: 246378\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "distilbert_model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "dataset = MultiTaskDataset(df, encodings, max_length=128, tasks=tasks)\n",
        "model = MultiTaskDistilBERT(distilbert_model, tasks)\n",
        "\n",
        "# Create dataset and dataloader\n",
        "dataloader = DataLoader(dataset, batch_size=8, shuffle=True, num_workers=0, pin_memory=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "30dff45ef1bf4726b58665b33d0ee7cb",
            "db4bfb1ecc654a80bad282c9fcbcf469",
            "724fb734869d415b8e73f447386ca2c5",
            "bf31b4dafb974153be6560c4a4eae753",
            "c0bf2f6df94342f39dbe60dd3fd20fd8",
            "23bfb7d5d39b45fa8e107316b8c4ed52",
            "8284d4f3589143eca715cbda33abb87e",
            "8af93053770a44fdaf9f31c404589776",
            "3de12666bd6b4256b967daac43351561",
            "07bad4d8e7ee4ed9a4a9c53df2fc0b0b",
            "fcfa268aa39648449de91bb160757567"
          ]
        },
        "id": "g3WjJl3kOIyQ",
        "outputId": "8229bea1-de15-4aff-b54e-62db8a3f75cc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30dff45ef1bf4726b58665b33d0ee7cb"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define optimizer and device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "model.to(device)\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEX9GJQkOVO8",
        "outputId": "79b104c4-af44-449c-beb0-68f36d16413a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start training from epoch 1\n",
        "num_epochs = 3\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for batch_idx, batch in enumerate(dataloader):\n",
        "        print(f\"Epoch {epoch + 1}, Processing batch {batch_idx+1}/{len(dataloader)}\")\n",
        "        try:\n",
        "            inputs, labels, masks = batch\n",
        "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "            labels = {k: v.to(device) for k, v in labels.items()}\n",
        "            masks = {k: v.to(device) for k, v in masks.items()}\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
        "            loss = 0\n",
        "            for task, output in outputs.items():\n",
        "                task_labels = labels[task]\n",
        "                task_mask = masks[task]\n",
        "                if task_mask.sum() > 0:\n",
        "                    indices = task_mask.nonzero().squeeze(1)\n",
        "                    if tasks[task]['type'] == 'binary':\n",
        "                        loss_fn = nn.BCEWithLogitsLoss()\n",
        "                        loss += loss_fn(output[indices], task_labels[indices].unsqueeze(1))\n",
        "                    elif tasks[task]['type'] == 'multi-class':\n",
        "                        loss_fn = nn.CrossEntropyLoss()\n",
        "                        loss += loss_fn(output[indices], task_labels[indices])\n",
        "                    elif tasks[task]['type'] == 'multi-label':\n",
        "                        loss_fn = nn.BCEWithLogitsLoss()\n",
        "                        loss += loss_fn(output[indices], task_labels[indices])\n",
        "            print(f\"Batch {batch_idx+1} Loss: {loss.item()}\")\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        except Exception as e:\n",
        "            print(f\"Error in batch {batch_idx+1}: {e}\")\n",
        "            break\n",
        "    print(f\"Epoch {epoch + 1} Loss: {total_loss / len(dataloader)}\")\n",
        "    torch.save(model.state_dict(), f'/content/drive/MyDrive/MLBD_Project/multi_task_distilbert_epoch_{epoch + 1}.pth')\n",
        "    tokenizer.save_pretrained(f'/content/drive/MyDrive/MLBD_Project/tokenizer_epoch_{epoch + 1}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7xUKNnEOhu5",
        "outputId": "52f8c8ff-3426-402c-aca5-d7e9f9d5051f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Batch 28299 Loss: 0.08113669604063034\n",
            "Epoch 3, Processing batch 28300/30798\n",
            "Batch 28300 Loss: 0.1831081509590149\n",
            "Epoch 3, Processing batch 28301/30798\n",
            "Batch 28301 Loss: 0.14321500062942505\n",
            "Epoch 3, Processing batch 28302/30798\n",
            "Batch 28302 Loss: 0.06600596755743027\n",
            "Epoch 3, Processing batch 28303/30798\n",
            "Batch 28303 Loss: 0.04115360230207443\n",
            "Epoch 3, Processing batch 28304/30798\n",
            "Batch 28304 Loss: 0.006646761670708656\n",
            "Epoch 3, Processing batch 28305/30798\n",
            "Batch 28305 Loss: 0.7241858839988708\n",
            "Epoch 3, Processing batch 28306/30798\n",
            "Batch 28306 Loss: 0.04994899407029152\n",
            "Epoch 3, Processing batch 28307/30798\n",
            "Batch 28307 Loss: 0.3716566562652588\n",
            "Epoch 3, Processing batch 28308/30798\n",
            "Batch 28308 Loss: 0.4348825216293335\n",
            "Epoch 3, Processing batch 28309/30798\n",
            "Batch 28309 Loss: 0.03132839500904083\n",
            "Epoch 3, Processing batch 28310/30798\n",
            "Batch 28310 Loss: 0.014272008091211319\n",
            "Epoch 3, Processing batch 28311/30798\n",
            "Batch 28311 Loss: 0.1934397667646408\n",
            "Epoch 3, Processing batch 28312/30798\n",
            "Batch 28312 Loss: 0.007396525237709284\n",
            "Epoch 3, Processing batch 28313/30798\n",
            "Batch 28313 Loss: 0.5575087666511536\n",
            "Epoch 3, Processing batch 28314/30798\n",
            "Batch 28314 Loss: 0.06176058202981949\n",
            "Epoch 3, Processing batch 28315/30798\n",
            "Batch 28315 Loss: 0.013638745062053204\n",
            "Epoch 3, Processing batch 28316/30798\n",
            "Batch 28316 Loss: 0.1681065559387207\n",
            "Epoch 3, Processing batch 28317/30798\n",
            "Batch 28317 Loss: 0.49079662561416626\n",
            "Epoch 3, Processing batch 28318/30798\n",
            "Batch 28318 Loss: 0.4011853039264679\n",
            "Epoch 3, Processing batch 28319/30798\n",
            "Batch 28319 Loss: 0.0032013526652008295\n",
            "Epoch 3, Processing batch 28320/30798\n",
            "Batch 28320 Loss: 0.06802012026309967\n",
            "Epoch 3, Processing batch 28321/30798\n",
            "Batch 28321 Loss: 0.6521804332733154\n",
            "Epoch 3, Processing batch 28322/30798\n",
            "Batch 28322 Loss: 0.0493832528591156\n",
            "Epoch 3, Processing batch 28323/30798\n",
            "Batch 28323 Loss: 2.245182752609253\n",
            "Epoch 3, Processing batch 28324/30798\n",
            "Batch 28324 Loss: 0.2520461678504944\n",
            "Epoch 3, Processing batch 28325/30798\n",
            "Batch 28325 Loss: 0.014837454073131084\n",
            "Epoch 3, Processing batch 28326/30798\n",
            "Batch 28326 Loss: 0.009650003165006638\n",
            "Epoch 3, Processing batch 28327/30798\n",
            "Batch 28327 Loss: 0.1540745347738266\n",
            "Epoch 3, Processing batch 28328/30798\n",
            "Batch 28328 Loss: 0.05332975462079048\n",
            "Epoch 3, Processing batch 28329/30798\n",
            "Batch 28329 Loss: 0.09247688204050064\n",
            "Epoch 3, Processing batch 28330/30798\n",
            "Batch 28330 Loss: 0.23095808923244476\n",
            "Epoch 3, Processing batch 28331/30798\n",
            "Batch 28331 Loss: 1.3588231801986694\n",
            "Epoch 3, Processing batch 28332/30798\n",
            "Batch 28332 Loss: 0.15267834067344666\n",
            "Epoch 3, Processing batch 28333/30798\n",
            "Batch 28333 Loss: 0.041751209646463394\n",
            "Epoch 3, Processing batch 28334/30798\n",
            "Batch 28334 Loss: 0.3983113765716553\n",
            "Epoch 3, Processing batch 28335/30798\n",
            "Batch 28335 Loss: 0.9888793230056763\n",
            "Epoch 3, Processing batch 28336/30798\n",
            "Batch 28336 Loss: 0.12286731600761414\n",
            "Epoch 3, Processing batch 28337/30798\n",
            "Batch 28337 Loss: 0.14321930706501007\n",
            "Epoch 3, Processing batch 28338/30798\n",
            "Batch 28338 Loss: 0.18379563093185425\n",
            "Epoch 3, Processing batch 28339/30798\n",
            "Batch 28339 Loss: 0.00953313522040844\n",
            "Epoch 3, Processing batch 28340/30798\n",
            "Batch 28340 Loss: 0.27497321367263794\n",
            "Epoch 3, Processing batch 28341/30798\n",
            "Batch 28341 Loss: 0.022155923768877983\n",
            "Epoch 3, Processing batch 28342/30798\n",
            "Batch 28342 Loss: 0.05783907696604729\n",
            "Epoch 3, Processing batch 28343/30798\n",
            "Batch 28343 Loss: 1.798647403717041\n",
            "Epoch 3, Processing batch 28344/30798\n",
            "Batch 28344 Loss: 0.06302627921104431\n",
            "Epoch 3, Processing batch 28345/30798\n",
            "Batch 28345 Loss: 0.08715061098337173\n",
            "Epoch 3, Processing batch 28346/30798\n",
            "Batch 28346 Loss: 1.716751217842102\n",
            "Epoch 3, Processing batch 28347/30798\n",
            "Batch 28347 Loss: 0.14598412811756134\n",
            "Epoch 3, Processing batch 28348/30798\n",
            "Batch 28348 Loss: 0.00621646735817194\n",
            "Epoch 3, Processing batch 28349/30798\n",
            "Batch 28349 Loss: 1.6718982458114624\n",
            "Epoch 3, Processing batch 28350/30798\n",
            "Batch 28350 Loss: 0.009822724387049675\n",
            "Epoch 3, Processing batch 28351/30798\n",
            "Batch 28351 Loss: 0.26169446110725403\n",
            "Epoch 3, Processing batch 28352/30798\n",
            "Batch 28352 Loss: 0.12108169496059418\n",
            "Epoch 3, Processing batch 28353/30798\n",
            "Batch 28353 Loss: 0.23777662217617035\n",
            "Epoch 3, Processing batch 28354/30798\n",
            "Batch 28354 Loss: 1.2272241115570068\n",
            "Epoch 3, Processing batch 28355/30798\n",
            "Batch 28355 Loss: 0.018131185322999954\n",
            "Epoch 3, Processing batch 28356/30798\n",
            "Batch 28356 Loss: 0.004789419937878847\n",
            "Epoch 3, Processing batch 28357/30798\n",
            "Batch 28357 Loss: 0.10081549733877182\n",
            "Epoch 3, Processing batch 28358/30798\n",
            "Batch 28358 Loss: 0.46756845712661743\n",
            "Epoch 3, Processing batch 28359/30798\n",
            "Batch 28359 Loss: 0.37031400203704834\n",
            "Epoch 3, Processing batch 28360/30798\n",
            "Batch 28360 Loss: 0.6330417394638062\n",
            "Epoch 3, Processing batch 28361/30798\n",
            "Batch 28361 Loss: 0.08567497879266739\n",
            "Epoch 3, Processing batch 28362/30798\n",
            "Batch 28362 Loss: 0.39364439249038696\n",
            "Epoch 3, Processing batch 28363/30798\n",
            "Batch 28363 Loss: 0.6126540899276733\n",
            "Epoch 3, Processing batch 28364/30798\n",
            "Batch 28364 Loss: 0.0758916363120079\n",
            "Epoch 3, Processing batch 28365/30798\n",
            "Batch 28365 Loss: 0.5117567777633667\n",
            "Epoch 3, Processing batch 28366/30798\n",
            "Batch 28366 Loss: 0.10702108591794968\n",
            "Epoch 3, Processing batch 28367/30798\n",
            "Batch 28367 Loss: 0.10372574627399445\n",
            "Epoch 3, Processing batch 28368/30798\n",
            "Batch 28368 Loss: 0.018382098525762558\n",
            "Epoch 3, Processing batch 28369/30798\n",
            "Batch 28369 Loss: 1.0043405294418335\n",
            "Epoch 3, Processing batch 28370/30798\n",
            "Batch 28370 Loss: 0.07456742227077484\n",
            "Epoch 3, Processing batch 28371/30798\n",
            "Batch 28371 Loss: 1.5254753828048706\n",
            "Epoch 3, Processing batch 28372/30798\n",
            "Batch 28372 Loss: 0.38611435890197754\n",
            "Epoch 3, Processing batch 28373/30798\n",
            "Batch 28373 Loss: 0.0034129787236452103\n",
            "Epoch 3, Processing batch 28374/30798\n",
            "Batch 28374 Loss: 0.6906783580780029\n",
            "Epoch 3, Processing batch 28375/30798\n",
            "Batch 28375 Loss: 0.04664688557386398\n",
            "Epoch 3, Processing batch 28376/30798\n",
            "Batch 28376 Loss: 0.04642980545759201\n",
            "Epoch 3, Processing batch 28377/30798\n",
            "Batch 28377 Loss: 0.15818104147911072\n",
            "Epoch 3, Processing batch 28378/30798\n",
            "Batch 28378 Loss: 0.0023061137180775404\n",
            "Epoch 3, Processing batch 28379/30798\n",
            "Batch 28379 Loss: 0.09644830971956253\n",
            "Epoch 3, Processing batch 28380/30798\n",
            "Batch 28380 Loss: 0.2761722207069397\n",
            "Epoch 3, Processing batch 28381/30798\n",
            "Batch 28381 Loss: 0.17011511325836182\n",
            "Epoch 3, Processing batch 28382/30798\n",
            "Batch 28382 Loss: 0.17103475332260132\n",
            "Epoch 3, Processing batch 28383/30798\n",
            "Batch 28383 Loss: 0.1673160046339035\n",
            "Epoch 3, Processing batch 28384/30798\n",
            "Batch 28384 Loss: 0.004189915955066681\n",
            "Epoch 3, Processing batch 28385/30798\n",
            "Batch 28385 Loss: 0.7258751392364502\n",
            "Epoch 3, Processing batch 28386/30798\n",
            "Batch 28386 Loss: 0.19460079073905945\n",
            "Epoch 3, Processing batch 28387/30798\n",
            "Batch 28387 Loss: 0.30120909214019775\n",
            "Epoch 3, Processing batch 28388/30798\n",
            "Batch 28388 Loss: 0.15786629915237427\n",
            "Epoch 3, Processing batch 28389/30798\n",
            "Batch 28389 Loss: 0.21260219812393188\n",
            "Epoch 3, Processing batch 28390/30798\n",
            "Batch 28390 Loss: 0.13085982203483582\n",
            "Epoch 3, Processing batch 28391/30798\n",
            "Batch 28391 Loss: 0.14349664747714996\n",
            "Epoch 3, Processing batch 28392/30798\n",
            "Batch 28392 Loss: 0.13282406330108643\n",
            "Epoch 3, Processing batch 28393/30798\n",
            "Batch 28393 Loss: 0.16903305053710938\n",
            "Epoch 3, Processing batch 28394/30798\n",
            "Batch 28394 Loss: 0.38505619764328003\n",
            "Epoch 3, Processing batch 28395/30798\n",
            "Batch 28395 Loss: 0.0029209833592176437\n",
            "Epoch 3, Processing batch 28396/30798\n",
            "Batch 28396 Loss: 0.02629663050174713\n",
            "Epoch 3, Processing batch 28397/30798\n",
            "Batch 28397 Loss: 0.1468118280172348\n",
            "Epoch 3, Processing batch 28398/30798\n",
            "Batch 28398 Loss: 0.5543947219848633\n",
            "Epoch 3, Processing batch 28399/30798\n",
            "Batch 28399 Loss: 0.20117241144180298\n",
            "Epoch 3, Processing batch 28400/30798\n",
            "Batch 28400 Loss: 0.9814554452896118\n",
            "Epoch 3, Processing batch 28401/30798\n",
            "Batch 28401 Loss: 0.2521815896034241\n",
            "Epoch 3, Processing batch 28402/30798\n",
            "Batch 28402 Loss: 0.027799712494015694\n",
            "Epoch 3, Processing batch 28403/30798\n",
            "Batch 28403 Loss: 0.34647324681282043\n",
            "Epoch 3, Processing batch 28404/30798\n",
            "Batch 28404 Loss: 0.06445906311273575\n",
            "Epoch 3, Processing batch 28405/30798\n",
            "Batch 28405 Loss: 0.07995583862066269\n",
            "Epoch 3, Processing batch 28406/30798\n",
            "Batch 28406 Loss: 0.0039009314496070147\n",
            "Epoch 3, Processing batch 28407/30798\n",
            "Batch 28407 Loss: 0.003728288458660245\n",
            "Epoch 3, Processing batch 28408/30798\n",
            "Batch 28408 Loss: 0.4021955132484436\n",
            "Epoch 3, Processing batch 28409/30798\n",
            "Batch 28409 Loss: 0.004884107504040003\n",
            "Epoch 3, Processing batch 28410/30798\n",
            "Batch 28410 Loss: 0.9014257192611694\n",
            "Epoch 3, Processing batch 28411/30798\n",
            "Batch 28411 Loss: 0.1883479356765747\n",
            "Epoch 3, Processing batch 28412/30798\n",
            "Batch 28412 Loss: 0.03823690116405487\n",
            "Epoch 3, Processing batch 28413/30798\n",
            "Batch 28413 Loss: 0.06504201143980026\n",
            "Epoch 3, Processing batch 28414/30798\n",
            "Batch 28414 Loss: 0.05765671283006668\n",
            "Epoch 3, Processing batch 28415/30798\n",
            "Batch 28415 Loss: 0.08688706159591675\n",
            "Epoch 3, Processing batch 28416/30798\n",
            "Batch 28416 Loss: 0.11046873033046722\n",
            "Epoch 3, Processing batch 28417/30798\n",
            "Batch 28417 Loss: 0.008796973153948784\n",
            "Epoch 3, Processing batch 28418/30798\n",
            "Batch 28418 Loss: 0.0033170764800161123\n",
            "Epoch 3, Processing batch 28419/30798\n",
            "Batch 28419 Loss: 0.08635794371366501\n",
            "Epoch 3, Processing batch 28420/30798\n",
            "Batch 28420 Loss: 0.01715390384197235\n",
            "Epoch 3, Processing batch 28421/30798\n",
            "Batch 28421 Loss: 3.441457509994507\n",
            "Epoch 3, Processing batch 28422/30798\n",
            "Batch 28422 Loss: 0.13415423035621643\n",
            "Epoch 3, Processing batch 28423/30798\n",
            "Batch 28423 Loss: 0.03606539964675903\n",
            "Epoch 3, Processing batch 28424/30798\n",
            "Batch 28424 Loss: 0.053950611501932144\n",
            "Epoch 3, Processing batch 28425/30798\n",
            "Batch 28425 Loss: 0.02599618397653103\n",
            "Epoch 3, Processing batch 28426/30798\n",
            "Batch 28426 Loss: 0.061714064329862595\n",
            "Epoch 3, Processing batch 28427/30798\n",
            "Batch 28427 Loss: 0.3588046431541443\n",
            "Epoch 3, Processing batch 28428/30798\n",
            "Batch 28428 Loss: 0.3543704152107239\n",
            "Epoch 3, Processing batch 28429/30798\n",
            "Batch 28429 Loss: 0.09791059792041779\n",
            "Epoch 3, Processing batch 28430/30798\n",
            "Batch 28430 Loss: 0.15403121709823608\n",
            "Epoch 3, Processing batch 28431/30798\n",
            "Batch 28431 Loss: 0.08920763432979584\n",
            "Epoch 3, Processing batch 28432/30798\n",
            "Batch 28432 Loss: 0.04537210613489151\n",
            "Epoch 3, Processing batch 28433/30798\n",
            "Batch 28433 Loss: 0.4183438718318939\n",
            "Epoch 3, Processing batch 28434/30798\n",
            "Batch 28434 Loss: 0.09694337844848633\n",
            "Epoch 3, Processing batch 28435/30798\n",
            "Batch 28435 Loss: 0.15855561196804047\n",
            "Epoch 3, Processing batch 28436/30798\n",
            "Batch 28436 Loss: 0.10420413315296173\n",
            "Epoch 3, Processing batch 28437/30798\n",
            "Batch 28437 Loss: 0.03594021499156952\n",
            "Epoch 3, Processing batch 28438/30798\n",
            "Batch 28438 Loss: 0.0597897469997406\n",
            "Epoch 3, Processing batch 28439/30798\n",
            "Batch 28439 Loss: 0.01806063763797283\n",
            "Epoch 3, Processing batch 28440/30798\n",
            "Batch 28440 Loss: 0.010739884339272976\n",
            "Epoch 3, Processing batch 28441/30798\n",
            "Batch 28441 Loss: 0.6519482731819153\n",
            "Epoch 3, Processing batch 28442/30798\n",
            "Batch 28442 Loss: 0.8735076189041138\n",
            "Epoch 3, Processing batch 28443/30798\n",
            "Batch 28443 Loss: 0.2258964329957962\n",
            "Epoch 3, Processing batch 28444/30798\n",
            "Batch 28444 Loss: 0.03575954958796501\n",
            "Epoch 3, Processing batch 28445/30798\n",
            "Batch 28445 Loss: 1.0347363948822021\n",
            "Epoch 3, Processing batch 28446/30798\n",
            "Batch 28446 Loss: 0.439894437789917\n",
            "Epoch 3, Processing batch 28447/30798\n",
            "Batch 28447 Loss: 0.04430948942899704\n",
            "Epoch 3, Processing batch 28448/30798\n",
            "Batch 28448 Loss: 2.3706374168395996\n",
            "Epoch 3, Processing batch 28449/30798\n",
            "Batch 28449 Loss: 0.03449250012636185\n",
            "Epoch 3, Processing batch 28450/30798\n",
            "Batch 28450 Loss: 0.6929575204849243\n",
            "Epoch 3, Processing batch 28451/30798\n",
            "Batch 28451 Loss: 0.0024174158461391926\n",
            "Epoch 3, Processing batch 28452/30798\n",
            "Batch 28452 Loss: 0.1517399549484253\n",
            "Epoch 3, Processing batch 28453/30798\n",
            "Batch 28453 Loss: 0.030017852783203125\n",
            "Epoch 3, Processing batch 28454/30798\n",
            "Batch 28454 Loss: 0.06540612876415253\n",
            "Epoch 3, Processing batch 28455/30798\n",
            "Batch 28455 Loss: 1.5631521940231323\n",
            "Epoch 3, Processing batch 28456/30798\n",
            "Batch 28456 Loss: 0.46085435152053833\n",
            "Epoch 3, Processing batch 28457/30798\n",
            "Batch 28457 Loss: 0.049148380756378174\n",
            "Epoch 3, Processing batch 28458/30798\n",
            "Batch 28458 Loss: 0.042907167226076126\n",
            "Epoch 3, Processing batch 28459/30798\n",
            "Batch 28459 Loss: 0.4764477014541626\n",
            "Epoch 3, Processing batch 28460/30798\n",
            "Batch 28460 Loss: 0.3046475946903229\n",
            "Epoch 3, Processing batch 28461/30798\n",
            "Batch 28461 Loss: 0.1332157701253891\n",
            "Epoch 3, Processing batch 28462/30798\n",
            "Batch 28462 Loss: 0.005641046911478043\n",
            "Epoch 3, Processing batch 28463/30798\n",
            "Batch 28463 Loss: 1.1367387771606445\n",
            "Epoch 3, Processing batch 28464/30798\n",
            "Batch 28464 Loss: 0.041748471558094025\n",
            "Epoch 3, Processing batch 28465/30798\n",
            "Batch 28465 Loss: 0.4625833034515381\n",
            "Epoch 3, Processing batch 28466/30798\n",
            "Batch 28466 Loss: 0.10025465488433838\n",
            "Epoch 3, Processing batch 28467/30798\n",
            "Batch 28467 Loss: 0.00842578150331974\n",
            "Epoch 3, Processing batch 28468/30798\n",
            "Batch 28468 Loss: 2.987480640411377\n",
            "Epoch 3, Processing batch 28469/30798\n",
            "Batch 28469 Loss: 0.5089474320411682\n",
            "Epoch 3, Processing batch 28470/30798\n",
            "Batch 28470 Loss: 0.14969375729560852\n",
            "Epoch 3, Processing batch 28471/30798\n",
            "Batch 28471 Loss: 0.304880827665329\n",
            "Epoch 3, Processing batch 28472/30798\n",
            "Batch 28472 Loss: 0.013707149773836136\n",
            "Epoch 3, Processing batch 28473/30798\n",
            "Batch 28473 Loss: 0.05824205279350281\n",
            "Epoch 3, Processing batch 28474/30798\n",
            "Batch 28474 Loss: 0.3019460141658783\n",
            "Epoch 3, Processing batch 28475/30798\n",
            "Batch 28475 Loss: 0.21859928965568542\n",
            "Epoch 3, Processing batch 28476/30798\n",
            "Batch 28476 Loss: 0.05412600561976433\n",
            "Epoch 3, Processing batch 28477/30798\n",
            "Batch 28477 Loss: 0.02565787360072136\n",
            "Epoch 3, Processing batch 28478/30798\n",
            "Batch 28478 Loss: 0.15131448209285736\n",
            "Epoch 3, Processing batch 28479/30798\n",
            "Batch 28479 Loss: 0.03607173264026642\n",
            "Epoch 3, Processing batch 28480/30798\n",
            "Batch 28480 Loss: 0.7642590999603271\n",
            "Epoch 3, Processing batch 28481/30798\n",
            "Batch 28481 Loss: 0.022556422278285027\n",
            "Epoch 3, Processing batch 28482/30798\n",
            "Batch 28482 Loss: 0.03933719918131828\n",
            "Epoch 3, Processing batch 28483/30798\n",
            "Batch 28483 Loss: 0.32671767473220825\n",
            "Epoch 3, Processing batch 28484/30798\n",
            "Batch 28484 Loss: 0.006101793609559536\n",
            "Epoch 3, Processing batch 28485/30798\n",
            "Batch 28485 Loss: 0.042458124458789825\n",
            "Epoch 3, Processing batch 28486/30798\n",
            "Batch 28486 Loss: 0.0865064486861229\n",
            "Epoch 3, Processing batch 28487/30798\n",
            "Batch 28487 Loss: 0.9875468611717224\n",
            "Epoch 3, Processing batch 28488/30798\n",
            "Batch 28488 Loss: 0.03300965577363968\n",
            "Epoch 3, Processing batch 28489/30798\n",
            "Batch 28489 Loss: 0.009225783869624138\n",
            "Epoch 3, Processing batch 28490/30798\n",
            "Batch 28490 Loss: 0.055215124040842056\n",
            "Epoch 3, Processing batch 28491/30798\n",
            "Batch 28491 Loss: 1.5735671520233154\n",
            "Epoch 3, Processing batch 28492/30798\n",
            "Batch 28492 Loss: 0.27371829748153687\n",
            "Epoch 3, Processing batch 28493/30798\n",
            "Batch 28493 Loss: 0.01652350090444088\n",
            "Epoch 3, Processing batch 28494/30798\n",
            "Batch 28494 Loss: 1.4432581663131714\n",
            "Epoch 3, Processing batch 28495/30798\n",
            "Batch 28495 Loss: 0.013120448216795921\n",
            "Epoch 3, Processing batch 28496/30798\n",
            "Batch 28496 Loss: 2.1310694217681885\n",
            "Epoch 3, Processing batch 28497/30798\n",
            "Batch 28497 Loss: 0.06778775900602341\n",
            "Epoch 3, Processing batch 28498/30798\n",
            "Batch 28498 Loss: 0.025592803955078125\n",
            "Epoch 3, Processing batch 28499/30798\n",
            "Batch 28499 Loss: 0.03858613222837448\n",
            "Epoch 3, Processing batch 28500/30798\n",
            "Batch 28500 Loss: 0.5874114036560059\n",
            "Epoch 3, Processing batch 28501/30798\n",
            "Batch 28501 Loss: 1.2528464794158936\n",
            "Epoch 3, Processing batch 28502/30798\n",
            "Batch 28502 Loss: 0.10191261023283005\n",
            "Epoch 3, Processing batch 28503/30798\n",
            "Batch 28503 Loss: 0.08261952549219131\n",
            "Epoch 3, Processing batch 28504/30798\n",
            "Batch 28504 Loss: 0.807449460029602\n",
            "Epoch 3, Processing batch 28505/30798\n",
            "Batch 28505 Loss: 0.051331669092178345\n",
            "Epoch 3, Processing batch 28506/30798\n",
            "Batch 28506 Loss: 0.04030464589595795\n",
            "Epoch 3, Processing batch 28507/30798\n",
            "Batch 28507 Loss: 0.023388206958770752\n",
            "Epoch 3, Processing batch 28508/30798\n",
            "Batch 28508 Loss: 0.3048500418663025\n",
            "Epoch 3, Processing batch 28509/30798\n",
            "Batch 28509 Loss: 0.5322630405426025\n",
            "Epoch 3, Processing batch 28510/30798\n",
            "Batch 28510 Loss: 0.2969292998313904\n",
            "Epoch 3, Processing batch 28511/30798\n",
            "Batch 28511 Loss: 0.4143649935722351\n",
            "Epoch 3, Processing batch 28512/30798\n",
            "Batch 28512 Loss: 0.10510976612567902\n",
            "Epoch 3, Processing batch 28513/30798\n",
            "Batch 28513 Loss: 1.7112103700637817\n",
            "Epoch 3, Processing batch 28514/30798\n",
            "Batch 28514 Loss: 0.1274976283311844\n",
            "Epoch 3, Processing batch 28515/30798\n",
            "Batch 28515 Loss: 1.0353368520736694\n",
            "Epoch 3, Processing batch 28516/30798\n",
            "Batch 28516 Loss: 0.0029403013177216053\n",
            "Epoch 3, Processing batch 28517/30798\n",
            "Batch 28517 Loss: 0.04832596331834793\n",
            "Epoch 3, Processing batch 28518/30798\n",
            "Batch 28518 Loss: 0.10800820589065552\n",
            "Epoch 3, Processing batch 28519/30798\n",
            "Batch 28519 Loss: 1.2874499559402466\n",
            "Epoch 3, Processing batch 28520/30798\n",
            "Batch 28520 Loss: 1.2764066457748413\n",
            "Epoch 3, Processing batch 28521/30798\n",
            "Batch 28521 Loss: 0.08528463542461395\n",
            "Epoch 3, Processing batch 28522/30798\n",
            "Batch 28522 Loss: 3.6632869243621826\n",
            "Epoch 3, Processing batch 28523/30798\n",
            "Batch 28523 Loss: 0.33774513006210327\n",
            "Epoch 3, Processing batch 28524/30798\n",
            "Batch 28524 Loss: 0.01095671858638525\n",
            "Epoch 3, Processing batch 28525/30798\n",
            "Batch 28525 Loss: 0.12538926303386688\n",
            "Epoch 3, Processing batch 28526/30798\n",
            "Batch 28526 Loss: 1.19430673122406\n",
            "Epoch 3, Processing batch 28527/30798\n",
            "Batch 28527 Loss: 0.11188870668411255\n",
            "Epoch 3, Processing batch 28528/30798\n",
            "Batch 28528 Loss: 0.027104705572128296\n",
            "Epoch 3, Processing batch 28529/30798\n",
            "Batch 28529 Loss: 0.9529641270637512\n",
            "Epoch 3, Processing batch 28530/30798\n",
            "Batch 28530 Loss: 0.25061750411987305\n",
            "Epoch 3, Processing batch 28531/30798\n",
            "Batch 28531 Loss: 0.020950576290488243\n",
            "Epoch 3, Processing batch 28532/30798\n",
            "Batch 28532 Loss: 1.3458791971206665\n",
            "Epoch 3, Processing batch 28533/30798\n",
            "Batch 28533 Loss: 0.03050883114337921\n",
            "Epoch 3, Processing batch 28534/30798\n",
            "Batch 28534 Loss: 0.12752094864845276\n",
            "Epoch 3, Processing batch 28535/30798\n",
            "Batch 28535 Loss: 0.22780771553516388\n",
            "Epoch 3, Processing batch 28536/30798\n",
            "Batch 28536 Loss: 0.23599587380886078\n",
            "Epoch 3, Processing batch 28537/30798\n",
            "Batch 28537 Loss: 0.1615734100341797\n",
            "Epoch 3, Processing batch 28538/30798\n",
            "Batch 28538 Loss: 0.3394692540168762\n",
            "Epoch 3, Processing batch 28539/30798\n",
            "Batch 28539 Loss: 0.02868928201496601\n",
            "Epoch 3, Processing batch 28540/30798\n",
            "Batch 28540 Loss: 0.4367907643318176\n",
            "Epoch 3, Processing batch 28541/30798\n",
            "Batch 28541 Loss: 0.04456818103790283\n",
            "Epoch 3, Processing batch 28542/30798\n",
            "Batch 28542 Loss: 2.718979835510254\n",
            "Epoch 3, Processing batch 28543/30798\n",
            "Batch 28543 Loss: 0.20143049955368042\n",
            "Epoch 3, Processing batch 28544/30798\n",
            "Batch 28544 Loss: 1.4624662399291992\n",
            "Epoch 3, Processing batch 28545/30798\n",
            "Batch 28545 Loss: 0.07521386444568634\n",
            "Epoch 3, Processing batch 28546/30798\n",
            "Batch 28546 Loss: 0.06353999674320221\n",
            "Epoch 3, Processing batch 28547/30798\n",
            "Batch 28547 Loss: 0.005305759143084288\n",
            "Epoch 3, Processing batch 28548/30798\n",
            "Batch 28548 Loss: 0.11683449894189835\n",
            "Epoch 3, Processing batch 28549/30798\n",
            "Batch 28549 Loss: 0.2128002643585205\n",
            "Epoch 3, Processing batch 28550/30798\n",
            "Batch 28550 Loss: 0.05858636647462845\n",
            "Epoch 3, Processing batch 28551/30798\n",
            "Batch 28551 Loss: 0.004704862367361784\n",
            "Epoch 3, Processing batch 28552/30798\n",
            "Batch 28552 Loss: 0.012984181754291058\n",
            "Epoch 3, Processing batch 28553/30798\n",
            "Batch 28553 Loss: 0.42400407791137695\n",
            "Epoch 3, Processing batch 28554/30798\n",
            "Batch 28554 Loss: 0.057761624455451965\n",
            "Epoch 3, Processing batch 28555/30798\n",
            "Batch 28555 Loss: 2.081801176071167\n",
            "Epoch 3, Processing batch 28556/30798\n",
            "Batch 28556 Loss: 0.42942339181900024\n",
            "Epoch 3, Processing batch 28557/30798\n",
            "Batch 28557 Loss: 0.059324562549591064\n",
            "Epoch 3, Processing batch 28558/30798\n",
            "Batch 28558 Loss: 0.09356950968503952\n",
            "Epoch 3, Processing batch 28559/30798\n",
            "Batch 28559 Loss: 0.17364855110645294\n",
            "Epoch 3, Processing batch 28560/30798\n",
            "Batch 28560 Loss: 1.270409107208252\n",
            "Epoch 3, Processing batch 28561/30798\n",
            "Batch 28561 Loss: 0.1097940132021904\n",
            "Epoch 3, Processing batch 28562/30798\n",
            "Batch 28562 Loss: 0.6351277828216553\n",
            "Epoch 3, Processing batch 28563/30798\n",
            "Batch 28563 Loss: 0.02087980881333351\n",
            "Epoch 3, Processing batch 28564/30798\n",
            "Batch 28564 Loss: 0.08473968505859375\n",
            "Epoch 3, Processing batch 28565/30798\n",
            "Batch 28565 Loss: 0.006110990419983864\n",
            "Epoch 3, Processing batch 28566/30798\n",
            "Batch 28566 Loss: 0.04653275012969971\n",
            "Epoch 3, Processing batch 28567/30798\n",
            "Batch 28567 Loss: 0.18826019763946533\n",
            "Epoch 3, Processing batch 28568/30798\n",
            "Batch 28568 Loss: 0.24782545864582062\n",
            "Epoch 3, Processing batch 28569/30798\n",
            "Batch 28569 Loss: 0.488136351108551\n",
            "Epoch 3, Processing batch 28570/30798\n",
            "Batch 28570 Loss: 1.546800136566162\n",
            "Epoch 3, Processing batch 28571/30798\n",
            "Batch 28571 Loss: 0.06714692711830139\n",
            "Epoch 3, Processing batch 28572/30798\n",
            "Batch 28572 Loss: 0.8537259101867676\n",
            "Epoch 3, Processing batch 28573/30798\n",
            "Batch 28573 Loss: 0.06485231220722198\n",
            "Epoch 3, Processing batch 28574/30798\n",
            "Batch 28574 Loss: 1.8953834772109985\n",
            "Epoch 3, Processing batch 28575/30798\n",
            "Batch 28575 Loss: 0.009726239368319511\n",
            "Epoch 3, Processing batch 28576/30798\n",
            "Batch 28576 Loss: 0.030707813799381256\n",
            "Epoch 3, Processing batch 28577/30798\n",
            "Batch 28577 Loss: 0.005886295810341835\n",
            "Epoch 3, Processing batch 28578/30798\n",
            "Batch 28578 Loss: 0.06443208456039429\n",
            "Epoch 3, Processing batch 28579/30798\n",
            "Batch 28579 Loss: 0.03575897961854935\n",
            "Epoch 3, Processing batch 28580/30798\n",
            "Batch 28580 Loss: 1.3192651271820068\n",
            "Epoch 3, Processing batch 28581/30798\n",
            "Batch 28581 Loss: 0.1424265056848526\n",
            "Epoch 3, Processing batch 28582/30798\n",
            "Batch 28582 Loss: 0.09077384322881699\n",
            "Epoch 3, Processing batch 28583/30798\n",
            "Batch 28583 Loss: 0.044118672609329224\n",
            "Epoch 3, Processing batch 28584/30798\n",
            "Batch 28584 Loss: 0.009987758472561836\n",
            "Epoch 3, Processing batch 28585/30798\n",
            "Batch 28585 Loss: 0.06065584719181061\n",
            "Epoch 3, Processing batch 28586/30798\n",
            "Batch 28586 Loss: 0.23347394168376923\n",
            "Epoch 3, Processing batch 28587/30798\n",
            "Batch 28587 Loss: 0.09218142181634903\n",
            "Epoch 3, Processing batch 28588/30798\n",
            "Batch 28588 Loss: 1.765991449356079\n",
            "Epoch 3, Processing batch 28589/30798\n",
            "Batch 28589 Loss: 0.0022760878782719374\n",
            "Epoch 3, Processing batch 28590/30798\n",
            "Batch 28590 Loss: 0.03797469660639763\n",
            "Epoch 3, Processing batch 28591/30798\n",
            "Batch 28591 Loss: 0.026731427758932114\n",
            "Epoch 3, Processing batch 28592/30798\n",
            "Batch 28592 Loss: 0.7900908589363098\n",
            "Epoch 3, Processing batch 28593/30798\n",
            "Batch 28593 Loss: 0.004598549101501703\n",
            "Epoch 3, Processing batch 28594/30798\n",
            "Batch 28594 Loss: 0.011189697310328484\n",
            "Epoch 3, Processing batch 28595/30798\n",
            "Batch 28595 Loss: 0.05115243420004845\n",
            "Epoch 3, Processing batch 28596/30798\n",
            "Batch 28596 Loss: 0.09961321949958801\n",
            "Epoch 3, Processing batch 28597/30798\n",
            "Batch 28597 Loss: 0.7272618412971497\n",
            "Epoch 3, Processing batch 28598/30798\n",
            "Batch 28598 Loss: 0.1754002422094345\n",
            "Epoch 3, Processing batch 28599/30798\n",
            "Batch 28599 Loss: 0.055785324424505234\n",
            "Epoch 3, Processing batch 28600/30798\n",
            "Batch 28600 Loss: 0.009266587905585766\n",
            "Epoch 3, Processing batch 28601/30798\n",
            "Batch 28601 Loss: 0.12522079050540924\n",
            "Epoch 3, Processing batch 28602/30798\n",
            "Batch 28602 Loss: 1.6901222467422485\n",
            "Epoch 3, Processing batch 28603/30798\n",
            "Batch 28603 Loss: 0.03713829815387726\n",
            "Epoch 3, Processing batch 28604/30798\n",
            "Batch 28604 Loss: 0.01738547533750534\n",
            "Epoch 3, Processing batch 28605/30798\n",
            "Batch 28605 Loss: 0.006215191446244717\n",
            "Epoch 3, Processing batch 28606/30798\n",
            "Batch 28606 Loss: 0.014506267383694649\n",
            "Epoch 3, Processing batch 28607/30798\n",
            "Batch 28607 Loss: 0.06051070615649223\n",
            "Epoch 3, Processing batch 28608/30798\n",
            "Batch 28608 Loss: 0.09680886566638947\n",
            "Epoch 3, Processing batch 28609/30798\n",
            "Batch 28609 Loss: 0.006581475026905537\n",
            "Epoch 3, Processing batch 28610/30798\n",
            "Batch 28610 Loss: 0.7341519594192505\n",
            "Epoch 3, Processing batch 28611/30798\n",
            "Batch 28611 Loss: 0.10220661759376526\n",
            "Epoch 3, Processing batch 28612/30798\n",
            "Batch 28612 Loss: 0.7421063184738159\n",
            "Epoch 3, Processing batch 28613/30798\n",
            "Batch 28613 Loss: 0.5914936661720276\n",
            "Epoch 3, Processing batch 28614/30798\n",
            "Batch 28614 Loss: 0.28292396664619446\n",
            "Epoch 3, Processing batch 28615/30798\n",
            "Batch 28615 Loss: 0.7028794288635254\n",
            "Epoch 3, Processing batch 28616/30798\n",
            "Batch 28616 Loss: 0.06819290667772293\n",
            "Epoch 3, Processing batch 28617/30798\n",
            "Batch 28617 Loss: 0.01516277901828289\n",
            "Epoch 3, Processing batch 28618/30798\n",
            "Batch 28618 Loss: 0.21993671357631683\n",
            "Epoch 3, Processing batch 28619/30798\n",
            "Batch 28619 Loss: 0.03414473310112953\n",
            "Epoch 3, Processing batch 28620/30798\n",
            "Batch 28620 Loss: 0.18464137613773346\n",
            "Epoch 3, Processing batch 28621/30798\n",
            "Batch 28621 Loss: 0.05731785297393799\n",
            "Epoch 3, Processing batch 28622/30798\n",
            "Batch 28622 Loss: 0.6200811862945557\n",
            "Epoch 3, Processing batch 28623/30798\n",
            "Batch 28623 Loss: 0.003659496083855629\n",
            "Epoch 3, Processing batch 28624/30798\n",
            "Batch 28624 Loss: 0.9756520390510559\n",
            "Epoch 3, Processing batch 28625/30798\n",
            "Batch 28625 Loss: 0.01602916792035103\n",
            "Epoch 3, Processing batch 28626/30798\n",
            "Batch 28626 Loss: 2.735877275466919\n",
            "Epoch 3, Processing batch 28627/30798\n",
            "Batch 28627 Loss: 0.006732642650604248\n",
            "Epoch 3, Processing batch 28628/30798\n",
            "Batch 28628 Loss: 1.1266499757766724\n",
            "Epoch 3, Processing batch 28629/30798\n",
            "Batch 28629 Loss: 0.15451382100582123\n",
            "Epoch 3, Processing batch 28630/30798\n",
            "Batch 28630 Loss: 0.08294066786766052\n",
            "Epoch 3, Processing batch 28631/30798\n",
            "Batch 28631 Loss: 0.9618163704872131\n",
            "Epoch 3, Processing batch 28632/30798\n",
            "Batch 28632 Loss: 0.09791368246078491\n",
            "Epoch 3, Processing batch 28633/30798\n",
            "Batch 28633 Loss: 0.003325254190713167\n",
            "Epoch 3, Processing batch 28634/30798\n",
            "Batch 28634 Loss: 1.1868714094161987\n",
            "Epoch 3, Processing batch 28635/30798\n",
            "Batch 28635 Loss: 0.6720958352088928\n",
            "Epoch 3, Processing batch 28636/30798\n",
            "Batch 28636 Loss: 1.681059718132019\n",
            "Epoch 3, Processing batch 28637/30798\n",
            "Batch 28637 Loss: 0.2162952721118927\n",
            "Epoch 3, Processing batch 28638/30798\n",
            "Batch 28638 Loss: 2.736102819442749\n",
            "Epoch 3, Processing batch 28639/30798\n",
            "Batch 28639 Loss: 0.13449731469154358\n",
            "Epoch 3, Processing batch 28640/30798\n",
            "Batch 28640 Loss: 0.540090799331665\n",
            "Epoch 3, Processing batch 28641/30798\n",
            "Batch 28641 Loss: 0.029306482523679733\n",
            "Epoch 3, Processing batch 28642/30798\n",
            "Batch 28642 Loss: 0.008211965672671795\n",
            "Epoch 3, Processing batch 28643/30798\n",
            "Batch 28643 Loss: 0.3710904121398926\n",
            "Epoch 3, Processing batch 28644/30798\n",
            "Batch 28644 Loss: 0.006247818004339933\n",
            "Epoch 3, Processing batch 28645/30798\n",
            "Batch 28645 Loss: 0.038678981363773346\n",
            "Epoch 3, Processing batch 28646/30798\n",
            "Batch 28646 Loss: 0.0018168360693380237\n",
            "Epoch 3, Processing batch 28647/30798\n",
            "Batch 28647 Loss: 0.4581385850906372\n",
            "Epoch 3, Processing batch 28648/30798\n",
            "Batch 28648 Loss: 0.005489248316735029\n",
            "Epoch 3, Processing batch 28649/30798\n",
            "Batch 28649 Loss: 0.8507367968559265\n",
            "Epoch 3, Processing batch 28650/30798\n",
            "Batch 28650 Loss: 0.006873295642435551\n",
            "Epoch 3, Processing batch 28651/30798\n",
            "Batch 28651 Loss: 0.013967392966151237\n",
            "Epoch 3, Processing batch 28652/30798\n",
            "Batch 28652 Loss: 0.08382824063301086\n",
            "Epoch 3, Processing batch 28653/30798\n",
            "Batch 28653 Loss: 0.03261489421129227\n",
            "Epoch 3, Processing batch 28654/30798\n",
            "Batch 28654 Loss: 0.8771108388900757\n",
            "Epoch 3, Processing batch 28655/30798\n",
            "Batch 28655 Loss: 0.1988307386636734\n",
            "Epoch 3, Processing batch 28656/30798\n",
            "Batch 28656 Loss: 0.0059433672577142715\n",
            "Epoch 3, Processing batch 28657/30798\n",
            "Batch 28657 Loss: 1.4561353921890259\n",
            "Epoch 3, Processing batch 28658/30798\n",
            "Batch 28658 Loss: 0.008397918194532394\n",
            "Epoch 3, Processing batch 28659/30798\n",
            "Batch 28659 Loss: 1.2285082340240479\n",
            "Epoch 3, Processing batch 28660/30798\n",
            "Batch 28660 Loss: 0.16115328669548035\n",
            "Epoch 3, Processing batch 28661/30798\n",
            "Batch 28661 Loss: 0.05261281132698059\n",
            "Epoch 3, Processing batch 28662/30798\n",
            "Batch 28662 Loss: 0.4426473081111908\n",
            "Epoch 3, Processing batch 28663/30798\n",
            "Batch 28663 Loss: 0.38055628538131714\n",
            "Epoch 3, Processing batch 28664/30798\n",
            "Batch 28664 Loss: 0.20573391020298004\n",
            "Epoch 3, Processing batch 28665/30798\n",
            "Batch 28665 Loss: 0.0004584292764775455\n",
            "Epoch 3, Processing batch 28666/30798\n",
            "Batch 28666 Loss: 0.20176272094249725\n",
            "Epoch 3, Processing batch 28667/30798\n",
            "Batch 28667 Loss: 0.0326785109937191\n",
            "Epoch 3, Processing batch 28668/30798\n",
            "Batch 28668 Loss: 0.03335579112172127\n",
            "Epoch 3, Processing batch 28669/30798\n",
            "Batch 28669 Loss: 0.01967570185661316\n",
            "Epoch 3, Processing batch 28670/30798\n",
            "Batch 28670 Loss: 0.1533687263727188\n",
            "Epoch 3, Processing batch 28671/30798\n",
            "Batch 28671 Loss: 0.07708005607128143\n",
            "Epoch 3, Processing batch 28672/30798\n",
            "Batch 28672 Loss: 0.003968243952840567\n",
            "Epoch 3, Processing batch 28673/30798\n",
            "Batch 28673 Loss: 0.18857772648334503\n",
            "Epoch 3, Processing batch 28674/30798\n",
            "Batch 28674 Loss: 0.0658910721540451\n",
            "Epoch 3, Processing batch 28675/30798\n",
            "Batch 28675 Loss: 0.020679641515016556\n",
            "Epoch 3, Processing batch 28676/30798\n",
            "Batch 28676 Loss: 0.008633207529783249\n",
            "Epoch 3, Processing batch 28677/30798\n",
            "Batch 28677 Loss: 0.07644614577293396\n",
            "Epoch 3, Processing batch 28678/30798\n",
            "Batch 28678 Loss: 0.05395231768488884\n",
            "Epoch 3, Processing batch 28679/30798\n",
            "Batch 28679 Loss: 0.19305925071239471\n",
            "Epoch 3, Processing batch 28680/30798\n",
            "Batch 28680 Loss: 0.032553285360336304\n",
            "Epoch 3, Processing batch 28681/30798\n",
            "Batch 28681 Loss: 0.7238984107971191\n",
            "Epoch 3, Processing batch 28682/30798\n",
            "Batch 28682 Loss: 0.21449969708919525\n",
            "Epoch 3, Processing batch 28683/30798\n",
            "Batch 28683 Loss: 0.6130125522613525\n",
            "Epoch 3, Processing batch 28684/30798\n",
            "Batch 28684 Loss: 0.3267885148525238\n",
            "Epoch 3, Processing batch 28685/30798\n",
            "Batch 28685 Loss: 0.24120594561100006\n",
            "Epoch 3, Processing batch 28686/30798\n",
            "Batch 28686 Loss: 0.03811825066804886\n",
            "Epoch 3, Processing batch 28687/30798\n",
            "Batch 28687 Loss: 1.576526403427124\n",
            "Epoch 3, Processing batch 28688/30798\n",
            "Batch 28688 Loss: 0.5728397369384766\n",
            "Epoch 3, Processing batch 28689/30798\n",
            "Batch 28689 Loss: 0.6996376514434814\n",
            "Epoch 3, Processing batch 28690/30798\n",
            "Batch 28690 Loss: 0.17411108314990997\n",
            "Epoch 3, Processing batch 28691/30798\n",
            "Batch 28691 Loss: 0.946410596370697\n",
            "Epoch 3, Processing batch 28692/30798\n",
            "Batch 28692 Loss: 0.02253836765885353\n",
            "Epoch 3, Processing batch 28693/30798\n",
            "Batch 28693 Loss: 0.8068627119064331\n",
            "Epoch 3, Processing batch 28694/30798\n",
            "Batch 28694 Loss: 0.4903802275657654\n",
            "Epoch 3, Processing batch 28695/30798\n",
            "Batch 28695 Loss: 0.006622369401156902\n",
            "Epoch 3, Processing batch 28696/30798\n",
            "Batch 28696 Loss: 0.592120349407196\n",
            "Epoch 3, Processing batch 28697/30798\n",
            "Batch 28697 Loss: 0.07047544419765472\n",
            "Epoch 3, Processing batch 28698/30798\n",
            "Batch 28698 Loss: 0.028990237042307854\n",
            "Epoch 3, Processing batch 28699/30798\n",
            "Batch 28699 Loss: 0.005383508279919624\n",
            "Epoch 3, Processing batch 28700/30798\n",
            "Batch 28700 Loss: 0.01733454130589962\n",
            "Epoch 3, Processing batch 28701/30798\n",
            "Batch 28701 Loss: 0.09117114543914795\n",
            "Epoch 3, Processing batch 28702/30798\n",
            "Batch 28702 Loss: 0.04478392377495766\n",
            "Epoch 3, Processing batch 28703/30798\n",
            "Batch 28703 Loss: 0.7866490483283997\n",
            "Epoch 3, Processing batch 28704/30798\n",
            "Batch 28704 Loss: 0.01744743064045906\n",
            "Epoch 3, Processing batch 28705/30798\n",
            "Batch 28705 Loss: 2.755094289779663\n",
            "Epoch 3, Processing batch 28706/30798\n",
            "Batch 28706 Loss: 0.003551692236214876\n",
            "Epoch 3, Processing batch 28707/30798\n",
            "Batch 28707 Loss: 0.022202370688319206\n",
            "Epoch 3, Processing batch 28708/30798\n",
            "Batch 28708 Loss: 0.05278315395116806\n",
            "Epoch 3, Processing batch 28709/30798\n",
            "Batch 28709 Loss: 0.0038988336455076933\n",
            "Epoch 3, Processing batch 28710/30798\n",
            "Batch 28710 Loss: 2.3298065662384033\n",
            "Epoch 3, Processing batch 28711/30798\n",
            "Batch 28711 Loss: 0.5776992440223694\n",
            "Epoch 3, Processing batch 28712/30798\n",
            "Batch 28712 Loss: 0.2350020408630371\n",
            "Epoch 3, Processing batch 28713/30798\n",
            "Batch 28713 Loss: 0.0806255117058754\n",
            "Epoch 3, Processing batch 28714/30798\n",
            "Batch 28714 Loss: 0.07851063460111618\n",
            "Epoch 3, Processing batch 28715/30798\n",
            "Batch 28715 Loss: 0.975395679473877\n",
            "Epoch 3, Processing batch 28716/30798\n",
            "Batch 28716 Loss: 0.07846757769584656\n",
            "Epoch 3, Processing batch 28717/30798\n",
            "Batch 28717 Loss: 0.25368544459342957\n",
            "Epoch 3, Processing batch 28718/30798\n",
            "Batch 28718 Loss: 1.5620715618133545\n",
            "Epoch 3, Processing batch 28719/30798\n",
            "Batch 28719 Loss: 0.0053992802277207375\n",
            "Epoch 3, Processing batch 28720/30798\n",
            "Batch 28720 Loss: 2.778080701828003\n",
            "Epoch 3, Processing batch 28721/30798\n",
            "Batch 28721 Loss: 0.27863389253616333\n",
            "Epoch 3, Processing batch 28722/30798\n",
            "Batch 28722 Loss: 0.06916234642267227\n",
            "Epoch 3, Processing batch 28723/30798\n",
            "Batch 28723 Loss: 1.3468716144561768\n",
            "Epoch 3, Processing batch 28724/30798\n",
            "Batch 28724 Loss: 0.22385874390602112\n",
            "Epoch 3, Processing batch 28725/30798\n",
            "Batch 28725 Loss: 0.35876986384391785\n",
            "Epoch 3, Processing batch 28726/30798\n",
            "Batch 28726 Loss: 0.6239016056060791\n",
            "Epoch 3, Processing batch 28727/30798\n",
            "Batch 28727 Loss: 0.06136108934879303\n",
            "Epoch 3, Processing batch 28728/30798\n",
            "Batch 28728 Loss: 0.015122292563319206\n",
            "Epoch 3, Processing batch 28729/30798\n",
            "Batch 28729 Loss: 0.12447910755872726\n",
            "Epoch 3, Processing batch 28730/30798\n",
            "Batch 28730 Loss: 1.043169379234314\n",
            "Epoch 3, Processing batch 28731/30798\n",
            "Batch 28731 Loss: 0.6736011505126953\n",
            "Epoch 3, Processing batch 28732/30798\n",
            "Batch 28732 Loss: 0.7874032855033875\n",
            "Epoch 3, Processing batch 28733/30798\n",
            "Batch 28733 Loss: 0.09601082652807236\n",
            "Epoch 3, Processing batch 28734/30798\n",
            "Batch 28734 Loss: 0.30358201265335083\n",
            "Epoch 3, Processing batch 28735/30798\n",
            "Batch 28735 Loss: 0.0872388407588005\n",
            "Epoch 3, Processing batch 28736/30798\n",
            "Batch 28736 Loss: 0.022902201861143112\n",
            "Epoch 3, Processing batch 28737/30798\n",
            "Batch 28737 Loss: 0.027138954028487206\n",
            "Epoch 3, Processing batch 28738/30798\n",
            "Batch 28738 Loss: 0.014189236797392368\n",
            "Epoch 3, Processing batch 28739/30798\n",
            "Batch 28739 Loss: 0.01864025555551052\n",
            "Epoch 3, Processing batch 28740/30798\n",
            "Batch 28740 Loss: 0.995024561882019\n",
            "Epoch 3, Processing batch 28741/30798\n",
            "Batch 28741 Loss: 0.03281416743993759\n",
            "Epoch 3, Processing batch 28742/30798\n",
            "Batch 28742 Loss: 1.5609402656555176\n",
            "Epoch 3, Processing batch 28743/30798\n",
            "Batch 28743 Loss: 0.01432882808148861\n",
            "Epoch 3, Processing batch 28744/30798\n",
            "Batch 28744 Loss: 0.09889708459377289\n",
            "Epoch 3, Processing batch 28745/30798\n",
            "Batch 28745 Loss: 0.19020295143127441\n",
            "Epoch 3, Processing batch 28746/30798\n",
            "Batch 28746 Loss: 1.5888317823410034\n",
            "Epoch 3, Processing batch 28747/30798\n",
            "Batch 28747 Loss: 0.005208176095038652\n",
            "Epoch 3, Processing batch 28748/30798\n",
            "Batch 28748 Loss: 0.57470703125\n",
            "Epoch 3, Processing batch 28749/30798\n",
            "Batch 28749 Loss: 0.3768526613712311\n",
            "Epoch 3, Processing batch 28750/30798\n",
            "Batch 28750 Loss: 0.3210582137107849\n",
            "Epoch 3, Processing batch 28751/30798\n",
            "Batch 28751 Loss: 0.662798285484314\n",
            "Epoch 3, Processing batch 28752/30798\n",
            "Batch 28752 Loss: 0.002643571002408862\n",
            "Epoch 3, Processing batch 28753/30798\n",
            "Batch 28753 Loss: 0.08304883539676666\n",
            "Epoch 3, Processing batch 28754/30798\n",
            "Batch 28754 Loss: 0.24091249704360962\n",
            "Epoch 3, Processing batch 28755/30798\n",
            "Batch 28755 Loss: 0.037115249782800674\n",
            "Epoch 3, Processing batch 28756/30798\n",
            "Batch 28756 Loss: 0.0020909211598336697\n",
            "Epoch 3, Processing batch 28757/30798\n",
            "Batch 28757 Loss: 0.060087863355875015\n",
            "Epoch 3, Processing batch 28758/30798\n",
            "Batch 28758 Loss: 0.1387999951839447\n",
            "Epoch 3, Processing batch 28759/30798\n",
            "Batch 28759 Loss: 0.26052728295326233\n",
            "Epoch 3, Processing batch 28760/30798\n",
            "Batch 28760 Loss: 1.509899616241455\n",
            "Epoch 3, Processing batch 28761/30798\n",
            "Batch 28761 Loss: 0.3084946274757385\n",
            "Epoch 3, Processing batch 28762/30798\n",
            "Batch 28762 Loss: 0.01939575932919979\n",
            "Epoch 3, Processing batch 28763/30798\n",
            "Batch 28763 Loss: 0.004117327742278576\n",
            "Epoch 3, Processing batch 28764/30798\n",
            "Batch 28764 Loss: 0.3419531583786011\n",
            "Epoch 3, Processing batch 28765/30798\n",
            "Batch 28765 Loss: 0.003344923257827759\n",
            "Epoch 3, Processing batch 28766/30798\n",
            "Batch 28766 Loss: 0.06665363162755966\n",
            "Epoch 3, Processing batch 28767/30798\n",
            "Batch 28767 Loss: 0.008710663765668869\n",
            "Epoch 3, Processing batch 28768/30798\n",
            "Batch 28768 Loss: 0.06647124886512756\n",
            "Epoch 3, Processing batch 28769/30798\n",
            "Batch 28769 Loss: 0.013859924860298634\n",
            "Epoch 3, Processing batch 28770/30798\n",
            "Batch 28770 Loss: 0.0026804725639522076\n",
            "Epoch 3, Processing batch 28771/30798\n",
            "Batch 28771 Loss: 0.03616410493850708\n",
            "Epoch 3, Processing batch 28772/30798\n",
            "Batch 28772 Loss: 0.0905194953083992\n",
            "Epoch 3, Processing batch 28773/30798\n",
            "Batch 28773 Loss: 1.839595079421997\n",
            "Epoch 3, Processing batch 28774/30798\n",
            "Batch 28774 Loss: 0.044866930693387985\n",
            "Epoch 3, Processing batch 28775/30798\n",
            "Batch 28775 Loss: 0.11899758130311966\n",
            "Epoch 3, Processing batch 28776/30798\n",
            "Batch 28776 Loss: 1.536460518836975\n",
            "Epoch 3, Processing batch 28777/30798\n",
            "Batch 28777 Loss: 0.05540342256426811\n",
            "Epoch 3, Processing batch 28778/30798\n",
            "Batch 28778 Loss: 0.06900879740715027\n",
            "Epoch 3, Processing batch 28779/30798\n",
            "Batch 28779 Loss: 0.02722904086112976\n",
            "Epoch 3, Processing batch 28780/30798\n",
            "Batch 28780 Loss: 1.2663273811340332\n",
            "Epoch 3, Processing batch 28781/30798\n",
            "Batch 28781 Loss: 0.01454138197004795\n",
            "Epoch 3, Processing batch 28782/30798\n",
            "Batch 28782 Loss: 0.004206594545394182\n",
            "Epoch 3, Processing batch 28783/30798\n",
            "Batch 28783 Loss: 0.1888456493616104\n",
            "Epoch 3, Processing batch 28784/30798\n",
            "Batch 28784 Loss: 0.4963548183441162\n",
            "Epoch 3, Processing batch 28785/30798\n",
            "Batch 28785 Loss: 0.3717857897281647\n",
            "Epoch 3, Processing batch 28786/30798\n",
            "Batch 28786 Loss: 0.0828506350517273\n",
            "Epoch 3, Processing batch 28787/30798\n",
            "Batch 28787 Loss: 0.06482277810573578\n",
            "Epoch 3, Processing batch 28788/30798\n",
            "Batch 28788 Loss: 0.2707272469997406\n",
            "Epoch 3, Processing batch 28789/30798\n",
            "Batch 28789 Loss: 0.013718951493501663\n",
            "Epoch 3, Processing batch 28790/30798\n",
            "Batch 28790 Loss: 2.187450647354126\n",
            "Epoch 3, Processing batch 28791/30798\n",
            "Batch 28791 Loss: 0.3339011073112488\n",
            "Epoch 3, Processing batch 28792/30798\n",
            "Batch 28792 Loss: 0.11137237399816513\n",
            "Epoch 3, Processing batch 28793/30798\n",
            "Batch 28793 Loss: 0.8199191093444824\n",
            "Epoch 3, Processing batch 28794/30798\n",
            "Batch 28794 Loss: 0.012084588408470154\n",
            "Epoch 3, Processing batch 28795/30798\n",
            "Batch 28795 Loss: 0.00725453719496727\n",
            "Epoch 3, Processing batch 28796/30798\n",
            "Batch 28796 Loss: 0.006724253762513399\n",
            "Epoch 3, Processing batch 28797/30798\n",
            "Batch 28797 Loss: 0.26708346605300903\n",
            "Epoch 3, Processing batch 28798/30798\n",
            "Batch 28798 Loss: 0.01940702646970749\n",
            "Epoch 3, Processing batch 28799/30798\n",
            "Batch 28799 Loss: 0.06451450288295746\n",
            "Epoch 3, Processing batch 28800/30798\n",
            "Batch 28800 Loss: 0.0016433753771707416\n",
            "Epoch 3, Processing batch 28801/30798\n",
            "Batch 28801 Loss: 0.6748677492141724\n",
            "Epoch 3, Processing batch 28802/30798\n",
            "Batch 28802 Loss: 0.01277115661650896\n",
            "Epoch 3, Processing batch 28803/30798\n",
            "Batch 28803 Loss: 0.1448649913072586\n",
            "Epoch 3, Processing batch 28804/30798\n",
            "Batch 28804 Loss: 0.09758484363555908\n",
            "Epoch 3, Processing batch 28805/30798\n",
            "Batch 28805 Loss: 0.33611008524894714\n",
            "Epoch 3, Processing batch 28806/30798\n",
            "Batch 28806 Loss: 0.016534611582756042\n",
            "Epoch 3, Processing batch 28807/30798\n",
            "Batch 28807 Loss: 0.03533530607819557\n",
            "Epoch 3, Processing batch 28808/30798\n",
            "Batch 28808 Loss: 0.08304503560066223\n",
            "Epoch 3, Processing batch 28809/30798\n",
            "Batch 28809 Loss: 0.10193601995706558\n",
            "Epoch 3, Processing batch 28810/30798\n",
            "Batch 28810 Loss: 2.6520419120788574\n",
            "Epoch 3, Processing batch 28811/30798\n",
            "Batch 28811 Loss: 0.06896628439426422\n",
            "Epoch 3, Processing batch 28812/30798\n",
            "Batch 28812 Loss: 0.09745360910892487\n",
            "Epoch 3, Processing batch 28813/30798\n",
            "Batch 28813 Loss: 0.49608170986175537\n",
            "Epoch 3, Processing batch 28814/30798\n",
            "Batch 28814 Loss: 0.13901910185813904\n",
            "Epoch 3, Processing batch 28815/30798\n",
            "Batch 28815 Loss: 0.2333475947380066\n",
            "Epoch 3, Processing batch 28816/30798\n",
            "Batch 28816 Loss: 0.012596409767866135\n",
            "Epoch 3, Processing batch 28817/30798\n",
            "Batch 28817 Loss: 0.007231272291392088\n",
            "Epoch 3, Processing batch 28818/30798\n",
            "Batch 28818 Loss: 0.12324309349060059\n",
            "Epoch 3, Processing batch 28819/30798\n",
            "Batch 28819 Loss: 0.07508955895900726\n",
            "Epoch 3, Processing batch 28820/30798\n",
            "Batch 28820 Loss: 0.47656428813934326\n",
            "Epoch 3, Processing batch 28821/30798\n",
            "Batch 28821 Loss: 0.5068402886390686\n",
            "Epoch 3, Processing batch 28822/30798\n",
            "Batch 28822 Loss: 0.0025730181951075792\n",
            "Epoch 3, Processing batch 28823/30798\n",
            "Batch 28823 Loss: 0.008675345219671726\n",
            "Epoch 3, Processing batch 28824/30798\n",
            "Batch 28824 Loss: 0.009103245101869106\n",
            "Epoch 3, Processing batch 28825/30798\n",
            "Batch 28825 Loss: 0.031830109655857086\n",
            "Epoch 3, Processing batch 28826/30798\n",
            "Batch 28826 Loss: 1.1700494289398193\n",
            "Epoch 3, Processing batch 28827/30798\n",
            "Batch 28827 Loss: 0.008990714326500893\n",
            "Epoch 3, Processing batch 28828/30798\n",
            "Batch 28828 Loss: 0.8010640144348145\n",
            "Epoch 3, Processing batch 28829/30798\n",
            "Batch 28829 Loss: 0.006322546396404505\n",
            "Epoch 3, Processing batch 28830/30798\n",
            "Batch 28830 Loss: 0.980767548084259\n",
            "Epoch 3, Processing batch 28831/30798\n",
            "Batch 28831 Loss: 3.93477725982666\n",
            "Epoch 3, Processing batch 28832/30798\n",
            "Batch 28832 Loss: 0.7466922402381897\n",
            "Epoch 3, Processing batch 28833/30798\n",
            "Batch 28833 Loss: 0.3658544421195984\n",
            "Epoch 3, Processing batch 28834/30798\n",
            "Batch 28834 Loss: 0.3113395869731903\n",
            "Epoch 3, Processing batch 28835/30798\n",
            "Batch 28835 Loss: 1.0271422863006592\n",
            "Epoch 3, Processing batch 28836/30798\n",
            "Batch 28836 Loss: 0.029397334903478622\n",
            "Epoch 3, Processing batch 28837/30798\n",
            "Batch 28837 Loss: 0.015425655990839005\n",
            "Epoch 3, Processing batch 28838/30798\n",
            "Batch 28838 Loss: 0.029114743694663048\n",
            "Epoch 3, Processing batch 28839/30798\n",
            "Batch 28839 Loss: 0.574379563331604\n",
            "Epoch 3, Processing batch 28840/30798\n",
            "Batch 28840 Loss: 0.9931824207305908\n",
            "Epoch 3, Processing batch 28841/30798\n",
            "Batch 28841 Loss: 0.21583200991153717\n",
            "Epoch 3, Processing batch 28842/30798\n",
            "Batch 28842 Loss: 0.023875441402196884\n",
            "Epoch 3, Processing batch 28843/30798\n",
            "Batch 28843 Loss: 1.3287403583526611\n",
            "Epoch 3, Processing batch 28844/30798\n",
            "Batch 28844 Loss: 0.5620756149291992\n",
            "Epoch 3, Processing batch 28845/30798\n",
            "Batch 28845 Loss: 2.1108481884002686\n",
            "Epoch 3, Processing batch 28846/30798\n",
            "Batch 28846 Loss: 0.038206797093153\n",
            "Epoch 3, Processing batch 28847/30798\n",
            "Batch 28847 Loss: 0.08410105854272842\n",
            "Epoch 3, Processing batch 28848/30798\n",
            "Batch 28848 Loss: 0.145459845662117\n",
            "Epoch 3, Processing batch 28849/30798\n",
            "Batch 28849 Loss: 0.21790441870689392\n",
            "Epoch 3, Processing batch 28850/30798\n",
            "Batch 28850 Loss: 0.04097606986761093\n",
            "Epoch 3, Processing batch 28851/30798\n",
            "Batch 28851 Loss: 0.19716913998126984\n",
            "Epoch 3, Processing batch 28852/30798\n",
            "Batch 28852 Loss: 0.364081472158432\n",
            "Epoch 3, Processing batch 28853/30798\n",
            "Batch 28853 Loss: 0.7594017386436462\n",
            "Epoch 3, Processing batch 28854/30798\n",
            "Batch 28854 Loss: 0.012571561150252819\n",
            "Epoch 3, Processing batch 28855/30798\n",
            "Batch 28855 Loss: 0.1553119421005249\n",
            "Epoch 3, Processing batch 28856/30798\n",
            "Batch 28856 Loss: 0.0024181529879570007\n",
            "Epoch 3, Processing batch 28857/30798\n",
            "Batch 28857 Loss: 0.30077672004699707\n",
            "Epoch 3, Processing batch 28858/30798\n",
            "Batch 28858 Loss: 1.6824235916137695\n",
            "Epoch 3, Processing batch 28859/30798\n",
            "Batch 28859 Loss: 0.007854309864342213\n",
            "Epoch 3, Processing batch 28860/30798\n",
            "Batch 28860 Loss: 0.007505080197006464\n",
            "Epoch 3, Processing batch 28861/30798\n",
            "Batch 28861 Loss: 0.1839999258518219\n",
            "Epoch 3, Processing batch 28862/30798\n",
            "Batch 28862 Loss: 0.0016039456240832806\n",
            "Epoch 3, Processing batch 28863/30798\n",
            "Batch 28863 Loss: 0.081957146525383\n",
            "Epoch 3, Processing batch 28864/30798\n",
            "Batch 28864 Loss: 0.14444994926452637\n",
            "Epoch 3, Processing batch 28865/30798\n",
            "Batch 28865 Loss: 0.09691651910543442\n",
            "Epoch 3, Processing batch 28866/30798\n",
            "Batch 28866 Loss: 0.06828641146421432\n",
            "Epoch 3, Processing batch 28867/30798\n",
            "Batch 28867 Loss: 1.864324927330017\n",
            "Epoch 3, Processing batch 28868/30798\n",
            "Batch 28868 Loss: 2.453735113143921\n",
            "Epoch 3, Processing batch 28869/30798\n",
            "Batch 28869 Loss: 0.17459158599376678\n",
            "Epoch 3, Processing batch 28870/30798\n",
            "Batch 28870 Loss: 0.053724661469459534\n",
            "Epoch 3, Processing batch 28871/30798\n",
            "Batch 28871 Loss: 0.23568521440029144\n",
            "Epoch 3, Processing batch 28872/30798\n",
            "Batch 28872 Loss: 0.1165655329823494\n",
            "Epoch 3, Processing batch 28873/30798\n",
            "Batch 28873 Loss: 0.030708199366927147\n",
            "Epoch 3, Processing batch 28874/30798\n",
            "Batch 28874 Loss: 0.47141051292419434\n",
            "Epoch 3, Processing batch 28875/30798\n",
            "Batch 28875 Loss: 0.29082632064819336\n",
            "Epoch 3, Processing batch 28876/30798\n",
            "Batch 28876 Loss: 0.09388776868581772\n",
            "Epoch 3, Processing batch 28877/30798\n",
            "Batch 28877 Loss: 0.4347638189792633\n",
            "Epoch 3, Processing batch 28878/30798\n",
            "Batch 28878 Loss: 1.3730149269104004\n",
            "Epoch 3, Processing batch 28879/30798\n",
            "Batch 28879 Loss: 0.557446300983429\n",
            "Epoch 3, Processing batch 28880/30798\n",
            "Batch 28880 Loss: 1.319981336593628\n",
            "Epoch 3, Processing batch 28881/30798\n",
            "Batch 28881 Loss: 0.5817713737487793\n",
            "Epoch 3, Processing batch 28882/30798\n",
            "Batch 28882 Loss: 0.38342002034187317\n",
            "Epoch 3, Processing batch 28883/30798\n",
            "Batch 28883 Loss: 0.689102828502655\n",
            "Epoch 3, Processing batch 28884/30798\n",
            "Batch 28884 Loss: 0.020040446892380714\n",
            "Epoch 3, Processing batch 28885/30798\n",
            "Batch 28885 Loss: 0.037889283150434494\n",
            "Epoch 3, Processing batch 28886/30798\n",
            "Batch 28886 Loss: 1.0414636135101318\n",
            "Epoch 3, Processing batch 28887/30798\n",
            "Batch 28887 Loss: 0.04398758336901665\n",
            "Epoch 3, Processing batch 28888/30798\n",
            "Batch 28888 Loss: 1.037174105644226\n",
            "Epoch 3, Processing batch 28889/30798\n",
            "Batch 28889 Loss: 0.010057289153337479\n",
            "Epoch 3, Processing batch 28890/30798\n",
            "Batch 28890 Loss: 0.28175097703933716\n",
            "Epoch 3, Processing batch 28891/30798\n",
            "Batch 28891 Loss: 0.5916878581047058\n",
            "Epoch 3, Processing batch 28892/30798\n",
            "Batch 28892 Loss: 0.0070514739491045475\n",
            "Epoch 3, Processing batch 28893/30798\n",
            "Batch 28893 Loss: 0.22061903774738312\n",
            "Epoch 3, Processing batch 28894/30798\n",
            "Batch 28894 Loss: 0.010393240489065647\n",
            "Epoch 3, Processing batch 28895/30798\n",
            "Batch 28895 Loss: 0.05026194453239441\n",
            "Epoch 3, Processing batch 28896/30798\n",
            "Batch 28896 Loss: 1.5054088830947876\n",
            "Epoch 3, Processing batch 28897/30798\n",
            "Batch 28897 Loss: 0.20335949957370758\n",
            "Epoch 3, Processing batch 28898/30798\n",
            "Batch 28898 Loss: 2.0312769412994385\n",
            "Epoch 3, Processing batch 28899/30798\n",
            "Batch 28899 Loss: 0.09083443135023117\n",
            "Epoch 3, Processing batch 28900/30798\n",
            "Batch 28900 Loss: 0.02505829557776451\n",
            "Epoch 3, Processing batch 28901/30798\n",
            "Batch 28901 Loss: 0.20279881358146667\n",
            "Epoch 3, Processing batch 28902/30798\n",
            "Batch 28902 Loss: 0.01825152151286602\n",
            "Epoch 3, Processing batch 28903/30798\n",
            "Batch 28903 Loss: 0.23847408592700958\n",
            "Epoch 3, Processing batch 28904/30798\n",
            "Batch 28904 Loss: 0.011192337609827518\n",
            "Epoch 3, Processing batch 28905/30798\n",
            "Batch 28905 Loss: 0.21996283531188965\n",
            "Epoch 3, Processing batch 28906/30798\n",
            "Batch 28906 Loss: 0.006239514797925949\n",
            "Epoch 3, Processing batch 28907/30798\n",
            "Batch 28907 Loss: 0.004918558523058891\n",
            "Epoch 3, Processing batch 28908/30798\n",
            "Batch 28908 Loss: 0.05924301967024803\n",
            "Epoch 3, Processing batch 28909/30798\n",
            "Batch 28909 Loss: 0.0036775334738194942\n",
            "Epoch 3, Processing batch 28910/30798\n",
            "Batch 28910 Loss: 0.044607553631067276\n",
            "Epoch 3, Processing batch 28911/30798\n",
            "Batch 28911 Loss: 0.2635332942008972\n",
            "Epoch 3, Processing batch 28912/30798\n",
            "Batch 28912 Loss: 0.03165971487760544\n",
            "Epoch 3, Processing batch 28913/30798\n",
            "Batch 28913 Loss: 0.054146647453308105\n",
            "Epoch 3, Processing batch 28914/30798\n",
            "Batch 28914 Loss: 0.09159939736127853\n",
            "Epoch 3, Processing batch 28915/30798\n",
            "Batch 28915 Loss: 0.07233886420726776\n",
            "Epoch 3, Processing batch 28916/30798\n",
            "Batch 28916 Loss: 0.8277024030685425\n",
            "Epoch 3, Processing batch 28917/30798\n",
            "Batch 28917 Loss: 0.6191096901893616\n",
            "Epoch 3, Processing batch 28918/30798\n",
            "Batch 28918 Loss: 0.5719532370567322\n",
            "Epoch 3, Processing batch 28919/30798\n",
            "Batch 28919 Loss: 1.0499130487442017\n",
            "Epoch 3, Processing batch 28920/30798\n",
            "Batch 28920 Loss: 0.17885953187942505\n",
            "Epoch 3, Processing batch 28921/30798\n",
            "Batch 28921 Loss: 2.3534903526306152\n",
            "Epoch 3, Processing batch 28922/30798\n",
            "Batch 28922 Loss: 0.10562962293624878\n",
            "Epoch 3, Processing batch 28923/30798\n",
            "Batch 28923 Loss: 1.0819154977798462\n",
            "Epoch 3, Processing batch 28924/30798\n",
            "Batch 28924 Loss: 0.08115292340517044\n",
            "Epoch 3, Processing batch 28925/30798\n",
            "Batch 28925 Loss: 0.012532738968729973\n",
            "Epoch 3, Processing batch 28926/30798\n",
            "Batch 28926 Loss: 0.0016757968114688993\n",
            "Epoch 3, Processing batch 28927/30798\n",
            "Batch 28927 Loss: 0.05794401466846466\n",
            "Epoch 3, Processing batch 28928/30798\n",
            "Batch 28928 Loss: 0.04813510552048683\n",
            "Epoch 3, Processing batch 28929/30798\n",
            "Batch 28929 Loss: 1.6706781387329102\n",
            "Epoch 3, Processing batch 28930/30798\n",
            "Batch 28930 Loss: 1.7299771308898926\n",
            "Epoch 3, Processing batch 28931/30798\n",
            "Batch 28931 Loss: 0.02078039012849331\n",
            "Epoch 3, Processing batch 28932/30798\n",
            "Batch 28932 Loss: 0.002708872314542532\n",
            "Epoch 3, Processing batch 28933/30798\n",
            "Batch 28933 Loss: 0.4396588206291199\n",
            "Epoch 3, Processing batch 28934/30798\n",
            "Batch 28934 Loss: 1.0947341918945312\n",
            "Epoch 3, Processing batch 28935/30798\n",
            "Batch 28935 Loss: 0.2563464641571045\n",
            "Epoch 3, Processing batch 28936/30798\n",
            "Batch 28936 Loss: 1.1755675077438354\n",
            "Epoch 3, Processing batch 28937/30798\n",
            "Batch 28937 Loss: 1.2691538333892822\n",
            "Epoch 3, Processing batch 28938/30798\n",
            "Batch 28938 Loss: 0.03050628863275051\n",
            "Epoch 3, Processing batch 28939/30798\n",
            "Batch 28939 Loss: 0.015434016473591328\n",
            "Epoch 3, Processing batch 28940/30798\n",
            "Batch 28940 Loss: 0.08965840190649033\n",
            "Epoch 3, Processing batch 28941/30798\n",
            "Batch 28941 Loss: 0.24629952013492584\n",
            "Epoch 3, Processing batch 28942/30798\n",
            "Batch 28942 Loss: 0.7753297090530396\n",
            "Epoch 3, Processing batch 28943/30798\n",
            "Batch 28943 Loss: 2.358168125152588\n",
            "Epoch 3, Processing batch 28944/30798\n",
            "Batch 28944 Loss: 0.7324569821357727\n",
            "Epoch 3, Processing batch 28945/30798\n",
            "Batch 28945 Loss: 0.12506622076034546\n",
            "Epoch 3, Processing batch 28946/30798\n",
            "Batch 28946 Loss: 0.8087866902351379\n",
            "Epoch 3, Processing batch 28947/30798\n",
            "Batch 28947 Loss: 0.009642064571380615\n",
            "Epoch 3, Processing batch 28948/30798\n",
            "Batch 28948 Loss: 0.7101348638534546\n",
            "Epoch 3, Processing batch 28949/30798\n",
            "Batch 28949 Loss: 0.005014737602323294\n",
            "Epoch 3, Processing batch 28950/30798\n",
            "Batch 28950 Loss: 0.7863084077835083\n",
            "Epoch 3, Processing batch 28951/30798\n",
            "Batch 28951 Loss: 0.0677444189786911\n",
            "Epoch 3, Processing batch 28952/30798\n",
            "Batch 28952 Loss: 0.026240870356559753\n",
            "Epoch 3, Processing batch 28953/30798\n",
            "Batch 28953 Loss: 0.2748371362686157\n",
            "Epoch 3, Processing batch 28954/30798\n",
            "Batch 28954 Loss: 0.03776722773909569\n",
            "Epoch 3, Processing batch 28955/30798\n",
            "Batch 28955 Loss: 0.006030148360878229\n",
            "Epoch 3, Processing batch 28956/30798\n",
            "Batch 28956 Loss: 0.17168071866035461\n",
            "Epoch 3, Processing batch 28957/30798\n",
            "Batch 28957 Loss: 0.12730324268341064\n",
            "Epoch 3, Processing batch 28958/30798\n",
            "Batch 28958 Loss: 0.026112020015716553\n",
            "Epoch 3, Processing batch 28959/30798\n",
            "Batch 28959 Loss: 0.43019697070121765\n",
            "Epoch 3, Processing batch 28960/30798\n",
            "Batch 28960 Loss: 0.04788365215063095\n",
            "Epoch 3, Processing batch 28961/30798\n",
            "Batch 28961 Loss: 0.4189293384552002\n",
            "Epoch 3, Processing batch 28962/30798\n",
            "Batch 28962 Loss: 0.00986090861260891\n",
            "Epoch 3, Processing batch 28963/30798\n",
            "Batch 28963 Loss: 0.04136596620082855\n",
            "Epoch 3, Processing batch 28964/30798\n",
            "Batch 28964 Loss: 0.4841592013835907\n",
            "Epoch 3, Processing batch 28965/30798\n",
            "Batch 28965 Loss: 0.1416100710630417\n",
            "Epoch 3, Processing batch 28966/30798\n",
            "Batch 28966 Loss: 0.016375649720430374\n",
            "Epoch 3, Processing batch 28967/30798\n",
            "Batch 28967 Loss: 0.023062309250235558\n",
            "Epoch 3, Processing batch 28968/30798\n",
            "Batch 28968 Loss: 0.6372449994087219\n",
            "Epoch 3, Processing batch 28969/30798\n",
            "Batch 28969 Loss: 0.11589384078979492\n",
            "Epoch 3, Processing batch 28970/30798\n",
            "Batch 28970 Loss: 1.1992932558059692\n",
            "Epoch 3, Processing batch 28971/30798\n",
            "Batch 28971 Loss: 1.8038032054901123\n",
            "Epoch 3, Processing batch 28972/30798\n",
            "Batch 28972 Loss: 0.5954247117042542\n",
            "Epoch 3, Processing batch 28973/30798\n",
            "Batch 28973 Loss: 0.23028220236301422\n",
            "Epoch 3, Processing batch 28974/30798\n",
            "Batch 28974 Loss: 0.14178447425365448\n",
            "Epoch 3, Processing batch 28975/30798\n",
            "Batch 28975 Loss: 0.6175366044044495\n",
            "Epoch 3, Processing batch 28976/30798\n",
            "Batch 28976 Loss: 0.22640667855739594\n",
            "Epoch 3, Processing batch 28977/30798\n",
            "Batch 28977 Loss: 0.019900750368833542\n",
            "Epoch 3, Processing batch 28978/30798\n",
            "Batch 28978 Loss: 0.05541466549038887\n",
            "Epoch 3, Processing batch 28979/30798\n",
            "Batch 28979 Loss: 0.059299442917108536\n",
            "Epoch 3, Processing batch 28980/30798\n",
            "Batch 28980 Loss: 0.03376800939440727\n",
            "Epoch 3, Processing batch 28981/30798\n",
            "Batch 28981 Loss: 0.10344021767377853\n",
            "Epoch 3, Processing batch 28982/30798\n",
            "Batch 28982 Loss: 0.10470180958509445\n",
            "Epoch 3, Processing batch 28983/30798\n",
            "Batch 28983 Loss: 0.11502287536859512\n",
            "Epoch 3, Processing batch 28984/30798\n",
            "Batch 28984 Loss: 0.410671204328537\n",
            "Epoch 3, Processing batch 28985/30798\n",
            "Batch 28985 Loss: 0.0038989288732409477\n",
            "Epoch 3, Processing batch 28986/30798\n",
            "Batch 28986 Loss: 0.14845111966133118\n",
            "Epoch 3, Processing batch 28987/30798\n",
            "Batch 28987 Loss: 0.6412810683250427\n",
            "Epoch 3, Processing batch 28988/30798\n",
            "Batch 28988 Loss: 0.01488442998379469\n",
            "Epoch 3, Processing batch 28989/30798\n",
            "Batch 28989 Loss: 0.999505877494812\n",
            "Epoch 3, Processing batch 28990/30798\n",
            "Batch 28990 Loss: 0.017977116629481316\n",
            "Epoch 3, Processing batch 28991/30798\n",
            "Batch 28991 Loss: 0.8860989809036255\n",
            "Epoch 3, Processing batch 28992/30798\n",
            "Batch 28992 Loss: 0.0746319591999054\n",
            "Epoch 3, Processing batch 28993/30798\n",
            "Batch 28993 Loss: 0.13939809799194336\n",
            "Epoch 3, Processing batch 28994/30798\n",
            "Batch 28994 Loss: 0.00524295074865222\n",
            "Epoch 3, Processing batch 28995/30798\n",
            "Batch 28995 Loss: 0.3703940510749817\n",
            "Epoch 3, Processing batch 28996/30798\n",
            "Batch 28996 Loss: 0.008516166359186172\n",
            "Epoch 3, Processing batch 28997/30798\n",
            "Batch 28997 Loss: 0.046022336930036545\n",
            "Epoch 3, Processing batch 28998/30798\n",
            "Batch 28998 Loss: 0.09826105087995529\n",
            "Epoch 3, Processing batch 28999/30798\n",
            "Batch 28999 Loss: 0.012362515553832054\n",
            "Epoch 3, Processing batch 29000/30798\n",
            "Batch 29000 Loss: 0.18590578436851501\n",
            "Epoch 3, Processing batch 29001/30798\n",
            "Batch 29001 Loss: 1.3428678512573242\n",
            "Epoch 3, Processing batch 29002/30798\n",
            "Batch 29002 Loss: 0.03900478407740593\n",
            "Epoch 3, Processing batch 29003/30798\n",
            "Batch 29003 Loss: 1.130348563194275\n",
            "Epoch 3, Processing batch 29004/30798\n",
            "Batch 29004 Loss: 0.0872228741645813\n",
            "Epoch 3, Processing batch 29005/30798\n",
            "Batch 29005 Loss: 1.1199966669082642\n",
            "Epoch 3, Processing batch 29006/30798\n",
            "Batch 29006 Loss: 0.00756780244410038\n",
            "Epoch 3, Processing batch 29007/30798\n",
            "Batch 29007 Loss: 0.07407455891370773\n",
            "Epoch 3, Processing batch 29008/30798\n",
            "Batch 29008 Loss: 0.05088828131556511\n",
            "Epoch 3, Processing batch 29009/30798\n",
            "Batch 29009 Loss: 0.05395082011818886\n",
            "Epoch 3, Processing batch 29010/30798\n",
            "Batch 29010 Loss: 0.889121413230896\n",
            "Epoch 3, Processing batch 29011/30798\n",
            "Batch 29011 Loss: 0.11303018033504486\n",
            "Epoch 3, Processing batch 29012/30798\n",
            "Batch 29012 Loss: 0.022523444145917892\n",
            "Epoch 3, Processing batch 29013/30798\n",
            "Batch 29013 Loss: 0.14194360375404358\n",
            "Epoch 3, Processing batch 29014/30798\n",
            "Batch 29014 Loss: 0.7619580030441284\n",
            "Epoch 3, Processing batch 29015/30798\n",
            "Batch 29015 Loss: 0.487546443939209\n",
            "Epoch 3, Processing batch 29016/30798\n",
            "Batch 29016 Loss: 0.5428598523139954\n",
            "Epoch 3, Processing batch 29017/30798\n",
            "Batch 29017 Loss: 0.01107080653309822\n",
            "Epoch 3, Processing batch 29018/30798\n",
            "Batch 29018 Loss: 0.6442716121673584\n",
            "Epoch 3, Processing batch 29019/30798\n",
            "Batch 29019 Loss: 0.04323245957493782\n",
            "Epoch 3, Processing batch 29020/30798\n",
            "Batch 29020 Loss: 0.3182309865951538\n",
            "Epoch 3, Processing batch 29021/30798\n",
            "Batch 29021 Loss: 0.5349502563476562\n",
            "Epoch 3, Processing batch 29022/30798\n",
            "Batch 29022 Loss: 0.0009389271726831794\n",
            "Epoch 3, Processing batch 29023/30798\n",
            "Batch 29023 Loss: 0.023085258901119232\n",
            "Epoch 3, Processing batch 29024/30798\n",
            "Batch 29024 Loss: 0.14922451972961426\n",
            "Epoch 3, Processing batch 29025/30798\n",
            "Batch 29025 Loss: 0.06443440169095993\n",
            "Epoch 3, Processing batch 29026/30798\n",
            "Batch 29026 Loss: 0.007444823160767555\n",
            "Epoch 3, Processing batch 29027/30798\n",
            "Batch 29027 Loss: 0.7401317358016968\n",
            "Epoch 3, Processing batch 29028/30798\n",
            "Batch 29028 Loss: 0.14864128828048706\n",
            "Epoch 3, Processing batch 29029/30798\n",
            "Batch 29029 Loss: 0.7827161550521851\n",
            "Epoch 3, Processing batch 29030/30798\n",
            "Batch 29030 Loss: 0.027234263718128204\n",
            "Epoch 3, Processing batch 29031/30798\n",
            "Batch 29031 Loss: 1.3740959167480469\n",
            "Epoch 3, Processing batch 29032/30798\n",
            "Batch 29032 Loss: 0.1135396808385849\n",
            "Epoch 3, Processing batch 29033/30798\n",
            "Batch 29033 Loss: 0.03520726412534714\n",
            "Epoch 3, Processing batch 29034/30798\n",
            "Batch 29034 Loss: 1.4526253938674927\n",
            "Epoch 3, Processing batch 29035/30798\n",
            "Batch 29035 Loss: 0.02470913529396057\n",
            "Epoch 3, Processing batch 29036/30798\n",
            "Batch 29036 Loss: 0.005846893414855003\n",
            "Epoch 3, Processing batch 29037/30798\n",
            "Batch 29037 Loss: 0.013887071050703526\n",
            "Epoch 3, Processing batch 29038/30798\n",
            "Batch 29038 Loss: 0.005202987231314182\n",
            "Epoch 3, Processing batch 29039/30798\n",
            "Batch 29039 Loss: 0.004451523069292307\n",
            "Epoch 3, Processing batch 29040/30798\n",
            "Batch 29040 Loss: 0.15423470735549927\n",
            "Epoch 3, Processing batch 29041/30798\n",
            "Batch 29041 Loss: 0.09014789015054703\n",
            "Epoch 3, Processing batch 29042/30798\n",
            "Batch 29042 Loss: 0.020545747131109238\n",
            "Epoch 3, Processing batch 29043/30798\n",
            "Batch 29043 Loss: 1.0737025737762451\n",
            "Epoch 3, Processing batch 29044/30798\n",
            "Batch 29044 Loss: 0.49143773317337036\n",
            "Epoch 3, Processing batch 29045/30798\n",
            "Batch 29045 Loss: 0.3914772868156433\n",
            "Epoch 3, Processing batch 29046/30798\n",
            "Batch 29046 Loss: 0.017431151121854782\n",
            "Epoch 3, Processing batch 29047/30798\n",
            "Batch 29047 Loss: 0.9543620944023132\n",
            "Epoch 3, Processing batch 29048/30798\n",
            "Batch 29048 Loss: 0.0512261763215065\n",
            "Epoch 3, Processing batch 29049/30798\n",
            "Batch 29049 Loss: 0.012434723787009716\n",
            "Epoch 3, Processing batch 29050/30798\n",
            "Batch 29050 Loss: 1.4023839235305786\n",
            "Epoch 3, Processing batch 29051/30798\n",
            "Batch 29051 Loss: 0.03254011273384094\n",
            "Epoch 3, Processing batch 29052/30798\n",
            "Batch 29052 Loss: 0.0552239865064621\n",
            "Epoch 3, Processing batch 29053/30798\n",
            "Batch 29053 Loss: 0.12810245156288147\n",
            "Epoch 3, Processing batch 29054/30798\n",
            "Batch 29054 Loss: 0.09665509313344955\n",
            "Epoch 3, Processing batch 29055/30798\n",
            "Batch 29055 Loss: 0.37667742371559143\n",
            "Epoch 3, Processing batch 29056/30798\n",
            "Batch 29056 Loss: 0.0036352677270770073\n",
            "Epoch 3, Processing batch 29057/30798\n",
            "Batch 29057 Loss: 0.0023361523635685444\n",
            "Epoch 3, Processing batch 29058/30798\n",
            "Batch 29058 Loss: 0.3758726716041565\n",
            "Epoch 3, Processing batch 29059/30798\n",
            "Batch 29059 Loss: 0.005980492569506168\n",
            "Epoch 3, Processing batch 29060/30798\n",
            "Batch 29060 Loss: 1.1523926258087158\n",
            "Epoch 3, Processing batch 29061/30798\n",
            "Batch 29061 Loss: 0.07138167321681976\n",
            "Epoch 3, Processing batch 29062/30798\n",
            "Batch 29062 Loss: 0.001998620806261897\n",
            "Epoch 3, Processing batch 29063/30798\n",
            "Batch 29063 Loss: 2.067758321762085\n",
            "Epoch 3, Processing batch 29064/30798\n",
            "Batch 29064 Loss: 0.007816612720489502\n",
            "Epoch 3, Processing batch 29065/30798\n",
            "Batch 29065 Loss: 0.0043381135910749435\n",
            "Epoch 3, Processing batch 29066/30798\n",
            "Batch 29066 Loss: 0.3590843677520752\n",
            "Epoch 3, Processing batch 29067/30798\n",
            "Batch 29067 Loss: 0.023388821631669998\n",
            "Epoch 3, Processing batch 29068/30798\n",
            "Batch 29068 Loss: 0.16053755581378937\n",
            "Epoch 3, Processing batch 29069/30798\n",
            "Batch 29069 Loss: 0.06992952525615692\n",
            "Epoch 3, Processing batch 29070/30798\n",
            "Batch 29070 Loss: 0.27286601066589355\n",
            "Epoch 3, Processing batch 29071/30798\n",
            "Batch 29071 Loss: 0.007925478741526604\n",
            "Epoch 3, Processing batch 29072/30798\n",
            "Batch 29072 Loss: 0.6584572792053223\n",
            "Epoch 3, Processing batch 29073/30798\n",
            "Batch 29073 Loss: 1.1444120407104492\n",
            "Epoch 3, Processing batch 29074/30798\n",
            "Batch 29074 Loss: 0.006137141026556492\n",
            "Epoch 3, Processing batch 29075/30798\n",
            "Batch 29075 Loss: 1.3377139568328857\n",
            "Epoch 3, Processing batch 29076/30798\n",
            "Batch 29076 Loss: 0.17100949585437775\n",
            "Epoch 3, Processing batch 29077/30798\n",
            "Batch 29077 Loss: 0.0753021314740181\n",
            "Epoch 3, Processing batch 29078/30798\n",
            "Batch 29078 Loss: 0.003238976001739502\n",
            "Epoch 3, Processing batch 29079/30798\n",
            "Batch 29079 Loss: 0.23363174498081207\n",
            "Epoch 3, Processing batch 29080/30798\n",
            "Batch 29080 Loss: 0.6337184906005859\n",
            "Epoch 3, Processing batch 29081/30798\n",
            "Batch 29081 Loss: 0.11588754504919052\n",
            "Epoch 3, Processing batch 29082/30798\n",
            "Batch 29082 Loss: 0.04351353645324707\n",
            "Epoch 3, Processing batch 29083/30798\n",
            "Batch 29083 Loss: 0.003271124791353941\n",
            "Epoch 3, Processing batch 29084/30798\n",
            "Batch 29084 Loss: 0.07345347106456757\n",
            "Epoch 3, Processing batch 29085/30798\n",
            "Batch 29085 Loss: 0.004675525240600109\n",
            "Epoch 3, Processing batch 29086/30798\n",
            "Batch 29086 Loss: 0.1438606083393097\n",
            "Epoch 3, Processing batch 29087/30798\n",
            "Batch 29087 Loss: 0.047744859009981155\n",
            "Epoch 3, Processing batch 29088/30798\n",
            "Batch 29088 Loss: 0.026291437447071075\n",
            "Epoch 3, Processing batch 29089/30798\n",
            "Batch 29089 Loss: 0.2639417350292206\n",
            "Epoch 3, Processing batch 29090/30798\n",
            "Batch 29090 Loss: 0.1282881796360016\n",
            "Epoch 3, Processing batch 29091/30798\n",
            "Batch 29091 Loss: 7.306775093078613\n",
            "Epoch 3, Processing batch 29092/30798\n",
            "Batch 29092 Loss: 0.07885000109672546\n",
            "Epoch 3, Processing batch 29093/30798\n",
            "Batch 29093 Loss: 0.01616937294602394\n",
            "Epoch 3, Processing batch 29094/30798\n",
            "Batch 29094 Loss: 0.017050517722964287\n",
            "Epoch 3, Processing batch 29095/30798\n",
            "Batch 29095 Loss: 0.21475306153297424\n",
            "Epoch 3, Processing batch 29096/30798\n",
            "Batch 29096 Loss: 0.03535553440451622\n",
            "Epoch 3, Processing batch 29097/30798\n",
            "Batch 29097 Loss: 0.11528009176254272\n",
            "Epoch 3, Processing batch 29098/30798\n",
            "Batch 29098 Loss: 0.005199854727834463\n",
            "Epoch 3, Processing batch 29099/30798\n",
            "Batch 29099 Loss: 0.03464491665363312\n",
            "Epoch 3, Processing batch 29100/30798\n",
            "Batch 29100 Loss: 0.11261199414730072\n",
            "Epoch 3, Processing batch 29101/30798\n",
            "Batch 29101 Loss: 0.12705357372760773\n",
            "Epoch 3, Processing batch 29102/30798\n",
            "Batch 29102 Loss: 0.3117784261703491\n",
            "Epoch 3, Processing batch 29103/30798\n",
            "Batch 29103 Loss: 0.015482205897569656\n",
            "Epoch 3, Processing batch 29104/30798\n",
            "Batch 29104 Loss: 0.43159300088882446\n",
            "Epoch 3, Processing batch 29105/30798\n",
            "Batch 29105 Loss: 0.056694284081459045\n",
            "Epoch 3, Processing batch 29106/30798\n",
            "Batch 29106 Loss: 0.18834219872951508\n",
            "Epoch 3, Processing batch 29107/30798\n",
            "Batch 29107 Loss: 0.20028477907180786\n",
            "Epoch 3, Processing batch 29108/30798\n",
            "Batch 29108 Loss: 0.044778257608413696\n",
            "Epoch 3, Processing batch 29109/30798\n",
            "Batch 29109 Loss: 0.41600215435028076\n",
            "Epoch 3, Processing batch 29110/30798\n",
            "Batch 29110 Loss: 0.013848530128598213\n",
            "Epoch 3, Processing batch 29111/30798\n",
            "Batch 29111 Loss: 0.5719932913780212\n",
            "Epoch 3, Processing batch 29112/30798\n",
            "Batch 29112 Loss: 0.5234183073043823\n",
            "Epoch 3, Processing batch 29113/30798\n",
            "Batch 29113 Loss: 0.09791546314954758\n",
            "Epoch 3, Processing batch 29114/30798\n",
            "Batch 29114 Loss: 0.016599642112851143\n",
            "Epoch 3, Processing batch 29115/30798\n",
            "Batch 29115 Loss: 0.2553023397922516\n",
            "Epoch 3, Processing batch 29116/30798\n",
            "Batch 29116 Loss: 0.09579252451658249\n",
            "Epoch 3, Processing batch 29117/30798\n",
            "Batch 29117 Loss: 0.05663201957941055\n",
            "Epoch 3, Processing batch 29118/30798\n",
            "Batch 29118 Loss: 0.1898157298564911\n",
            "Epoch 3, Processing batch 29119/30798\n",
            "Batch 29119 Loss: 0.011212462559342384\n",
            "Epoch 3, Processing batch 29120/30798\n",
            "Batch 29120 Loss: 0.028047805652022362\n",
            "Epoch 3, Processing batch 29121/30798\n",
            "Batch 29121 Loss: 0.23019789159297943\n",
            "Epoch 3, Processing batch 29122/30798\n",
            "Batch 29122 Loss: 0.608009934425354\n",
            "Epoch 3, Processing batch 29123/30798\n",
            "Batch 29123 Loss: 0.12478361278772354\n",
            "Epoch 3, Processing batch 29124/30798\n",
            "Batch 29124 Loss: 0.04900914430618286\n",
            "Epoch 3, Processing batch 29125/30798\n",
            "Batch 29125 Loss: 0.8143571019172668\n",
            "Epoch 3, Processing batch 29126/30798\n",
            "Batch 29126 Loss: 0.07172364741563797\n",
            "Epoch 3, Processing batch 29127/30798\n",
            "Batch 29127 Loss: 0.3901771306991577\n",
            "Epoch 3, Processing batch 29128/30798\n",
            "Batch 29128 Loss: 1.159675121307373\n",
            "Epoch 3, Processing batch 29129/30798\n",
            "Batch 29129 Loss: 0.004139295779168606\n",
            "Epoch 3, Processing batch 29130/30798\n",
            "Batch 29130 Loss: 0.01426461711525917\n",
            "Epoch 3, Processing batch 29131/30798\n",
            "Batch 29131 Loss: 0.029602427035570145\n",
            "Epoch 3, Processing batch 29132/30798\n",
            "Batch 29132 Loss: 0.12667407095432281\n",
            "Epoch 3, Processing batch 29133/30798\n",
            "Batch 29133 Loss: 0.2138199508190155\n",
            "Epoch 3, Processing batch 29134/30798\n",
            "Batch 29134 Loss: 0.008214869536459446\n",
            "Epoch 3, Processing batch 29135/30798\n",
            "Batch 29135 Loss: 3.2465333938598633\n",
            "Epoch 3, Processing batch 29136/30798\n",
            "Batch 29136 Loss: 2.0862252712249756\n",
            "Epoch 3, Processing batch 29137/30798\n",
            "Batch 29137 Loss: 0.054469652473926544\n",
            "Epoch 3, Processing batch 29138/30798\n",
            "Batch 29138 Loss: 0.49323907494544983\n",
            "Epoch 3, Processing batch 29139/30798\n",
            "Batch 29139 Loss: 0.024463795125484467\n",
            "Epoch 3, Processing batch 29140/30798\n",
            "Batch 29140 Loss: 0.20976731181144714\n",
            "Epoch 3, Processing batch 29141/30798\n",
            "Batch 29141 Loss: 0.27809712290763855\n",
            "Epoch 3, Processing batch 29142/30798\n",
            "Batch 29142 Loss: 0.12065830081701279\n",
            "Epoch 3, Processing batch 29143/30798\n",
            "Batch 29143 Loss: 0.02478272095322609\n",
            "Epoch 3, Processing batch 29144/30798\n",
            "Batch 29144 Loss: 0.009511358104646206\n",
            "Epoch 3, Processing batch 29145/30798\n",
            "Batch 29145 Loss: 0.14462965726852417\n",
            "Epoch 3, Processing batch 29146/30798\n",
            "Batch 29146 Loss: 0.16688598692417145\n",
            "Epoch 3, Processing batch 29147/30798\n",
            "Batch 29147 Loss: 0.5005756616592407\n",
            "Epoch 3, Processing batch 29148/30798\n",
            "Batch 29148 Loss: 0.04963169991970062\n",
            "Epoch 3, Processing batch 29149/30798\n",
            "Batch 29149 Loss: 0.0959075316786766\n",
            "Epoch 3, Processing batch 29150/30798\n",
            "Batch 29150 Loss: 0.09432870149612427\n",
            "Epoch 3, Processing batch 29151/30798\n",
            "Batch 29151 Loss: 0.0031542135402560234\n",
            "Epoch 3, Processing batch 29152/30798\n",
            "Batch 29152 Loss: 0.08525928854942322\n",
            "Epoch 3, Processing batch 29153/30798\n",
            "Batch 29153 Loss: 0.003172834636643529\n",
            "Epoch 3, Processing batch 29154/30798\n",
            "Batch 29154 Loss: 0.11565549671649933\n",
            "Epoch 3, Processing batch 29155/30798\n",
            "Batch 29155 Loss: 0.01260549109429121\n",
            "Epoch 3, Processing batch 29156/30798\n",
            "Batch 29156 Loss: 2.6268656253814697\n",
            "Epoch 3, Processing batch 29157/30798\n",
            "Batch 29157 Loss: 0.4052182137966156\n",
            "Epoch 3, Processing batch 29158/30798\n",
            "Batch 29158 Loss: 0.10183713585138321\n",
            "Epoch 3, Processing batch 29159/30798\n",
            "Batch 29159 Loss: 0.17441493272781372\n",
            "Epoch 3, Processing batch 29160/30798\n",
            "Batch 29160 Loss: 0.4462226927280426\n",
            "Epoch 3, Processing batch 29161/30798\n",
            "Batch 29161 Loss: 0.26835504174232483\n",
            "Epoch 3, Processing batch 29162/30798\n",
            "Batch 29162 Loss: 0.005895887967199087\n",
            "Epoch 3, Processing batch 29163/30798\n",
            "Batch 29163 Loss: 0.008658921346068382\n",
            "Epoch 3, Processing batch 29164/30798\n",
            "Batch 29164 Loss: 0.18329088389873505\n",
            "Epoch 3, Processing batch 29165/30798\n",
            "Batch 29165 Loss: 0.0888814628124237\n",
            "Epoch 3, Processing batch 29166/30798\n",
            "Batch 29166 Loss: 2.587230682373047\n",
            "Epoch 3, Processing batch 29167/30798\n",
            "Batch 29167 Loss: 3.2676987648010254\n",
            "Epoch 3, Processing batch 29168/30798\n",
            "Batch 29168 Loss: 0.017602402716875076\n",
            "Epoch 3, Processing batch 29169/30798\n",
            "Batch 29169 Loss: 0.004277126397937536\n",
            "Epoch 3, Processing batch 29170/30798\n",
            "Batch 29170 Loss: 0.07091525942087173\n",
            "Epoch 3, Processing batch 29171/30798\n",
            "Batch 29171 Loss: 3.180203437805176\n",
            "Epoch 3, Processing batch 29172/30798\n",
            "Batch 29172 Loss: 0.19298788905143738\n",
            "Epoch 3, Processing batch 29173/30798\n",
            "Batch 29173 Loss: 0.9950230121612549\n",
            "Epoch 3, Processing batch 29174/30798\n",
            "Batch 29174 Loss: 0.8654544949531555\n",
            "Epoch 3, Processing batch 29175/30798\n",
            "Batch 29175 Loss: 1.0551021099090576\n",
            "Epoch 3, Processing batch 29176/30798\n",
            "Batch 29176 Loss: 0.15720166265964508\n",
            "Epoch 3, Processing batch 29177/30798\n",
            "Batch 29177 Loss: 0.23314279317855835\n",
            "Epoch 3, Processing batch 29178/30798\n",
            "Batch 29178 Loss: 0.09590215981006622\n",
            "Epoch 3, Processing batch 29179/30798\n",
            "Batch 29179 Loss: 0.130057692527771\n",
            "Epoch 3, Processing batch 29180/30798\n",
            "Batch 29180 Loss: 0.04845190793275833\n",
            "Epoch 3, Processing batch 29181/30798\n",
            "Batch 29181 Loss: 0.026136016473174095\n",
            "Epoch 3, Processing batch 29182/30798\n",
            "Batch 29182 Loss: 0.018726155161857605\n",
            "Epoch 3, Processing batch 29183/30798\n",
            "Batch 29183 Loss: 0.004418558906763792\n",
            "Epoch 3, Processing batch 29184/30798\n",
            "Batch 29184 Loss: 0.0068075573071837425\n",
            "Epoch 3, Processing batch 29185/30798\n",
            "Batch 29185 Loss: 0.3942832350730896\n",
            "Epoch 3, Processing batch 29186/30798\n",
            "Batch 29186 Loss: 0.39788225293159485\n",
            "Epoch 3, Processing batch 29187/30798\n",
            "Batch 29187 Loss: 0.11730194091796875\n",
            "Epoch 3, Processing batch 29188/30798\n",
            "Batch 29188 Loss: 0.1373654305934906\n",
            "Epoch 3, Processing batch 29189/30798\n",
            "Batch 29189 Loss: 0.19225762784481049\n",
            "Epoch 3, Processing batch 29190/30798\n",
            "Batch 29190 Loss: 1.5260889530181885\n",
            "Epoch 3, Processing batch 29191/30798\n",
            "Batch 29191 Loss: 0.0356648787856102\n",
            "Epoch 3, Processing batch 29192/30798\n",
            "Batch 29192 Loss: 0.1049410030245781\n",
            "Epoch 3, Processing batch 29193/30798\n",
            "Batch 29193 Loss: 0.0032552843913435936\n",
            "Epoch 3, Processing batch 29194/30798\n",
            "Batch 29194 Loss: 0.1323293149471283\n",
            "Epoch 3, Processing batch 29195/30798\n",
            "Batch 29195 Loss: 0.35319775342941284\n",
            "Epoch 3, Processing batch 29196/30798\n",
            "Batch 29196 Loss: 0.5577816367149353\n",
            "Epoch 3, Processing batch 29197/30798\n",
            "Batch 29197 Loss: 0.004784582182765007\n",
            "Epoch 3, Processing batch 29198/30798\n",
            "Batch 29198 Loss: 0.22956985235214233\n",
            "Epoch 3, Processing batch 29199/30798\n",
            "Batch 29199 Loss: 0.00837595947086811\n",
            "Epoch 3, Processing batch 29200/30798\n",
            "Batch 29200 Loss: 0.011731710284948349\n",
            "Epoch 3, Processing batch 29201/30798\n",
            "Batch 29201 Loss: 0.3572426736354828\n",
            "Epoch 3, Processing batch 29202/30798\n",
            "Batch 29202 Loss: 0.00891951471567154\n",
            "Epoch 3, Processing batch 29203/30798\n",
            "Batch 29203 Loss: 2.6438403129577637\n",
            "Epoch 3, Processing batch 29204/30798\n",
            "Batch 29204 Loss: 0.05713214352726936\n",
            "Epoch 3, Processing batch 29205/30798\n",
            "Batch 29205 Loss: 0.05916190147399902\n",
            "Epoch 3, Processing batch 29206/30798\n",
            "Batch 29206 Loss: 0.05489133298397064\n",
            "Epoch 3, Processing batch 29207/30798\n",
            "Batch 29207 Loss: 0.3760697841644287\n",
            "Epoch 3, Processing batch 29208/30798\n",
            "Batch 29208 Loss: 0.01173829659819603\n",
            "Epoch 3, Processing batch 29209/30798\n",
            "Batch 29209 Loss: 1.0281856060028076\n",
            "Epoch 3, Processing batch 29210/30798\n",
            "Batch 29210 Loss: 0.01525924727320671\n",
            "Epoch 3, Processing batch 29211/30798\n",
            "Batch 29211 Loss: 0.004851450212299824\n",
            "Epoch 3, Processing batch 29212/30798\n",
            "Batch 29212 Loss: 0.002332925796508789\n",
            "Epoch 3, Processing batch 29213/30798\n",
            "Batch 29213 Loss: 0.13210827112197876\n",
            "Epoch 3, Processing batch 29214/30798\n",
            "Batch 29214 Loss: 0.7504932880401611\n",
            "Epoch 3, Processing batch 29215/30798\n",
            "Batch 29215 Loss: 0.547781229019165\n",
            "Epoch 3, Processing batch 29216/30798\n",
            "Batch 29216 Loss: 0.3338298201560974\n",
            "Epoch 3, Processing batch 29217/30798\n",
            "Batch 29217 Loss: 0.0030996035784482956\n",
            "Epoch 3, Processing batch 29218/30798\n",
            "Batch 29218 Loss: 0.376666784286499\n",
            "Epoch 3, Processing batch 29219/30798\n",
            "Batch 29219 Loss: 0.27054667472839355\n",
            "Epoch 3, Processing batch 29220/30798\n",
            "Batch 29220 Loss: 0.1749735176563263\n",
            "Epoch 3, Processing batch 29221/30798\n",
            "Batch 29221 Loss: 0.09938624501228333\n",
            "Epoch 3, Processing batch 29222/30798\n",
            "Batch 29222 Loss: 0.04739939048886299\n",
            "Epoch 3, Processing batch 29223/30798\n",
            "Batch 29223 Loss: 0.3219650387763977\n",
            "Epoch 3, Processing batch 29224/30798\n",
            "Batch 29224 Loss: 0.06789927184581757\n",
            "Epoch 3, Processing batch 29225/30798\n",
            "Batch 29225 Loss: 0.03848428279161453\n",
            "Epoch 3, Processing batch 29226/30798\n",
            "Batch 29226 Loss: 0.017410527914762497\n",
            "Epoch 3, Processing batch 29227/30798\n",
            "Batch 29227 Loss: 0.037904758006334305\n",
            "Epoch 3, Processing batch 29228/30798\n",
            "Batch 29228 Loss: 0.17768383026123047\n",
            "Epoch 3, Processing batch 29229/30798\n",
            "Batch 29229 Loss: 2.551266670227051\n",
            "Epoch 3, Processing batch 29230/30798\n",
            "Batch 29230 Loss: 0.08946562558412552\n",
            "Epoch 3, Processing batch 29231/30798\n",
            "Batch 29231 Loss: 0.044302087277173996\n",
            "Epoch 3, Processing batch 29232/30798\n",
            "Batch 29232 Loss: 0.03085671178996563\n",
            "Epoch 3, Processing batch 29233/30798\n",
            "Batch 29233 Loss: 0.00897972658276558\n",
            "Epoch 3, Processing batch 29234/30798\n",
            "Batch 29234 Loss: 0.005756116472184658\n",
            "Epoch 3, Processing batch 29235/30798\n",
            "Batch 29235 Loss: 0.12684237957000732\n",
            "Epoch 3, Processing batch 29236/30798\n",
            "Batch 29236 Loss: 0.021432209759950638\n",
            "Epoch 3, Processing batch 29237/30798\n",
            "Batch 29237 Loss: 0.5095936059951782\n",
            "Epoch 3, Processing batch 29238/30798\n",
            "Batch 29238 Loss: 0.24281999468803406\n",
            "Epoch 3, Processing batch 29239/30798\n",
            "Batch 29239 Loss: 0.052522726356983185\n",
            "Epoch 3, Processing batch 29240/30798\n",
            "Batch 29240 Loss: 1.5790246725082397\n",
            "Epoch 3, Processing batch 29241/30798\n",
            "Batch 29241 Loss: 0.006349429488182068\n",
            "Epoch 3, Processing batch 29242/30798\n",
            "Batch 29242 Loss: 0.09002327919006348\n",
            "Epoch 3, Processing batch 29243/30798\n",
            "Batch 29243 Loss: 0.12170553207397461\n",
            "Epoch 3, Processing batch 29244/30798\n",
            "Batch 29244 Loss: 0.2972812056541443\n",
            "Epoch 3, Processing batch 29245/30798\n",
            "Batch 29245 Loss: 0.04305863752961159\n",
            "Epoch 3, Processing batch 29246/30798\n",
            "Batch 29246 Loss: 0.06564288586378098\n",
            "Epoch 3, Processing batch 29247/30798\n",
            "Batch 29247 Loss: 0.003421921283006668\n",
            "Epoch 3, Processing batch 29248/30798\n",
            "Batch 29248 Loss: 0.1453002244234085\n",
            "Epoch 3, Processing batch 29249/30798\n",
            "Batch 29249 Loss: 0.2922838032245636\n",
            "Epoch 3, Processing batch 29250/30798\n",
            "Batch 29250 Loss: 0.003420522902160883\n",
            "Epoch 3, Processing batch 29251/30798\n",
            "Batch 29251 Loss: 0.2237643599510193\n",
            "Epoch 3, Processing batch 29252/30798\n",
            "Batch 29252 Loss: 0.03268417343497276\n",
            "Epoch 3, Processing batch 29253/30798\n",
            "Batch 29253 Loss: 0.013659288175404072\n",
            "Epoch 3, Processing batch 29254/30798\n",
            "Batch 29254 Loss: 0.2214515507221222\n",
            "Epoch 3, Processing batch 29255/30798\n",
            "Batch 29255 Loss: 0.008330337703227997\n",
            "Epoch 3, Processing batch 29256/30798\n",
            "Batch 29256 Loss: 0.2826186418533325\n",
            "Epoch 3, Processing batch 29257/30798\n",
            "Batch 29257 Loss: 0.3372897207736969\n",
            "Epoch 3, Processing batch 29258/30798\n",
            "Batch 29258 Loss: 0.7565451860427856\n",
            "Epoch 3, Processing batch 29259/30798\n",
            "Batch 29259 Loss: 0.050116997212171555\n",
            "Epoch 3, Processing batch 29260/30798\n",
            "Batch 29260 Loss: 0.5223513841629028\n",
            "Epoch 3, Processing batch 29261/30798\n",
            "Batch 29261 Loss: 0.0159846730530262\n",
            "Epoch 3, Processing batch 29262/30798\n",
            "Batch 29262 Loss: 0.049007922410964966\n",
            "Epoch 3, Processing batch 29263/30798\n",
            "Batch 29263 Loss: 0.2355944812297821\n",
            "Epoch 3, Processing batch 29264/30798\n",
            "Batch 29264 Loss: 0.08011621236801147\n",
            "Epoch 3, Processing batch 29265/30798\n",
            "Batch 29265 Loss: 1.769648790359497\n",
            "Epoch 3, Processing batch 29266/30798\n",
            "Batch 29266 Loss: 0.8412365913391113\n",
            "Epoch 3, Processing batch 29267/30798\n",
            "Batch 29267 Loss: 0.10690836608409882\n",
            "Epoch 3, Processing batch 29268/30798\n",
            "Batch 29268 Loss: 0.7345911264419556\n",
            "Epoch 3, Processing batch 29269/30798\n",
            "Batch 29269 Loss: 0.4611680507659912\n",
            "Epoch 3, Processing batch 29270/30798\n",
            "Batch 29270 Loss: 0.10916011035442352\n",
            "Epoch 3, Processing batch 29271/30798\n",
            "Batch 29271 Loss: 0.007245614193379879\n",
            "Epoch 3, Processing batch 29272/30798\n",
            "Batch 29272 Loss: 0.5858679413795471\n",
            "Epoch 3, Processing batch 29273/30798\n",
            "Batch 29273 Loss: 0.6190685629844666\n",
            "Epoch 3, Processing batch 29274/30798\n",
            "Batch 29274 Loss: 1.082984209060669\n",
            "Epoch 3, Processing batch 29275/30798\n",
            "Batch 29275 Loss: 0.03468000143766403\n",
            "Epoch 3, Processing batch 29276/30798\n",
            "Batch 29276 Loss: 0.008855910040438175\n",
            "Epoch 3, Processing batch 29277/30798\n",
            "Batch 29277 Loss: 0.06432533264160156\n",
            "Epoch 3, Processing batch 29278/30798\n",
            "Batch 29278 Loss: 0.019155360758304596\n",
            "Epoch 3, Processing batch 29279/30798\n",
            "Batch 29279 Loss: 0.11379379779100418\n",
            "Epoch 3, Processing batch 29280/30798\n",
            "Batch 29280 Loss: 0.17199136316776276\n",
            "Epoch 3, Processing batch 29281/30798\n",
            "Batch 29281 Loss: 1.4984300136566162\n",
            "Epoch 3, Processing batch 29282/30798\n",
            "Batch 29282 Loss: 0.007439394947141409\n",
            "Epoch 3, Processing batch 29283/30798\n",
            "Batch 29283 Loss: 0.050882596522569656\n",
            "Epoch 3, Processing batch 29284/30798\n",
            "Batch 29284 Loss: 0.0335412360727787\n",
            "Epoch 3, Processing batch 29285/30798\n",
            "Batch 29285 Loss: 0.1752082109451294\n",
            "Epoch 3, Processing batch 29286/30798\n",
            "Batch 29286 Loss: 0.04414665326476097\n",
            "Epoch 3, Processing batch 29287/30798\n",
            "Batch 29287 Loss: 0.08862016350030899\n",
            "Epoch 3, Processing batch 29288/30798\n",
            "Batch 29288 Loss: 0.19796378910541534\n",
            "Epoch 3, Processing batch 29289/30798\n",
            "Batch 29289 Loss: 0.1127999797463417\n",
            "Epoch 3, Processing batch 29290/30798\n",
            "Batch 29290 Loss: 0.11375050246715546\n",
            "Epoch 3, Processing batch 29291/30798\n",
            "Batch 29291 Loss: 0.0066498941741883755\n",
            "Epoch 3, Processing batch 29292/30798\n",
            "Batch 29292 Loss: 0.7645983099937439\n",
            "Epoch 3, Processing batch 29293/30798\n",
            "Batch 29293 Loss: 0.236680805683136\n",
            "Epoch 3, Processing batch 29294/30798\n",
            "Batch 29294 Loss: 0.01190834492444992\n",
            "Epoch 3, Processing batch 29295/30798\n",
            "Batch 29295 Loss: 0.0013611962785944343\n",
            "Epoch 3, Processing batch 29296/30798\n",
            "Batch 29296 Loss: 0.04425698146224022\n",
            "Epoch 3, Processing batch 29297/30798\n",
            "Batch 29297 Loss: 0.370975524187088\n",
            "Epoch 3, Processing batch 29298/30798\n",
            "Batch 29298 Loss: 0.007248449604958296\n",
            "Epoch 3, Processing batch 29299/30798\n",
            "Batch 29299 Loss: 0.014543875120580196\n",
            "Epoch 3, Processing batch 29300/30798\n",
            "Batch 29300 Loss: 0.004760498646646738\n",
            "Epoch 3, Processing batch 29301/30798\n",
            "Batch 29301 Loss: 0.0036051576025784016\n",
            "Epoch 3, Processing batch 29302/30798\n",
            "Batch 29302 Loss: 0.029283424839377403\n",
            "Epoch 3, Processing batch 29303/30798\n",
            "Batch 29303 Loss: 0.42028480768203735\n",
            "Epoch 3, Processing batch 29304/30798\n",
            "Batch 29304 Loss: 0.06002875789999962\n",
            "Epoch 3, Processing batch 29305/30798\n",
            "Batch 29305 Loss: 0.33632755279541016\n",
            "Epoch 3, Processing batch 29306/30798\n",
            "Batch 29306 Loss: 0.09693330526351929\n",
            "Epoch 3, Processing batch 29307/30798\n",
            "Batch 29307 Loss: 2.698068618774414\n",
            "Epoch 3, Processing batch 29308/30798\n",
            "Batch 29308 Loss: 0.11983436346054077\n",
            "Epoch 3, Processing batch 29309/30798\n",
            "Batch 29309 Loss: 0.29152992367744446\n",
            "Epoch 3, Processing batch 29310/30798\n",
            "Batch 29310 Loss: 0.1675601452589035\n",
            "Epoch 3, Processing batch 29311/30798\n",
            "Batch 29311 Loss: 0.16872099041938782\n",
            "Epoch 3, Processing batch 29312/30798\n",
            "Batch 29312 Loss: 0.006183333694934845\n",
            "Epoch 3, Processing batch 29313/30798\n",
            "Batch 29313 Loss: 0.4172652065753937\n",
            "Epoch 3, Processing batch 29314/30798\n",
            "Batch 29314 Loss: 0.15513552725315094\n",
            "Epoch 3, Processing batch 29315/30798\n",
            "Batch 29315 Loss: 0.0014519592514261603\n",
            "Epoch 3, Processing batch 29316/30798\n",
            "Batch 29316 Loss: 0.046852853149175644\n",
            "Epoch 3, Processing batch 29317/30798\n",
            "Batch 29317 Loss: 0.0834265723824501\n",
            "Epoch 3, Processing batch 29318/30798\n",
            "Batch 29318 Loss: 0.021877704188227654\n",
            "Epoch 3, Processing batch 29319/30798\n",
            "Batch 29319 Loss: 0.004402711521834135\n",
            "Epoch 3, Processing batch 29320/30798\n",
            "Batch 29320 Loss: 0.04616149514913559\n",
            "Epoch 3, Processing batch 29321/30798\n",
            "Batch 29321 Loss: 0.06696077436208725\n",
            "Epoch 3, Processing batch 29322/30798\n",
            "Batch 29322 Loss: 0.051891326904296875\n",
            "Epoch 3, Processing batch 29323/30798\n",
            "Batch 29323 Loss: 0.1138589084148407\n",
            "Epoch 3, Processing batch 29324/30798\n",
            "Batch 29324 Loss: 0.05936054512858391\n",
            "Epoch 3, Processing batch 29325/30798\n",
            "Batch 29325 Loss: 0.6336163282394409\n",
            "Epoch 3, Processing batch 29326/30798\n",
            "Batch 29326 Loss: 0.3540402054786682\n",
            "Epoch 3, Processing batch 29327/30798\n",
            "Batch 29327 Loss: 0.9615035057067871\n",
            "Epoch 3, Processing batch 29328/30798\n",
            "Batch 29328 Loss: 0.014242753386497498\n",
            "Epoch 3, Processing batch 29329/30798\n",
            "Batch 29329 Loss: 0.08138556778430939\n",
            "Epoch 3, Processing batch 29330/30798\n",
            "Batch 29330 Loss: 0.14563050866127014\n",
            "Epoch 3, Processing batch 29331/30798\n",
            "Batch 29331 Loss: 0.07248567044734955\n",
            "Epoch 3, Processing batch 29332/30798\n",
            "Batch 29332 Loss: 0.24772970378398895\n",
            "Epoch 3, Processing batch 29333/30798\n",
            "Batch 29333 Loss: 0.037372440099716187\n",
            "Epoch 3, Processing batch 29334/30798\n",
            "Batch 29334 Loss: 0.007395891472697258\n",
            "Epoch 3, Processing batch 29335/30798\n",
            "Batch 29335 Loss: 0.190727099776268\n",
            "Epoch 3, Processing batch 29336/30798\n",
            "Batch 29336 Loss: 0.008949111215770245\n",
            "Epoch 3, Processing batch 29337/30798\n",
            "Batch 29337 Loss: 0.01783044822514057\n",
            "Epoch 3, Processing batch 29338/30798\n",
            "Batch 29338 Loss: 0.4466252326965332\n",
            "Epoch 3, Processing batch 29339/30798\n",
            "Batch 29339 Loss: 0.15426135063171387\n",
            "Epoch 3, Processing batch 29340/30798\n",
            "Batch 29340 Loss: 0.37819185853004456\n",
            "Epoch 3, Processing batch 29341/30798\n",
            "Batch 29341 Loss: 0.06508422642946243\n",
            "Epoch 3, Processing batch 29342/30798\n",
            "Batch 29342 Loss: 0.055309079587459564\n",
            "Epoch 3, Processing batch 29343/30798\n",
            "Batch 29343 Loss: 1.421481966972351\n",
            "Epoch 3, Processing batch 29344/30798\n",
            "Batch 29344 Loss: 0.1668740063905716\n",
            "Epoch 3, Processing batch 29345/30798\n",
            "Batch 29345 Loss: 0.03858600929379463\n",
            "Epoch 3, Processing batch 29346/30798\n",
            "Batch 29346 Loss: 0.38866308331489563\n",
            "Epoch 3, Processing batch 29347/30798\n",
            "Batch 29347 Loss: 0.010447215288877487\n",
            "Epoch 3, Processing batch 29348/30798\n",
            "Batch 29348 Loss: 0.052960727363824844\n",
            "Epoch 3, Processing batch 29349/30798\n",
            "Batch 29349 Loss: 0.11373358964920044\n",
            "Epoch 3, Processing batch 29350/30798\n",
            "Batch 29350 Loss: 0.006498935632407665\n",
            "Epoch 3, Processing batch 29351/30798\n",
            "Batch 29351 Loss: 0.030724726617336273\n",
            "Epoch 3, Processing batch 29352/30798\n",
            "Batch 29352 Loss: 0.049925800412893295\n",
            "Epoch 3, Processing batch 29353/30798\n",
            "Batch 29353 Loss: 0.058448661118745804\n",
            "Epoch 3, Processing batch 29354/30798\n",
            "Batch 29354 Loss: 0.02922334335744381\n",
            "Epoch 3, Processing batch 29355/30798\n",
            "Batch 29355 Loss: 0.05496981739997864\n",
            "Epoch 3, Processing batch 29356/30798\n",
            "Batch 29356 Loss: 0.03989778459072113\n",
            "Epoch 3, Processing batch 29357/30798\n",
            "Batch 29357 Loss: 0.03650699928402901\n",
            "Epoch 3, Processing batch 29358/30798\n",
            "Batch 29358 Loss: 0.13270524144172668\n",
            "Epoch 3, Processing batch 29359/30798\n",
            "Batch 29359 Loss: 0.030470654368400574\n",
            "Epoch 3, Processing batch 29360/30798\n",
            "Batch 29360 Loss: 0.5374536514282227\n",
            "Epoch 3, Processing batch 29361/30798\n",
            "Batch 29361 Loss: 0.09912558645009995\n",
            "Epoch 3, Processing batch 29362/30798\n",
            "Batch 29362 Loss: 0.07963746786117554\n",
            "Epoch 3, Processing batch 29363/30798\n",
            "Batch 29363 Loss: 0.05216575786471367\n",
            "Epoch 3, Processing batch 29364/30798\n",
            "Batch 29364 Loss: 0.7082360982894897\n",
            "Epoch 3, Processing batch 29365/30798\n",
            "Batch 29365 Loss: 0.08143532276153564\n",
            "Epoch 3, Processing batch 29366/30798\n",
            "Batch 29366 Loss: 0.3512893617153168\n",
            "Epoch 3, Processing batch 29367/30798\n",
            "Batch 29367 Loss: 0.08825666457414627\n",
            "Epoch 3, Processing batch 29368/30798\n",
            "Batch 29368 Loss: 0.19406771659851074\n",
            "Epoch 3, Processing batch 29369/30798\n",
            "Batch 29369 Loss: 0.13825920224189758\n",
            "Epoch 3, Processing batch 29370/30798\n",
            "Batch 29370 Loss: 0.7996990084648132\n",
            "Epoch 3, Processing batch 29371/30798\n",
            "Batch 29371 Loss: 0.02922350913286209\n",
            "Epoch 3, Processing batch 29372/30798\n",
            "Batch 29372 Loss: 0.6851517558097839\n",
            "Epoch 3, Processing batch 29373/30798\n",
            "Batch 29373 Loss: 0.004218078684061766\n",
            "Epoch 3, Processing batch 29374/30798\n",
            "Batch 29374 Loss: 0.3101286292076111\n",
            "Epoch 3, Processing batch 29375/30798\n",
            "Batch 29375 Loss: 0.06789546459913254\n",
            "Epoch 3, Processing batch 29376/30798\n",
            "Batch 29376 Loss: 0.14025527238845825\n",
            "Epoch 3, Processing batch 29377/30798\n",
            "Batch 29377 Loss: 0.03451170772314072\n",
            "Epoch 3, Processing batch 29378/30798\n",
            "Batch 29378 Loss: 0.46874862909317017\n",
            "Epoch 3, Processing batch 29379/30798\n",
            "Batch 29379 Loss: 0.04004472494125366\n",
            "Epoch 3, Processing batch 29380/30798\n",
            "Batch 29380 Loss: 0.10853218287229538\n",
            "Epoch 3, Processing batch 29381/30798\n",
            "Batch 29381 Loss: 0.2016572803258896\n",
            "Epoch 3, Processing batch 29382/30798\n",
            "Batch 29382 Loss: 0.009323818609118462\n",
            "Epoch 3, Processing batch 29383/30798\n",
            "Batch 29383 Loss: 3.8620262145996094\n",
            "Epoch 3, Processing batch 29384/30798\n",
            "Batch 29384 Loss: 0.5844072103500366\n",
            "Epoch 3, Processing batch 29385/30798\n",
            "Batch 29385 Loss: 0.04680601507425308\n",
            "Epoch 3, Processing batch 29386/30798\n",
            "Batch 29386 Loss: 0.007387136574834585\n",
            "Epoch 3, Processing batch 29387/30798\n",
            "Batch 29387 Loss: 0.011345148086547852\n",
            "Epoch 3, Processing batch 29388/30798\n",
            "Batch 29388 Loss: 0.02717834711074829\n",
            "Epoch 3, Processing batch 29389/30798\n",
            "Batch 29389 Loss: 0.12529703974723816\n",
            "Epoch 3, Processing batch 29390/30798\n",
            "Batch 29390 Loss: 0.22438925504684448\n",
            "Epoch 3, Processing batch 29391/30798\n",
            "Batch 29391 Loss: 0.6611716151237488\n",
            "Epoch 3, Processing batch 29392/30798\n",
            "Batch 29392 Loss: 0.08821582049131393\n",
            "Epoch 3, Processing batch 29393/30798\n",
            "Batch 29393 Loss: 0.025451576337218285\n",
            "Epoch 3, Processing batch 29394/30798\n",
            "Batch 29394 Loss: 2.4341392517089844\n",
            "Epoch 3, Processing batch 29395/30798\n",
            "Batch 29395 Loss: 0.05301183462142944\n",
            "Epoch 3, Processing batch 29396/30798\n",
            "Batch 29396 Loss: 0.34956738352775574\n",
            "Epoch 3, Processing batch 29397/30798\n",
            "Batch 29397 Loss: 0.1630489081144333\n",
            "Epoch 3, Processing batch 29398/30798\n",
            "Batch 29398 Loss: 0.27924951910972595\n",
            "Epoch 3, Processing batch 29399/30798\n",
            "Batch 29399 Loss: 0.93757164478302\n",
            "Epoch 3, Processing batch 29400/30798\n",
            "Batch 29400 Loss: 0.02190452627837658\n",
            "Epoch 3, Processing batch 29401/30798\n",
            "Batch 29401 Loss: 0.033523138612508774\n",
            "Epoch 3, Processing batch 29402/30798\n",
            "Batch 29402 Loss: 0.28706979751586914\n",
            "Epoch 3, Processing batch 29403/30798\n",
            "Batch 29403 Loss: 0.21092921495437622\n",
            "Epoch 3, Processing batch 29404/30798\n",
            "Batch 29404 Loss: 0.13438256084918976\n",
            "Epoch 3, Processing batch 29405/30798\n",
            "Batch 29405 Loss: 0.02839221991598606\n",
            "Epoch 3, Processing batch 29406/30798\n",
            "Batch 29406 Loss: 0.12264452874660492\n",
            "Epoch 3, Processing batch 29407/30798\n",
            "Batch 29407 Loss: 0.9777296781539917\n",
            "Epoch 3, Processing batch 29408/30798\n",
            "Batch 29408 Loss: 0.26072365045547485\n",
            "Epoch 3, Processing batch 29409/30798\n",
            "Batch 29409 Loss: 0.10551689565181732\n",
            "Epoch 3, Processing batch 29410/30798\n",
            "Batch 29410 Loss: 0.40899163484573364\n",
            "Epoch 3, Processing batch 29411/30798\n",
            "Batch 29411 Loss: 0.036674827337265015\n",
            "Epoch 3, Processing batch 29412/30798\n",
            "Batch 29412 Loss: 0.0674726665019989\n",
            "Epoch 3, Processing batch 29413/30798\n",
            "Batch 29413 Loss: 0.016202477738261223\n",
            "Epoch 3, Processing batch 29414/30798\n",
            "Batch 29414 Loss: 0.044819239526987076\n",
            "Epoch 3, Processing batch 29415/30798\n",
            "Batch 29415 Loss: 0.017729030922055244\n",
            "Epoch 3, Processing batch 29416/30798\n",
            "Batch 29416 Loss: 0.011133303865790367\n",
            "Epoch 3, Processing batch 29417/30798\n",
            "Batch 29417 Loss: 0.003134003607556224\n",
            "Epoch 3, Processing batch 29418/30798\n",
            "Batch 29418 Loss: 0.07717390358448029\n",
            "Epoch 3, Processing batch 29419/30798\n",
            "Batch 29419 Loss: 0.04132990539073944\n",
            "Epoch 3, Processing batch 29420/30798\n",
            "Batch 29420 Loss: 0.6951117515563965\n",
            "Epoch 3, Processing batch 29421/30798\n",
            "Batch 29421 Loss: 0.13523468375205994\n",
            "Epoch 3, Processing batch 29422/30798\n",
            "Batch 29422 Loss: 0.01911204867064953\n",
            "Epoch 3, Processing batch 29423/30798\n",
            "Batch 29423 Loss: 0.09246888756752014\n",
            "Epoch 3, Processing batch 29424/30798\n",
            "Batch 29424 Loss: 0.0032191528007388115\n",
            "Epoch 3, Processing batch 29425/30798\n",
            "Batch 29425 Loss: 0.6132595539093018\n",
            "Epoch 3, Processing batch 29426/30798\n",
            "Batch 29426 Loss: 0.024559924378991127\n",
            "Epoch 3, Processing batch 29427/30798\n",
            "Batch 29427 Loss: 0.005248283036053181\n",
            "Epoch 3, Processing batch 29428/30798\n",
            "Batch 29428 Loss: 0.6821770071983337\n",
            "Epoch 3, Processing batch 29429/30798\n",
            "Batch 29429 Loss: 0.02327830158174038\n",
            "Epoch 3, Processing batch 29430/30798\n",
            "Batch 29430 Loss: 0.08847616612911224\n",
            "Epoch 3, Processing batch 29431/30798\n",
            "Batch 29431 Loss: 0.16353851556777954\n",
            "Epoch 3, Processing batch 29432/30798\n",
            "Batch 29432 Loss: 1.2331671714782715\n",
            "Epoch 3, Processing batch 29433/30798\n",
            "Batch 29433 Loss: 1.3322607278823853\n",
            "Epoch 3, Processing batch 29434/30798\n",
            "Batch 29434 Loss: 0.022427914664149284\n",
            "Epoch 3, Processing batch 29435/30798\n",
            "Batch 29435 Loss: 0.0032728686928749084\n",
            "Epoch 3, Processing batch 29436/30798\n",
            "Batch 29436 Loss: 0.022613629698753357\n",
            "Epoch 3, Processing batch 29437/30798\n",
            "Batch 29437 Loss: 0.2082013487815857\n",
            "Epoch 3, Processing batch 29438/30798\n",
            "Batch 29438 Loss: 0.34090352058410645\n",
            "Epoch 3, Processing batch 29439/30798\n",
            "Batch 29439 Loss: 0.45796358585357666\n",
            "Epoch 3, Processing batch 29440/30798\n",
            "Batch 29440 Loss: 0.022877007722854614\n",
            "Epoch 3, Processing batch 29441/30798\n",
            "Batch 29441 Loss: 0.2665572762489319\n",
            "Epoch 3, Processing batch 29442/30798\n",
            "Batch 29442 Loss: 0.03430836647748947\n",
            "Epoch 3, Processing batch 29443/30798\n",
            "Batch 29443 Loss: 0.00899442471563816\n",
            "Epoch 3, Processing batch 29444/30798\n",
            "Batch 29444 Loss: 0.9298489093780518\n",
            "Epoch 3, Processing batch 29445/30798\n",
            "Batch 29445 Loss: 0.21311770379543304\n",
            "Epoch 3, Processing batch 29446/30798\n",
            "Batch 29446 Loss: 0.0064151836559176445\n",
            "Epoch 3, Processing batch 29447/30798\n",
            "Batch 29447 Loss: 0.020780442282557487\n",
            "Epoch 3, Processing batch 29448/30798\n",
            "Batch 29448 Loss: 0.004292260855436325\n",
            "Epoch 3, Processing batch 29449/30798\n",
            "Batch 29449 Loss: 0.7101410031318665\n",
            "Epoch 3, Processing batch 29450/30798\n",
            "Batch 29450 Loss: 0.10968563705682755\n",
            "Epoch 3, Processing batch 29451/30798\n",
            "Batch 29451 Loss: 1.242478609085083\n",
            "Epoch 3, Processing batch 29452/30798\n",
            "Batch 29452 Loss: 0.0053520179353654385\n",
            "Epoch 3, Processing batch 29453/30798\n",
            "Batch 29453 Loss: 2.538196563720703\n",
            "Epoch 3, Processing batch 29454/30798\n",
            "Batch 29454 Loss: 0.009814299643039703\n",
            "Epoch 3, Processing batch 29455/30798\n",
            "Batch 29455 Loss: 0.07143931835889816\n",
            "Epoch 3, Processing batch 29456/30798\n",
            "Batch 29456 Loss: 0.061028048396110535\n",
            "Epoch 3, Processing batch 29457/30798\n",
            "Batch 29457 Loss: 0.007434440776705742\n",
            "Epoch 3, Processing batch 29458/30798\n",
            "Batch 29458 Loss: 0.06671817600727081\n",
            "Epoch 3, Processing batch 29459/30798\n",
            "Batch 29459 Loss: 0.10375787317752838\n",
            "Epoch 3, Processing batch 29460/30798\n",
            "Batch 29460 Loss: 0.42371290922164917\n",
            "Epoch 3, Processing batch 29461/30798\n",
            "Batch 29461 Loss: 0.18324711918830872\n",
            "Epoch 3, Processing batch 29462/30798\n",
            "Batch 29462 Loss: 0.16787336766719818\n",
            "Epoch 3, Processing batch 29463/30798\n",
            "Batch 29463 Loss: 0.02075435407459736\n",
            "Epoch 3, Processing batch 29464/30798\n",
            "Batch 29464 Loss: 0.25723791122436523\n",
            "Epoch 3, Processing batch 29465/30798\n",
            "Batch 29465 Loss: 0.1379977911710739\n",
            "Epoch 3, Processing batch 29466/30798\n",
            "Batch 29466 Loss: 1.229803204536438\n",
            "Epoch 3, Processing batch 29467/30798\n",
            "Batch 29467 Loss: 0.8917681574821472\n",
            "Epoch 3, Processing batch 29468/30798\n",
            "Batch 29468 Loss: 0.18265199661254883\n",
            "Epoch 3, Processing batch 29469/30798\n",
            "Batch 29469 Loss: 0.15997494757175446\n",
            "Epoch 3, Processing batch 29470/30798\n",
            "Batch 29470 Loss: 1.4844789505004883\n",
            "Epoch 3, Processing batch 29471/30798\n",
            "Batch 29471 Loss: 0.3902231454849243\n",
            "Epoch 3, Processing batch 29472/30798\n",
            "Batch 29472 Loss: 0.021581308916211128\n",
            "Epoch 3, Processing batch 29473/30798\n",
            "Batch 29473 Loss: 0.008681255392730236\n",
            "Epoch 3, Processing batch 29474/30798\n",
            "Batch 29474 Loss: 0.003452762495726347\n",
            "Epoch 3, Processing batch 29475/30798\n",
            "Batch 29475 Loss: 0.09217473864555359\n",
            "Epoch 3, Processing batch 29476/30798\n",
            "Batch 29476 Loss: 1.7718816995620728\n",
            "Epoch 3, Processing batch 29477/30798\n",
            "Batch 29477 Loss: 0.22631776332855225\n",
            "Epoch 3, Processing batch 29478/30798\n",
            "Batch 29478 Loss: 0.5227168202400208\n",
            "Epoch 3, Processing batch 29479/30798\n",
            "Batch 29479 Loss: 0.02434186264872551\n",
            "Epoch 3, Processing batch 29480/30798\n",
            "Batch 29480 Loss: 0.07321397215127945\n",
            "Epoch 3, Processing batch 29481/30798\n",
            "Batch 29481 Loss: 0.0034118983894586563\n",
            "Epoch 3, Processing batch 29482/30798\n",
            "Batch 29482 Loss: 0.8923259377479553\n",
            "Epoch 3, Processing batch 29483/30798\n",
            "Batch 29483 Loss: 0.4787524938583374\n",
            "Epoch 3, Processing batch 29484/30798\n",
            "Batch 29484 Loss: 0.1092613935470581\n",
            "Epoch 3, Processing batch 29485/30798\n",
            "Batch 29485 Loss: 0.3590511083602905\n",
            "Epoch 3, Processing batch 29486/30798\n",
            "Batch 29486 Loss: 1.7963664531707764\n",
            "Epoch 3, Processing batch 29487/30798\n",
            "Batch 29487 Loss: 0.06311575323343277\n",
            "Epoch 3, Processing batch 29488/30798\n",
            "Batch 29488 Loss: 4.387994766235352\n",
            "Epoch 3, Processing batch 29489/30798\n",
            "Batch 29489 Loss: 0.025175634771585464\n",
            "Epoch 3, Processing batch 29490/30798\n",
            "Batch 29490 Loss: 1.6886467933654785\n",
            "Epoch 3, Processing batch 29491/30798\n",
            "Batch 29491 Loss: 0.1610376238822937\n",
            "Epoch 3, Processing batch 29492/30798\n",
            "Batch 29492 Loss: 0.20133152604103088\n",
            "Epoch 3, Processing batch 29493/30798\n",
            "Batch 29493 Loss: 0.45949631929397583\n",
            "Epoch 3, Processing batch 29494/30798\n",
            "Batch 29494 Loss: 0.004579224623739719\n",
            "Epoch 3, Processing batch 29495/30798\n",
            "Batch 29495 Loss: 0.19361382722854614\n",
            "Epoch 3, Processing batch 29496/30798\n",
            "Batch 29496 Loss: 0.024206964299082756\n",
            "Epoch 3, Processing batch 29497/30798\n",
            "Batch 29497 Loss: 0.08774310350418091\n",
            "Epoch 3, Processing batch 29498/30798\n",
            "Batch 29498 Loss: 0.12648004293441772\n",
            "Epoch 3, Processing batch 29499/30798\n",
            "Batch 29499 Loss: 0.026665758341550827\n",
            "Epoch 3, Processing batch 29500/30798\n",
            "Batch 29500 Loss: 0.21709425747394562\n",
            "Epoch 3, Processing batch 29501/30798\n",
            "Batch 29501 Loss: 0.31793883442878723\n",
            "Epoch 3, Processing batch 29502/30798\n",
            "Batch 29502 Loss: 0.017200414091348648\n",
            "Epoch 3, Processing batch 29503/30798\n",
            "Batch 29503 Loss: 0.12027422338724136\n",
            "Epoch 3, Processing batch 29504/30798\n",
            "Batch 29504 Loss: 1.464439868927002\n",
            "Epoch 3, Processing batch 29505/30798\n",
            "Batch 29505 Loss: 0.6141301393508911\n",
            "Epoch 3, Processing batch 29506/30798\n",
            "Batch 29506 Loss: 0.004481797106564045\n",
            "Epoch 3, Processing batch 29507/30798\n",
            "Batch 29507 Loss: 0.08350260555744171\n",
            "Epoch 3, Processing batch 29508/30798\n",
            "Batch 29508 Loss: 0.16255004703998566\n",
            "Epoch 3, Processing batch 29509/30798\n",
            "Batch 29509 Loss: 0.12076680362224579\n",
            "Epoch 3, Processing batch 29510/30798\n",
            "Batch 29510 Loss: 0.005778440274298191\n",
            "Epoch 3, Processing batch 29511/30798\n",
            "Batch 29511 Loss: 0.4536024034023285\n",
            "Epoch 3, Processing batch 29512/30798\n",
            "Batch 29512 Loss: 0.13527709245681763\n",
            "Epoch 3, Processing batch 29513/30798\n",
            "Batch 29513 Loss: 0.32565003633499146\n",
            "Epoch 3, Processing batch 29514/30798\n",
            "Batch 29514 Loss: 0.04132050275802612\n",
            "Epoch 3, Processing batch 29515/30798\n",
            "Batch 29515 Loss: 1.0499262809753418\n",
            "Epoch 3, Processing batch 29516/30798\n",
            "Batch 29516 Loss: 0.04038671404123306\n",
            "Epoch 3, Processing batch 29517/30798\n",
            "Batch 29517 Loss: 0.10513097047805786\n",
            "Epoch 3, Processing batch 29518/30798\n",
            "Batch 29518 Loss: 1.0266058444976807\n",
            "Epoch 3, Processing batch 29519/30798\n",
            "Batch 29519 Loss: 0.025910107418894768\n",
            "Epoch 3, Processing batch 29520/30798\n",
            "Batch 29520 Loss: 0.14233839511871338\n",
            "Epoch 3, Processing batch 29521/30798\n",
            "Batch 29521 Loss: 0.005499646533280611\n",
            "Epoch 3, Processing batch 29522/30798\n",
            "Batch 29522 Loss: 0.0016893455758690834\n",
            "Epoch 3, Processing batch 29523/30798\n",
            "Batch 29523 Loss: 0.019395388662815094\n",
            "Epoch 3, Processing batch 29524/30798\n",
            "Batch 29524 Loss: 0.14296090602874756\n",
            "Epoch 3, Processing batch 29525/30798\n",
            "Batch 29525 Loss: 0.4241873621940613\n",
            "Epoch 3, Processing batch 29526/30798\n",
            "Batch 29526 Loss: 0.5497204065322876\n",
            "Epoch 3, Processing batch 29527/30798\n",
            "Batch 29527 Loss: 1.3157159090042114\n",
            "Epoch 3, Processing batch 29528/30798\n",
            "Batch 29528 Loss: 0.40630942583084106\n",
            "Epoch 3, Processing batch 29529/30798\n",
            "Batch 29529 Loss: 0.025552287697792053\n",
            "Epoch 3, Processing batch 29530/30798\n",
            "Batch 29530 Loss: 0.09104196727275848\n",
            "Epoch 3, Processing batch 29531/30798\n",
            "Batch 29531 Loss: 0.020716171711683273\n",
            "Epoch 3, Processing batch 29532/30798\n",
            "Batch 29532 Loss: 0.43619558215141296\n",
            "Epoch 3, Processing batch 29533/30798\n",
            "Batch 29533 Loss: 0.5776887536048889\n",
            "Epoch 3, Processing batch 29534/30798\n",
            "Batch 29534 Loss: 0.05946316570043564\n",
            "Epoch 3, Processing batch 29535/30798\n",
            "Batch 29535 Loss: 0.08583024889230728\n",
            "Epoch 3, Processing batch 29536/30798\n",
            "Batch 29536 Loss: 0.9232754111289978\n",
            "Epoch 3, Processing batch 29537/30798\n",
            "Batch 29537 Loss: 2.389676570892334\n",
            "Epoch 3, Processing batch 29538/30798\n",
            "Batch 29538 Loss: 0.03211241215467453\n",
            "Epoch 3, Processing batch 29539/30798\n",
            "Batch 29539 Loss: 1.0833775997161865\n",
            "Epoch 3, Processing batch 29540/30798\n",
            "Batch 29540 Loss: 1.1373202800750732\n",
            "Epoch 3, Processing batch 29541/30798\n",
            "Batch 29541 Loss: 0.19015179574489594\n",
            "Epoch 3, Processing batch 29542/30798\n",
            "Batch 29542 Loss: 0.6488759517669678\n",
            "Epoch 3, Processing batch 29543/30798\n",
            "Batch 29543 Loss: 0.2539231777191162\n",
            "Epoch 3, Processing batch 29544/30798\n",
            "Batch 29544 Loss: 0.10487101227045059\n",
            "Epoch 3, Processing batch 29545/30798\n",
            "Batch 29545 Loss: 0.11681617796421051\n",
            "Epoch 3, Processing batch 29546/30798\n",
            "Batch 29546 Loss: 1.590772271156311\n",
            "Epoch 3, Processing batch 29547/30798\n",
            "Batch 29547 Loss: 0.12448141723871231\n",
            "Epoch 3, Processing batch 29548/30798\n",
            "Batch 29548 Loss: 0.3406601846218109\n",
            "Epoch 3, Processing batch 29549/30798\n",
            "Batch 29549 Loss: 0.25541192293167114\n",
            "Epoch 3, Processing batch 29550/30798\n",
            "Batch 29550 Loss: 0.13264241814613342\n",
            "Epoch 3, Processing batch 29551/30798\n",
            "Batch 29551 Loss: 0.14279232919216156\n",
            "Epoch 3, Processing batch 29552/30798\n",
            "Batch 29552 Loss: 0.22383643686771393\n",
            "Epoch 3, Processing batch 29553/30798\n",
            "Batch 29553 Loss: 0.07869615405797958\n",
            "Epoch 3, Processing batch 29554/30798\n",
            "Batch 29554 Loss: 0.012750941328704357\n",
            "Epoch 3, Processing batch 29555/30798\n",
            "Batch 29555 Loss: 0.02594982646405697\n",
            "Epoch 3, Processing batch 29556/30798\n",
            "Batch 29556 Loss: 0.8993126153945923\n",
            "Epoch 3, Processing batch 29557/30798\n",
            "Batch 29557 Loss: 0.008751322515308857\n",
            "Epoch 3, Processing batch 29558/30798\n",
            "Batch 29558 Loss: 1.5400742292404175\n",
            "Epoch 3, Processing batch 29559/30798\n",
            "Batch 29559 Loss: 0.9316607713699341\n",
            "Epoch 3, Processing batch 29560/30798\n",
            "Batch 29560 Loss: 3.252166986465454\n",
            "Epoch 3, Processing batch 29561/30798\n",
            "Batch 29561 Loss: 0.0032117730006575584\n",
            "Epoch 3, Processing batch 29562/30798\n",
            "Batch 29562 Loss: 0.35685473680496216\n",
            "Epoch 3, Processing batch 29563/30798\n",
            "Batch 29563 Loss: 0.0006904503097757697\n",
            "Epoch 3, Processing batch 29564/30798\n",
            "Batch 29564 Loss: 0.1546126902103424\n",
            "Epoch 3, Processing batch 29565/30798\n",
            "Batch 29565 Loss: 0.0026100915856659412\n",
            "Epoch 3, Processing batch 29566/30798\n",
            "Batch 29566 Loss: 0.25487756729125977\n",
            "Epoch 3, Processing batch 29567/30798\n",
            "Batch 29567 Loss: 2.4369723796844482\n",
            "Epoch 3, Processing batch 29568/30798\n",
            "Batch 29568 Loss: 0.2895047068595886\n",
            "Epoch 3, Processing batch 29569/30798\n",
            "Batch 29569 Loss: 0.39465492963790894\n",
            "Epoch 3, Processing batch 29570/30798\n",
            "Batch 29570 Loss: 0.05455637723207474\n",
            "Epoch 3, Processing batch 29571/30798\n",
            "Batch 29571 Loss: 0.09206168353557587\n",
            "Epoch 3, Processing batch 29572/30798\n",
            "Batch 29572 Loss: 0.5125335454940796\n",
            "Epoch 3, Processing batch 29573/30798\n",
            "Batch 29573 Loss: 0.02333744242787361\n",
            "Epoch 3, Processing batch 29574/30798\n",
            "Batch 29574 Loss: 0.053907252848148346\n",
            "Epoch 3, Processing batch 29575/30798\n",
            "Batch 29575 Loss: 0.21059063076972961\n",
            "Epoch 3, Processing batch 29576/30798\n",
            "Batch 29576 Loss: 0.08572284877300262\n",
            "Epoch 3, Processing batch 29577/30798\n",
            "Batch 29577 Loss: 0.07557407021522522\n",
            "Epoch 3, Processing batch 29578/30798\n",
            "Batch 29578 Loss: 0.13438600301742554\n",
            "Epoch 3, Processing batch 29579/30798\n",
            "Batch 29579 Loss: 0.10900377482175827\n",
            "Epoch 3, Processing batch 29580/30798\n",
            "Batch 29580 Loss: 0.0326993465423584\n",
            "Epoch 3, Processing batch 29581/30798\n",
            "Batch 29581 Loss: 0.1911570429801941\n",
            "Epoch 3, Processing batch 29582/30798\n",
            "Batch 29582 Loss: 0.04337445646524429\n",
            "Epoch 3, Processing batch 29583/30798\n",
            "Batch 29583 Loss: 0.04601302742958069\n",
            "Epoch 3, Processing batch 29584/30798\n",
            "Batch 29584 Loss: 2.356557607650757\n",
            "Epoch 3, Processing batch 29585/30798\n",
            "Batch 29585 Loss: 0.021858537569642067\n",
            "Epoch 3, Processing batch 29586/30798\n",
            "Batch 29586 Loss: 0.09599895775318146\n",
            "Epoch 3, Processing batch 29587/30798\n",
            "Batch 29587 Loss: 0.23863089084625244\n",
            "Epoch 3, Processing batch 29588/30798\n",
            "Batch 29588 Loss: 0.8540030717849731\n",
            "Epoch 3, Processing batch 29589/30798\n",
            "Batch 29589 Loss: 0.6751598119735718\n",
            "Epoch 3, Processing batch 29590/30798\n",
            "Batch 29590 Loss: 0.16132599115371704\n",
            "Epoch 3, Processing batch 29591/30798\n",
            "Batch 29591 Loss: 0.09675471484661102\n",
            "Epoch 3, Processing batch 29592/30798\n",
            "Batch 29592 Loss: 1.168433666229248\n",
            "Epoch 3, Processing batch 29593/30798\n",
            "Batch 29593 Loss: 0.43586018681526184\n",
            "Epoch 3, Processing batch 29594/30798\n",
            "Batch 29594 Loss: 1.2482547760009766\n",
            "Epoch 3, Processing batch 29595/30798\n",
            "Batch 29595 Loss: 0.05829776078462601\n",
            "Epoch 3, Processing batch 29596/30798\n",
            "Batch 29596 Loss: 0.3127589225769043\n",
            "Epoch 3, Processing batch 29597/30798\n",
            "Batch 29597 Loss: 0.07369957119226456\n",
            "Epoch 3, Processing batch 29598/30798\n",
            "Batch 29598 Loss: 0.84024977684021\n",
            "Epoch 3, Processing batch 29599/30798\n",
            "Batch 29599 Loss: 0.008844258263707161\n",
            "Epoch 3, Processing batch 29600/30798\n",
            "Batch 29600 Loss: 0.014378425665199757\n",
            "Epoch 3, Processing batch 29601/30798\n",
            "Batch 29601 Loss: 0.037402331829071045\n",
            "Epoch 3, Processing batch 29602/30798\n",
            "Batch 29602 Loss: 0.5788649320602417\n",
            "Epoch 3, Processing batch 29603/30798\n",
            "Batch 29603 Loss: 0.003984513226896524\n",
            "Epoch 3, Processing batch 29604/30798\n",
            "Batch 29604 Loss: 0.037336565554142\n",
            "Epoch 3, Processing batch 29605/30798\n",
            "Batch 29605 Loss: 0.07991543412208557\n",
            "Epoch 3, Processing batch 29606/30798\n",
            "Batch 29606 Loss: 0.11699239164590836\n",
            "Epoch 3, Processing batch 29607/30798\n",
            "Batch 29607 Loss: 0.4976397454738617\n",
            "Epoch 3, Processing batch 29608/30798\n",
            "Batch 29608 Loss: 0.14759686589241028\n",
            "Epoch 3, Processing batch 29609/30798\n",
            "Batch 29609 Loss: 0.03470303863286972\n",
            "Epoch 3, Processing batch 29610/30798\n",
            "Batch 29610 Loss: 0.0005854269256815314\n",
            "Epoch 3, Processing batch 29611/30798\n",
            "Batch 29611 Loss: 0.04457651823759079\n",
            "Epoch 3, Processing batch 29612/30798\n",
            "Batch 29612 Loss: 0.07146739959716797\n",
            "Epoch 3, Processing batch 29613/30798\n",
            "Batch 29613 Loss: 0.0036996728740632534\n",
            "Epoch 3, Processing batch 29614/30798\n",
            "Batch 29614 Loss: 0.02771015465259552\n",
            "Epoch 3, Processing batch 29615/30798\n",
            "Batch 29615 Loss: 1.0802366733551025\n",
            "Epoch 3, Processing batch 29616/30798\n",
            "Batch 29616 Loss: 0.4319385886192322\n",
            "Epoch 3, Processing batch 29617/30798\n",
            "Batch 29617 Loss: 0.1965429037809372\n",
            "Epoch 3, Processing batch 29618/30798\n",
            "Batch 29618 Loss: 0.17439796030521393\n",
            "Epoch 3, Processing batch 29619/30798\n",
            "Batch 29619 Loss: 0.20885615050792694\n",
            "Epoch 3, Processing batch 29620/30798\n",
            "Batch 29620 Loss: 0.0035385177470743656\n",
            "Epoch 3, Processing batch 29621/30798\n",
            "Batch 29621 Loss: 0.09700436890125275\n",
            "Epoch 3, Processing batch 29622/30798\n",
            "Batch 29622 Loss: 0.0037723903078585863\n",
            "Epoch 3, Processing batch 29623/30798\n",
            "Batch 29623 Loss: 0.10505198687314987\n",
            "Epoch 3, Processing batch 29624/30798\n",
            "Batch 29624 Loss: 0.12411274015903473\n",
            "Epoch 3, Processing batch 29625/30798\n",
            "Batch 29625 Loss: 0.06993758678436279\n",
            "Epoch 3, Processing batch 29626/30798\n",
            "Batch 29626 Loss: 1.1653350591659546\n",
            "Epoch 3, Processing batch 29627/30798\n",
            "Batch 29627 Loss: 0.02783283218741417\n",
            "Epoch 3, Processing batch 29628/30798\n",
            "Batch 29628 Loss: 1.3845036029815674\n",
            "Epoch 3, Processing batch 29629/30798\n",
            "Batch 29629 Loss: 0.07413677871227264\n",
            "Epoch 3, Processing batch 29630/30798\n",
            "Batch 29630 Loss: 0.11572501063346863\n",
            "Epoch 3, Processing batch 29631/30798\n",
            "Batch 29631 Loss: 3.571232557296753\n",
            "Epoch 3, Processing batch 29632/30798\n",
            "Batch 29632 Loss: 0.3895096480846405\n",
            "Epoch 3, Processing batch 29633/30798\n",
            "Batch 29633 Loss: 0.18415279686450958\n",
            "Epoch 3, Processing batch 29634/30798\n",
            "Batch 29634 Loss: 0.044161614030599594\n",
            "Epoch 3, Processing batch 29635/30798\n",
            "Batch 29635 Loss: 0.05013679713010788\n",
            "Epoch 3, Processing batch 29636/30798\n",
            "Batch 29636 Loss: 0.45379623770713806\n",
            "Epoch 3, Processing batch 29637/30798\n",
            "Batch 29637 Loss: 0.04681307077407837\n",
            "Epoch 3, Processing batch 29638/30798\n",
            "Batch 29638 Loss: 0.00483478931710124\n",
            "Epoch 3, Processing batch 29639/30798\n",
            "Batch 29639 Loss: 0.08767256140708923\n",
            "Epoch 3, Processing batch 29640/30798\n",
            "Batch 29640 Loss: 3.761065721511841\n",
            "Epoch 3, Processing batch 29641/30798\n",
            "Batch 29641 Loss: 0.014842946082353592\n",
            "Epoch 3, Processing batch 29642/30798\n",
            "Batch 29642 Loss: 0.03727182373404503\n",
            "Epoch 3, Processing batch 29643/30798\n",
            "Batch 29643 Loss: 0.003492667805403471\n",
            "Epoch 3, Processing batch 29644/30798\n",
            "Batch 29644 Loss: 2.0244481563568115\n",
            "Epoch 3, Processing batch 29645/30798\n",
            "Batch 29645 Loss: 0.9524068236351013\n",
            "Epoch 3, Processing batch 29646/30798\n",
            "Batch 29646 Loss: 0.13721831142902374\n",
            "Epoch 3, Processing batch 29647/30798\n",
            "Batch 29647 Loss: 0.04164016246795654\n",
            "Epoch 3, Processing batch 29648/30798\n",
            "Batch 29648 Loss: 0.7535362243652344\n",
            "Epoch 3, Processing batch 29649/30798\n",
            "Batch 29649 Loss: 0.2009119689464569\n",
            "Epoch 3, Processing batch 29650/30798\n",
            "Batch 29650 Loss: 0.07494492828845978\n",
            "Epoch 3, Processing batch 29651/30798\n",
            "Batch 29651 Loss: 0.5969443321228027\n",
            "Epoch 3, Processing batch 29652/30798\n",
            "Batch 29652 Loss: 0.020789073780179024\n",
            "Epoch 3, Processing batch 29653/30798\n",
            "Batch 29653 Loss: 0.698946475982666\n",
            "Epoch 3, Processing batch 29654/30798\n",
            "Batch 29654 Loss: 0.2931423485279083\n",
            "Epoch 3, Processing batch 29655/30798\n",
            "Batch 29655 Loss: 1.6943302154541016\n",
            "Epoch 3, Processing batch 29656/30798\n",
            "Batch 29656 Loss: 0.047821566462516785\n",
            "Epoch 3, Processing batch 29657/30798\n",
            "Batch 29657 Loss: 0.1026516705751419\n",
            "Epoch 3, Processing batch 29658/30798\n",
            "Batch 29658 Loss: 0.011136282235383987\n",
            "Epoch 3, Processing batch 29659/30798\n",
            "Batch 29659 Loss: 0.003982934635132551\n",
            "Epoch 3, Processing batch 29660/30798\n",
            "Batch 29660 Loss: 1.0167700052261353\n",
            "Epoch 3, Processing batch 29661/30798\n",
            "Batch 29661 Loss: 0.041424352675676346\n",
            "Epoch 3, Processing batch 29662/30798\n",
            "Batch 29662 Loss: 0.10253032296895981\n",
            "Epoch 3, Processing batch 29663/30798\n",
            "Batch 29663 Loss: 0.007032793015241623\n",
            "Epoch 3, Processing batch 29664/30798\n",
            "Batch 29664 Loss: 0.07842990756034851\n",
            "Epoch 3, Processing batch 29665/30798\n",
            "Batch 29665 Loss: 0.05392716825008392\n",
            "Epoch 3, Processing batch 29666/30798\n",
            "Batch 29666 Loss: 0.29407042264938354\n",
            "Epoch 3, Processing batch 29667/30798\n",
            "Batch 29667 Loss: 3.0537307262420654\n",
            "Epoch 3, Processing batch 29668/30798\n",
            "Batch 29668 Loss: 0.13182184100151062\n",
            "Epoch 3, Processing batch 29669/30798\n",
            "Batch 29669 Loss: 0.28929999470710754\n",
            "Epoch 3, Processing batch 29670/30798\n",
            "Batch 29670 Loss: 0.3979662358760834\n",
            "Epoch 3, Processing batch 29671/30798\n",
            "Batch 29671 Loss: 0.3639172911643982\n",
            "Epoch 3, Processing batch 29672/30798\n",
            "Batch 29672 Loss: 0.0635497197508812\n",
            "Epoch 3, Processing batch 29673/30798\n",
            "Batch 29673 Loss: 0.026283491402864456\n",
            "Epoch 3, Processing batch 29674/30798\n",
            "Batch 29674 Loss: 0.12505067884922028\n",
            "Epoch 3, Processing batch 29675/30798\n",
            "Batch 29675 Loss: 0.008170781657099724\n",
            "Epoch 3, Processing batch 29676/30798\n",
            "Batch 29676 Loss: 0.5869595408439636\n",
            "Epoch 3, Processing batch 29677/30798\n",
            "Batch 29677 Loss: 0.2650333344936371\n",
            "Epoch 3, Processing batch 29678/30798\n",
            "Batch 29678 Loss: 0.00629339087754488\n",
            "Epoch 3, Processing batch 29679/30798\n",
            "Batch 29679 Loss: 0.09855557978153229\n",
            "Epoch 3, Processing batch 29680/30798\n",
            "Batch 29680 Loss: 0.09788442403078079\n",
            "Epoch 3, Processing batch 29681/30798\n",
            "Batch 29681 Loss: 0.07990337163209915\n",
            "Epoch 3, Processing batch 29682/30798\n",
            "Batch 29682 Loss: 1.3130519390106201\n",
            "Epoch 3, Processing batch 29683/30798\n",
            "Batch 29683 Loss: 2.415924072265625\n",
            "Epoch 3, Processing batch 29684/30798\n",
            "Batch 29684 Loss: 0.002726417500525713\n",
            "Epoch 3, Processing batch 29685/30798\n",
            "Batch 29685 Loss: 0.04283178970217705\n",
            "Epoch 3, Processing batch 29686/30798\n",
            "Batch 29686 Loss: 0.285758376121521\n",
            "Epoch 3, Processing batch 29687/30798\n",
            "Batch 29687 Loss: 0.1303270161151886\n",
            "Epoch 3, Processing batch 29688/30798\n",
            "Batch 29688 Loss: 0.1109306663274765\n",
            "Epoch 3, Processing batch 29689/30798\n",
            "Batch 29689 Loss: 0.4510570764541626\n",
            "Epoch 3, Processing batch 29690/30798\n",
            "Batch 29690 Loss: 0.06275666505098343\n",
            "Epoch 3, Processing batch 29691/30798\n",
            "Batch 29691 Loss: 2.8962857723236084\n",
            "Epoch 3, Processing batch 29692/30798\n",
            "Batch 29692 Loss: 0.3659314513206482\n",
            "Epoch 3, Processing batch 29693/30798\n",
            "Batch 29693 Loss: 3.097776412963867\n",
            "Epoch 3, Processing batch 29694/30798\n",
            "Batch 29694 Loss: 0.08755777776241302\n",
            "Epoch 3, Processing batch 29695/30798\n",
            "Batch 29695 Loss: 0.0028111422434449196\n",
            "Epoch 3, Processing batch 29696/30798\n",
            "Batch 29696 Loss: 0.07936179637908936\n",
            "Epoch 3, Processing batch 29697/30798\n",
            "Batch 29697 Loss: 0.3272993564605713\n",
            "Epoch 3, Processing batch 29698/30798\n",
            "Batch 29698 Loss: 0.6977814435958862\n",
            "Epoch 3, Processing batch 29699/30798\n",
            "Batch 29699 Loss: 0.06623057276010513\n",
            "Epoch 3, Processing batch 29700/30798\n",
            "Batch 29700 Loss: 0.22953766584396362\n",
            "Epoch 3, Processing batch 29701/30798\n",
            "Batch 29701 Loss: 0.14300397038459778\n",
            "Epoch 3, Processing batch 29702/30798\n",
            "Batch 29702 Loss: 0.07800445705652237\n",
            "Epoch 3, Processing batch 29703/30798\n",
            "Batch 29703 Loss: 0.24688071012496948\n",
            "Epoch 3, Processing batch 29704/30798\n",
            "Batch 29704 Loss: 0.13036870956420898\n",
            "Epoch 3, Processing batch 29705/30798\n",
            "Batch 29705 Loss: 1.54196035861969\n",
            "Epoch 3, Processing batch 29706/30798\n",
            "Batch 29706 Loss: 0.012625551782548428\n",
            "Epoch 3, Processing batch 29707/30798\n",
            "Batch 29707 Loss: 0.013222061097621918\n",
            "Epoch 3, Processing batch 29708/30798\n",
            "Batch 29708 Loss: 0.08323678374290466\n",
            "Epoch 3, Processing batch 29709/30798\n",
            "Batch 29709 Loss: 0.5166051983833313\n",
            "Epoch 3, Processing batch 29710/30798\n",
            "Batch 29710 Loss: 0.9212591648101807\n",
            "Epoch 3, Processing batch 29711/30798\n",
            "Batch 29711 Loss: 0.7678694725036621\n",
            "Epoch 3, Processing batch 29712/30798\n",
            "Batch 29712 Loss: 0.03513587266206741\n",
            "Epoch 3, Processing batch 29713/30798\n",
            "Batch 29713 Loss: 0.07177220284938812\n",
            "Epoch 3, Processing batch 29714/30798\n",
            "Batch 29714 Loss: 0.18273591995239258\n",
            "Epoch 3, Processing batch 29715/30798\n",
            "Batch 29715 Loss: 0.05205598473548889\n",
            "Epoch 3, Processing batch 29716/30798\n",
            "Batch 29716 Loss: 0.0589778758585453\n",
            "Epoch 3, Processing batch 29717/30798\n",
            "Batch 29717 Loss: 0.07279300689697266\n",
            "Epoch 3, Processing batch 29718/30798\n",
            "Batch 29718 Loss: 0.017246346920728683\n",
            "Epoch 3, Processing batch 29719/30798\n",
            "Batch 29719 Loss: 0.0416482575237751\n",
            "Epoch 3, Processing batch 29720/30798\n",
            "Batch 29720 Loss: 0.06296014785766602\n",
            "Epoch 3, Processing batch 29721/30798\n",
            "Batch 29721 Loss: 0.048540983349084854\n",
            "Epoch 3, Processing batch 29722/30798\n",
            "Batch 29722 Loss: 0.07256139069795609\n",
            "Epoch 3, Processing batch 29723/30798\n",
            "Batch 29723 Loss: 0.07905517518520355\n",
            "Epoch 3, Processing batch 29724/30798\n",
            "Batch 29724 Loss: 0.18857064843177795\n",
            "Epoch 3, Processing batch 29725/30798\n",
            "Batch 29725 Loss: 0.14121156930923462\n",
            "Epoch 3, Processing batch 29726/30798\n",
            "Batch 29726 Loss: 0.18744775652885437\n",
            "Epoch 3, Processing batch 29727/30798\n",
            "Batch 29727 Loss: 2.4423108100891113\n",
            "Epoch 3, Processing batch 29728/30798\n",
            "Batch 29728 Loss: 0.43894100189208984\n",
            "Epoch 3, Processing batch 29729/30798\n",
            "Batch 29729 Loss: 0.24276848137378693\n",
            "Epoch 3, Processing batch 29730/30798\n",
            "Batch 29730 Loss: 0.06087108328938484\n",
            "Epoch 3, Processing batch 29731/30798\n",
            "Batch 29731 Loss: 0.5070009827613831\n",
            "Epoch 3, Processing batch 29732/30798\n",
            "Batch 29732 Loss: 0.17904160916805267\n",
            "Epoch 3, Processing batch 29733/30798\n",
            "Batch 29733 Loss: 0.2928793132305145\n",
            "Epoch 3, Processing batch 29734/30798\n",
            "Batch 29734 Loss: 0.15169507265090942\n",
            "Epoch 3, Processing batch 29735/30798\n",
            "Batch 29735 Loss: 0.21727706491947174\n",
            "Epoch 3, Processing batch 29736/30798\n",
            "Batch 29736 Loss: 0.1588859260082245\n",
            "Epoch 3, Processing batch 29737/30798\n",
            "Batch 29737 Loss: 0.048533715307712555\n",
            "Epoch 3, Processing batch 29738/30798\n",
            "Batch 29738 Loss: 1.1312816143035889\n",
            "Epoch 3, Processing batch 29739/30798\n",
            "Batch 29739 Loss: 0.08804527670145035\n",
            "Epoch 3, Processing batch 29740/30798\n",
            "Batch 29740 Loss: 1.9341200590133667\n",
            "Epoch 3, Processing batch 29741/30798\n",
            "Batch 29741 Loss: 0.15145736932754517\n",
            "Epoch 3, Processing batch 29742/30798\n",
            "Batch 29742 Loss: 1.1878303289413452\n",
            "Epoch 3, Processing batch 29743/30798\n",
            "Batch 29743 Loss: 1.2520853281021118\n",
            "Epoch 3, Processing batch 29744/30798\n",
            "Batch 29744 Loss: 0.037839315831661224\n",
            "Epoch 3, Processing batch 29745/30798\n",
            "Batch 29745 Loss: 0.006514668930321932\n",
            "Epoch 3, Processing batch 29746/30798\n",
            "Batch 29746 Loss: 0.25923436880111694\n",
            "Epoch 3, Processing batch 29747/30798\n",
            "Batch 29747 Loss: 1.8247463703155518\n",
            "Epoch 3, Processing batch 29748/30798\n",
            "Batch 29748 Loss: 0.0025923000648617744\n",
            "Epoch 3, Processing batch 29749/30798\n",
            "Batch 29749 Loss: 0.8845095634460449\n",
            "Epoch 3, Processing batch 29750/30798\n",
            "Batch 29750 Loss: 0.12091047316789627\n",
            "Epoch 3, Processing batch 29751/30798\n",
            "Batch 29751 Loss: 0.17396517097949982\n",
            "Epoch 3, Processing batch 29752/30798\n",
            "Batch 29752 Loss: 0.20102377235889435\n",
            "Epoch 3, Processing batch 29753/30798\n",
            "Batch 29753 Loss: 0.14409390091896057\n",
            "Epoch 3, Processing batch 29754/30798\n",
            "Batch 29754 Loss: 0.09603486210107803\n",
            "Epoch 3, Processing batch 29755/30798\n",
            "Batch 29755 Loss: 0.11079205572605133\n",
            "Epoch 3, Processing batch 29756/30798\n",
            "Batch 29756 Loss: 0.1473468840122223\n",
            "Epoch 3, Processing batch 29757/30798\n",
            "Batch 29757 Loss: 0.023291634395718575\n",
            "Epoch 3, Processing batch 29758/30798\n",
            "Batch 29758 Loss: 1.170989990234375\n",
            "Epoch 3, Processing batch 29759/30798\n",
            "Batch 29759 Loss: 0.056106165051460266\n",
            "Epoch 3, Processing batch 29760/30798\n",
            "Batch 29760 Loss: 0.41740983724594116\n",
            "Epoch 3, Processing batch 29761/30798\n",
            "Batch 29761 Loss: 0.2584352195262909\n",
            "Epoch 3, Processing batch 29762/30798\n",
            "Batch 29762 Loss: 0.15130965411663055\n",
            "Epoch 3, Processing batch 29763/30798\n",
            "Batch 29763 Loss: 0.261128306388855\n",
            "Epoch 3, Processing batch 29764/30798\n",
            "Batch 29764 Loss: 0.8509993553161621\n",
            "Epoch 3, Processing batch 29765/30798\n",
            "Batch 29765 Loss: 0.1178291067481041\n",
            "Epoch 3, Processing batch 29766/30798\n",
            "Batch 29766 Loss: 2.6430907249450684\n",
            "Epoch 3, Processing batch 29767/30798\n",
            "Batch 29767 Loss: 0.0034605965483933687\n",
            "Epoch 3, Processing batch 29768/30798\n",
            "Batch 29768 Loss: 0.2517724335193634\n",
            "Epoch 3, Processing batch 29769/30798\n",
            "Batch 29769 Loss: 0.008362325839698315\n",
            "Epoch 3, Processing batch 29770/30798\n",
            "Batch 29770 Loss: 0.014521567150950432\n",
            "Epoch 3, Processing batch 29771/30798\n",
            "Batch 29771 Loss: 0.2505013048648834\n",
            "Epoch 3, Processing batch 29772/30798\n",
            "Batch 29772 Loss: 0.033523742109537125\n",
            "Epoch 3, Processing batch 29773/30798\n",
            "Batch 29773 Loss: 0.12359340488910675\n",
            "Epoch 3, Processing batch 29774/30798\n",
            "Batch 29774 Loss: 0.5720837116241455\n",
            "Epoch 3, Processing batch 29775/30798\n",
            "Batch 29775 Loss: 0.06262035667896271\n",
            "Epoch 3, Processing batch 29776/30798\n",
            "Batch 29776 Loss: 0.00811584759503603\n",
            "Epoch 3, Processing batch 29777/30798\n",
            "Batch 29777 Loss: 0.6566562056541443\n",
            "Epoch 3, Processing batch 29778/30798\n",
            "Batch 29778 Loss: 0.549443781375885\n",
            "Epoch 3, Processing batch 29779/30798\n",
            "Batch 29779 Loss: 0.15418092906475067\n",
            "Epoch 3, Processing batch 29780/30798\n",
            "Batch 29780 Loss: 0.06718394160270691\n",
            "Epoch 3, Processing batch 29781/30798\n",
            "Batch 29781 Loss: 0.11386744678020477\n",
            "Epoch 3, Processing batch 29782/30798\n",
            "Batch 29782 Loss: 0.008077342994511127\n",
            "Epoch 3, Processing batch 29783/30798\n",
            "Batch 29783 Loss: 0.1302802413702011\n",
            "Epoch 3, Processing batch 29784/30798\n",
            "Batch 29784 Loss: 0.05466488376259804\n",
            "Epoch 3, Processing batch 29785/30798\n",
            "Batch 29785 Loss: 0.8217426538467407\n",
            "Epoch 3, Processing batch 29786/30798\n",
            "Batch 29786 Loss: 0.0012021511793136597\n",
            "Epoch 3, Processing batch 29787/30798\n",
            "Batch 29787 Loss: 0.7057250142097473\n",
            "Epoch 3, Processing batch 29788/30798\n",
            "Batch 29788 Loss: 0.4364510476589203\n",
            "Epoch 3, Processing batch 29789/30798\n",
            "Batch 29789 Loss: 0.5666633248329163\n",
            "Epoch 3, Processing batch 29790/30798\n",
            "Batch 29790 Loss: 0.6060824394226074\n",
            "Epoch 3, Processing batch 29791/30798\n",
            "Batch 29791 Loss: 0.29231181740760803\n",
            "Epoch 3, Processing batch 29792/30798\n",
            "Batch 29792 Loss: 0.2042131870985031\n",
            "Epoch 3, Processing batch 29793/30798\n",
            "Batch 29793 Loss: 1.646883487701416\n",
            "Epoch 3, Processing batch 29794/30798\n",
            "Batch 29794 Loss: 0.5940353274345398\n",
            "Epoch 3, Processing batch 29795/30798\n",
            "Batch 29795 Loss: 0.14882896840572357\n",
            "Epoch 3, Processing batch 29796/30798\n",
            "Batch 29796 Loss: 1.2661473751068115\n",
            "Epoch 3, Processing batch 29797/30798\n",
            "Batch 29797 Loss: 3.021688461303711\n",
            "Epoch 3, Processing batch 29798/30798\n",
            "Batch 29798 Loss: 0.8042853474617004\n",
            "Epoch 3, Processing batch 29799/30798\n",
            "Batch 29799 Loss: 0.02214892953634262\n",
            "Epoch 3, Processing batch 29800/30798\n",
            "Batch 29800 Loss: 1.2476271390914917\n",
            "Epoch 3, Processing batch 29801/30798\n",
            "Batch 29801 Loss: 1.4557522535324097\n",
            "Epoch 3, Processing batch 29802/30798\n",
            "Batch 29802 Loss: 0.041981156915426254\n",
            "Epoch 3, Processing batch 29803/30798\n",
            "Batch 29803 Loss: 0.07716365158557892\n",
            "Epoch 3, Processing batch 29804/30798\n",
            "Batch 29804 Loss: 0.033518534153699875\n",
            "Epoch 3, Processing batch 29805/30798\n",
            "Batch 29805 Loss: 1.5275272130966187\n",
            "Epoch 3, Processing batch 29806/30798\n",
            "Batch 29806 Loss: 0.12418975681066513\n",
            "Epoch 3, Processing batch 29807/30798\n",
            "Batch 29807 Loss: 0.43119609355926514\n",
            "Epoch 3, Processing batch 29808/30798\n",
            "Batch 29808 Loss: 0.20374473929405212\n",
            "Epoch 3, Processing batch 29809/30798\n",
            "Batch 29809 Loss: 0.04378854110836983\n",
            "Epoch 3, Processing batch 29810/30798\n",
            "Batch 29810 Loss: 0.37009039521217346\n",
            "Epoch 3, Processing batch 29811/30798\n",
            "Batch 29811 Loss: 0.36995938420295715\n",
            "Epoch 3, Processing batch 29812/30798\n",
            "Batch 29812 Loss: 0.127018541097641\n",
            "Epoch 3, Processing batch 29813/30798\n",
            "Batch 29813 Loss: 0.33019396662712097\n",
            "Epoch 3, Processing batch 29814/30798\n",
            "Batch 29814 Loss: 2.2820796966552734\n",
            "Epoch 3, Processing batch 29815/30798\n",
            "Batch 29815 Loss: 0.6368474960327148\n",
            "Epoch 3, Processing batch 29816/30798\n",
            "Batch 29816 Loss: 0.12181872874498367\n",
            "Epoch 3, Processing batch 29817/30798\n",
            "Batch 29817 Loss: 0.06140458956360817\n",
            "Epoch 3, Processing batch 29818/30798\n",
            "Batch 29818 Loss: 0.29076436161994934\n",
            "Epoch 3, Processing batch 29819/30798\n",
            "Batch 29819 Loss: 0.11553073674440384\n",
            "Epoch 3, Processing batch 29820/30798\n",
            "Batch 29820 Loss: 0.02846698835492134\n",
            "Epoch 3, Processing batch 29821/30798\n",
            "Batch 29821 Loss: 0.25157830119132996\n",
            "Epoch 3, Processing batch 29822/30798\n",
            "Batch 29822 Loss: 2.255005359649658\n",
            "Epoch 3, Processing batch 29823/30798\n",
            "Batch 29823 Loss: 0.08141849935054779\n",
            "Epoch 3, Processing batch 29824/30798\n",
            "Batch 29824 Loss: 0.1789359450340271\n",
            "Epoch 3, Processing batch 29825/30798\n",
            "Batch 29825 Loss: 0.401490181684494\n",
            "Epoch 3, Processing batch 29826/30798\n",
            "Batch 29826 Loss: 0.013937930576503277\n",
            "Epoch 3, Processing batch 29827/30798\n",
            "Batch 29827 Loss: 0.040817465633153915\n",
            "Epoch 3, Processing batch 29828/30798\n",
            "Batch 29828 Loss: 0.0429312102496624\n",
            "Epoch 3, Processing batch 29829/30798\n",
            "Batch 29829 Loss: 0.3482292890548706\n",
            "Epoch 3, Processing batch 29830/30798\n",
            "Batch 29830 Loss: 0.03951617330312729\n",
            "Epoch 3, Processing batch 29831/30798\n",
            "Batch 29831 Loss: 0.37019452452659607\n",
            "Epoch 3, Processing batch 29832/30798\n",
            "Batch 29832 Loss: 0.16565105319023132\n",
            "Epoch 3, Processing batch 29833/30798\n",
            "Batch 29833 Loss: 0.08795627951622009\n",
            "Epoch 3, Processing batch 29834/30798\n",
            "Batch 29834 Loss: 0.25879085063934326\n",
            "Epoch 3, Processing batch 29835/30798\n",
            "Batch 29835 Loss: 0.1327189803123474\n",
            "Epoch 3, Processing batch 29836/30798\n",
            "Batch 29836 Loss: 0.5487015247344971\n",
            "Epoch 3, Processing batch 29837/30798\n",
            "Batch 29837 Loss: 0.011843452230095863\n",
            "Epoch 3, Processing batch 29838/30798\n",
            "Batch 29838 Loss: 0.004547424614429474\n",
            "Epoch 3, Processing batch 29839/30798\n",
            "Batch 29839 Loss: 0.3987388610839844\n",
            "Epoch 3, Processing batch 29840/30798\n",
            "Batch 29840 Loss: 0.32145872712135315\n",
            "Epoch 3, Processing batch 29841/30798\n",
            "Batch 29841 Loss: 0.12341666221618652\n",
            "Epoch 3, Processing batch 29842/30798\n",
            "Batch 29842 Loss: 0.13881675899028778\n",
            "Epoch 3, Processing batch 29843/30798\n",
            "Batch 29843 Loss: 0.31327158212661743\n",
            "Epoch 3, Processing batch 29844/30798\n",
            "Batch 29844 Loss: 0.634702205657959\n",
            "Epoch 3, Processing batch 29845/30798\n",
            "Batch 29845 Loss: 0.026690272614359856\n",
            "Epoch 3, Processing batch 29846/30798\n",
            "Batch 29846 Loss: 0.08574220538139343\n",
            "Epoch 3, Processing batch 29847/30798\n",
            "Batch 29847 Loss: 0.07559844851493835\n",
            "Epoch 3, Processing batch 29848/30798\n",
            "Batch 29848 Loss: 0.2547733187675476\n",
            "Epoch 3, Processing batch 29849/30798\n",
            "Batch 29849 Loss: 1.2641409635543823\n",
            "Epoch 3, Processing batch 29850/30798\n",
            "Batch 29850 Loss: 0.06105215102434158\n",
            "Epoch 3, Processing batch 29851/30798\n",
            "Batch 29851 Loss: 0.35129302740097046\n",
            "Epoch 3, Processing batch 29852/30798\n",
            "Batch 29852 Loss: 0.22989146411418915\n",
            "Epoch 3, Processing batch 29853/30798\n",
            "Batch 29853 Loss: 0.022102326154708862\n",
            "Epoch 3, Processing batch 29854/30798\n",
            "Batch 29854 Loss: 0.05424955487251282\n",
            "Epoch 3, Processing batch 29855/30798\n",
            "Batch 29855 Loss: 0.1390801966190338\n",
            "Epoch 3, Processing batch 29856/30798\n",
            "Batch 29856 Loss: 0.31928423047065735\n",
            "Epoch 3, Processing batch 29857/30798\n",
            "Batch 29857 Loss: 0.0599062442779541\n",
            "Epoch 3, Processing batch 29858/30798\n",
            "Batch 29858 Loss: 0.13170279562473297\n",
            "Epoch 3, Processing batch 29859/30798\n",
            "Batch 29859 Loss: 0.006319466978311539\n",
            "Epoch 3, Processing batch 29860/30798\n",
            "Batch 29860 Loss: 0.08486499637365341\n",
            "Epoch 3, Processing batch 29861/30798\n",
            "Batch 29861 Loss: 0.5806441903114319\n",
            "Epoch 3, Processing batch 29862/30798\n",
            "Batch 29862 Loss: 0.39611732959747314\n",
            "Epoch 3, Processing batch 29863/30798\n",
            "Batch 29863 Loss: 0.02442822977900505\n",
            "Epoch 3, Processing batch 29864/30798\n",
            "Batch 29864 Loss: 0.003410747740417719\n",
            "Epoch 3, Processing batch 29865/30798\n",
            "Batch 29865 Loss: 0.07747756689786911\n",
            "Epoch 3, Processing batch 29866/30798\n",
            "Batch 29866 Loss: 0.07611899077892303\n",
            "Epoch 3, Processing batch 29867/30798\n",
            "Batch 29867 Loss: 3.9226698875427246\n",
            "Epoch 3, Processing batch 29868/30798\n",
            "Batch 29868 Loss: 0.7259610891342163\n",
            "Epoch 3, Processing batch 29869/30798\n",
            "Batch 29869 Loss: 0.03541574254631996\n",
            "Epoch 3, Processing batch 29870/30798\n",
            "Batch 29870 Loss: 0.00448319036513567\n",
            "Epoch 3, Processing batch 29871/30798\n",
            "Batch 29871 Loss: 0.06866306066513062\n",
            "Epoch 3, Processing batch 29872/30798\n",
            "Batch 29872 Loss: 0.07323692739009857\n",
            "Epoch 3, Processing batch 29873/30798\n",
            "Batch 29873 Loss: 0.10769754648208618\n",
            "Epoch 3, Processing batch 29874/30798\n",
            "Batch 29874 Loss: 0.08195969462394714\n",
            "Epoch 3, Processing batch 29875/30798\n",
            "Batch 29875 Loss: 0.008155970834195614\n",
            "Epoch 3, Processing batch 29876/30798\n",
            "Batch 29876 Loss: 0.014506037347018719\n",
            "Epoch 3, Processing batch 29877/30798\n",
            "Batch 29877 Loss: 0.08629918098449707\n",
            "Epoch 3, Processing batch 29878/30798\n",
            "Batch 29878 Loss: 0.06757329404354095\n",
            "Epoch 3, Processing batch 29879/30798\n",
            "Batch 29879 Loss: 0.05050090327858925\n",
            "Epoch 3, Processing batch 29880/30798\n",
            "Batch 29880 Loss: 1.0472160577774048\n",
            "Epoch 3, Processing batch 29881/30798\n",
            "Batch 29881 Loss: 0.23515373468399048\n",
            "Epoch 3, Processing batch 29882/30798\n",
            "Batch 29882 Loss: 0.007196987979114056\n",
            "Epoch 3, Processing batch 29883/30798\n",
            "Batch 29883 Loss: 0.004723158199340105\n",
            "Epoch 3, Processing batch 29884/30798\n",
            "Batch 29884 Loss: 0.08318962156772614\n",
            "Epoch 3, Processing batch 29885/30798\n",
            "Batch 29885 Loss: 0.006031656637787819\n",
            "Epoch 3, Processing batch 29886/30798\n",
            "Batch 29886 Loss: 0.11480658501386642\n",
            "Epoch 3, Processing batch 29887/30798\n",
            "Batch 29887 Loss: 0.02372613176703453\n",
            "Epoch 3, Processing batch 29888/30798\n",
            "Batch 29888 Loss: 0.0390770360827446\n",
            "Epoch 3, Processing batch 29889/30798\n",
            "Batch 29889 Loss: 0.004937625955790281\n",
            "Epoch 3, Processing batch 29890/30798\n",
            "Batch 29890 Loss: 0.6993467807769775\n",
            "Epoch 3, Processing batch 29891/30798\n",
            "Batch 29891 Loss: 0.6002558469772339\n",
            "Epoch 3, Processing batch 29892/30798\n",
            "Batch 29892 Loss: 0.2330923080444336\n",
            "Epoch 3, Processing batch 29893/30798\n",
            "Batch 29893 Loss: 0.023459790274500847\n",
            "Epoch 3, Processing batch 29894/30798\n",
            "Batch 29894 Loss: 2.5413482189178467\n",
            "Epoch 3, Processing batch 29895/30798\n",
            "Batch 29895 Loss: 0.11576247215270996\n",
            "Epoch 3, Processing batch 29896/30798\n",
            "Batch 29896 Loss: 0.1497081071138382\n",
            "Epoch 3, Processing batch 29897/30798\n",
            "Batch 29897 Loss: 0.3730558454990387\n",
            "Epoch 3, Processing batch 29898/30798\n",
            "Batch 29898 Loss: 0.018501877784729004\n",
            "Epoch 3, Processing batch 29899/30798\n",
            "Batch 29899 Loss: 0.5606170296669006\n",
            "Epoch 3, Processing batch 29900/30798\n",
            "Batch 29900 Loss: 0.8047550916671753\n",
            "Epoch 3, Processing batch 29901/30798\n",
            "Batch 29901 Loss: 0.021672293543815613\n",
            "Epoch 3, Processing batch 29902/30798\n",
            "Batch 29902 Loss: 0.1074087992310524\n",
            "Epoch 3, Processing batch 29903/30798\n",
            "Batch 29903 Loss: 0.039661020040512085\n",
            "Epoch 3, Processing batch 29904/30798\n",
            "Batch 29904 Loss: 0.150857612490654\n",
            "Epoch 3, Processing batch 29905/30798\n",
            "Batch 29905 Loss: 0.6166386008262634\n",
            "Epoch 3, Processing batch 29906/30798\n",
            "Batch 29906 Loss: 0.015546184033155441\n",
            "Epoch 3, Processing batch 29907/30798\n",
            "Batch 29907 Loss: 0.004004509653896093\n",
            "Epoch 3, Processing batch 29908/30798\n",
            "Batch 29908 Loss: 0.7109448909759521\n",
            "Epoch 3, Processing batch 29909/30798\n",
            "Batch 29909 Loss: 0.48410964012145996\n",
            "Epoch 3, Processing batch 29910/30798\n",
            "Batch 29910 Loss: 0.6756057739257812\n",
            "Epoch 3, Processing batch 29911/30798\n",
            "Batch 29911 Loss: 0.5916452407836914\n",
            "Epoch 3, Processing batch 29912/30798\n",
            "Batch 29912 Loss: 0.018458548933267593\n",
            "Epoch 3, Processing batch 29913/30798\n",
            "Batch 29913 Loss: 0.04937624931335449\n",
            "Epoch 3, Processing batch 29914/30798\n",
            "Batch 29914 Loss: 2.2826919555664062\n",
            "Epoch 3, Processing batch 29915/30798\n",
            "Batch 29915 Loss: 0.5492992401123047\n",
            "Epoch 3, Processing batch 29916/30798\n",
            "Batch 29916 Loss: 0.04662463814020157\n",
            "Epoch 3, Processing batch 29917/30798\n",
            "Batch 29917 Loss: 1.0993866920471191\n",
            "Epoch 3, Processing batch 29918/30798\n",
            "Batch 29918 Loss: 0.03673464059829712\n",
            "Epoch 3, Processing batch 29919/30798\n",
            "Batch 29919 Loss: 0.12024369835853577\n",
            "Epoch 3, Processing batch 29920/30798\n",
            "Batch 29920 Loss: 1.6054233312606812\n",
            "Epoch 3, Processing batch 29921/30798\n",
            "Batch 29921 Loss: 0.000779916881583631\n",
            "Epoch 3, Processing batch 29922/30798\n",
            "Batch 29922 Loss: 0.19619077444076538\n",
            "Epoch 3, Processing batch 29923/30798\n",
            "Batch 29923 Loss: 0.02287820167839527\n",
            "Epoch 3, Processing batch 29924/30798\n",
            "Batch 29924 Loss: 0.03987643122673035\n",
            "Epoch 3, Processing batch 29925/30798\n",
            "Batch 29925 Loss: 0.014779644086956978\n",
            "Epoch 3, Processing batch 29926/30798\n",
            "Batch 29926 Loss: 0.29101553559303284\n",
            "Epoch 3, Processing batch 29927/30798\n",
            "Batch 29927 Loss: 0.0017654995899647474\n",
            "Epoch 3, Processing batch 29928/30798\n",
            "Batch 29928 Loss: 0.09895866364240646\n",
            "Epoch 3, Processing batch 29929/30798\n",
            "Batch 29929 Loss: 0.007951009087264538\n",
            "Epoch 3, Processing batch 29930/30798\n",
            "Batch 29930 Loss: 0.015651885420084\n",
            "Epoch 3, Processing batch 29931/30798\n",
            "Batch 29931 Loss: 0.05411425232887268\n",
            "Epoch 3, Processing batch 29932/30798\n",
            "Batch 29932 Loss: 0.036096710711717606\n",
            "Epoch 3, Processing batch 29933/30798\n",
            "Batch 29933 Loss: 0.004788893274962902\n",
            "Epoch 3, Processing batch 29934/30798\n",
            "Batch 29934 Loss: 0.004442189820110798\n",
            "Epoch 3, Processing batch 29935/30798\n",
            "Batch 29935 Loss: 0.16700419783592224\n",
            "Epoch 3, Processing batch 29936/30798\n",
            "Batch 29936 Loss: 0.1715611070394516\n",
            "Epoch 3, Processing batch 29937/30798\n",
            "Batch 29937 Loss: 2.8796863555908203\n",
            "Epoch 3, Processing batch 29938/30798\n",
            "Batch 29938 Loss: 0.07312975078821182\n",
            "Epoch 3, Processing batch 29939/30798\n",
            "Batch 29939 Loss: 0.3888501822948456\n",
            "Epoch 3, Processing batch 29940/30798\n",
            "Batch 29940 Loss: 1.2209476232528687\n",
            "Epoch 3, Processing batch 29941/30798\n",
            "Batch 29941 Loss: 0.03207769617438316\n",
            "Epoch 3, Processing batch 29942/30798\n",
            "Batch 29942 Loss: 0.03653288260102272\n",
            "Epoch 3, Processing batch 29943/30798\n",
            "Batch 29943 Loss: 0.14405639469623566\n",
            "Epoch 3, Processing batch 29944/30798\n",
            "Batch 29944 Loss: 0.3490554094314575\n",
            "Epoch 3, Processing batch 29945/30798\n",
            "Batch 29945 Loss: 2.9652578830718994\n",
            "Epoch 3, Processing batch 29946/30798\n",
            "Batch 29946 Loss: 0.2951796054840088\n",
            "Epoch 3, Processing batch 29947/30798\n",
            "Batch 29947 Loss: 0.6190429925918579\n",
            "Epoch 3, Processing batch 29948/30798\n",
            "Batch 29948 Loss: 0.6480291485786438\n",
            "Epoch 3, Processing batch 29949/30798\n",
            "Batch 29949 Loss: 0.00561260711401701\n",
            "Epoch 3, Processing batch 29950/30798\n",
            "Batch 29950 Loss: 0.012624154798686504\n",
            "Epoch 3, Processing batch 29951/30798\n",
            "Batch 29951 Loss: 0.05635042116045952\n",
            "Epoch 3, Processing batch 29952/30798\n",
            "Batch 29952 Loss: 0.03360574319958687\n",
            "Epoch 3, Processing batch 29953/30798\n",
            "Batch 29953 Loss: 0.04977021366357803\n",
            "Epoch 3, Processing batch 29954/30798\n",
            "Batch 29954 Loss: 0.672621488571167\n",
            "Epoch 3, Processing batch 29955/30798\n",
            "Batch 29955 Loss: 1.1653553247451782\n",
            "Epoch 3, Processing batch 29956/30798\n",
            "Batch 29956 Loss: 0.038528334349393845\n",
            "Epoch 3, Processing batch 29957/30798\n",
            "Batch 29957 Loss: 0.05247245356440544\n",
            "Epoch 3, Processing batch 29958/30798\n",
            "Batch 29958 Loss: 0.00851004384458065\n",
            "Epoch 3, Processing batch 29959/30798\n",
            "Batch 29959 Loss: 0.2999027371406555\n",
            "Epoch 3, Processing batch 29960/30798\n",
            "Batch 29960 Loss: 0.7579834461212158\n",
            "Epoch 3, Processing batch 29961/30798\n",
            "Batch 29961 Loss: 0.04185701161623001\n",
            "Epoch 3, Processing batch 29962/30798\n",
            "Batch 29962 Loss: 0.15315397083759308\n",
            "Epoch 3, Processing batch 29963/30798\n",
            "Batch 29963 Loss: 0.0753491222858429\n",
            "Epoch 3, Processing batch 29964/30798\n",
            "Batch 29964 Loss: 0.07489936798810959\n",
            "Epoch 3, Processing batch 29965/30798\n",
            "Batch 29965 Loss: 0.12474872171878815\n",
            "Epoch 3, Processing batch 29966/30798\n",
            "Batch 29966 Loss: 0.012912704609334469\n",
            "Epoch 3, Processing batch 29967/30798\n",
            "Batch 29967 Loss: 0.0443052239716053\n",
            "Epoch 3, Processing batch 29968/30798\n",
            "Batch 29968 Loss: 0.08388189971446991\n",
            "Epoch 3, Processing batch 29969/30798\n",
            "Batch 29969 Loss: 0.03991331905126572\n",
            "Epoch 3, Processing batch 29970/30798\n",
            "Batch 29970 Loss: 0.37763512134552\n",
            "Epoch 3, Processing batch 29971/30798\n",
            "Batch 29971 Loss: 0.6572328209877014\n",
            "Epoch 3, Processing batch 29972/30798\n",
            "Batch 29972 Loss: 0.09185513854026794\n",
            "Epoch 3, Processing batch 29973/30798\n",
            "Batch 29973 Loss: 1.0399682521820068\n",
            "Epoch 3, Processing batch 29974/30798\n",
            "Batch 29974 Loss: 0.27733778953552246\n",
            "Epoch 3, Processing batch 29975/30798\n",
            "Batch 29975 Loss: 0.2818461060523987\n",
            "Epoch 3, Processing batch 29976/30798\n",
            "Batch 29976 Loss: 0.08595429360866547\n",
            "Epoch 3, Processing batch 29977/30798\n",
            "Batch 29977 Loss: 0.22917965054512024\n",
            "Epoch 3, Processing batch 29978/30798\n",
            "Batch 29978 Loss: 0.07383279502391815\n",
            "Epoch 3, Processing batch 29979/30798\n",
            "Batch 29979 Loss: 0.6234660148620605\n",
            "Epoch 3, Processing batch 29980/30798\n",
            "Batch 29980 Loss: 0.07602044939994812\n",
            "Epoch 3, Processing batch 29981/30798\n",
            "Batch 29981 Loss: 0.0811118632555008\n",
            "Epoch 3, Processing batch 29982/30798\n",
            "Batch 29982 Loss: 0.3842093050479889\n",
            "Epoch 3, Processing batch 29983/30798\n",
            "Batch 29983 Loss: 0.0058939335867762566\n",
            "Epoch 3, Processing batch 29984/30798\n",
            "Batch 29984 Loss: 0.011537929996848106\n",
            "Epoch 3, Processing batch 29985/30798\n",
            "Batch 29985 Loss: 0.010980691760778427\n",
            "Epoch 3, Processing batch 29986/30798\n",
            "Batch 29986 Loss: 0.3128332793712616\n",
            "Epoch 3, Processing batch 29987/30798\n",
            "Batch 29987 Loss: 0.021808870136737823\n",
            "Epoch 3, Processing batch 29988/30798\n",
            "Batch 29988 Loss: 0.04809581860899925\n",
            "Epoch 3, Processing batch 29989/30798\n",
            "Batch 29989 Loss: 0.02170397713780403\n",
            "Epoch 3, Processing batch 29990/30798\n",
            "Batch 29990 Loss: 0.09790270030498505\n",
            "Epoch 3, Processing batch 29991/30798\n",
            "Batch 29991 Loss: 0.1661982536315918\n",
            "Epoch 3, Processing batch 29992/30798\n",
            "Batch 29992 Loss: 0.007602641824632883\n",
            "Epoch 3, Processing batch 29993/30798\n",
            "Batch 29993 Loss: 0.01688837632536888\n",
            "Epoch 3, Processing batch 29994/30798\n",
            "Batch 29994 Loss: 0.0019361909944564104\n",
            "Epoch 3, Processing batch 29995/30798\n",
            "Batch 29995 Loss: 0.7873196601867676\n",
            "Epoch 3, Processing batch 29996/30798\n",
            "Batch 29996 Loss: 1.224412441253662\n",
            "Epoch 3, Processing batch 29997/30798\n",
            "Batch 29997 Loss: 0.08904135972261429\n",
            "Epoch 3, Processing batch 29998/30798\n",
            "Batch 29998 Loss: 0.2625933885574341\n",
            "Epoch 3, Processing batch 29999/30798\n",
            "Batch 29999 Loss: 0.022297168150544167\n",
            "Epoch 3, Processing batch 30000/30798\n",
            "Batch 30000 Loss: 0.13059751689434052\n",
            "Epoch 3, Processing batch 30001/30798\n",
            "Batch 30001 Loss: 1.1312401294708252\n",
            "Epoch 3, Processing batch 30002/30798\n",
            "Batch 30002 Loss: 0.28392428159713745\n",
            "Epoch 3, Processing batch 30003/30798\n",
            "Batch 30003 Loss: 0.8952507972717285\n",
            "Epoch 3, Processing batch 30004/30798\n",
            "Batch 30004 Loss: 0.025843007490038872\n",
            "Epoch 3, Processing batch 30005/30798\n",
            "Batch 30005 Loss: 0.4571058452129364\n",
            "Epoch 3, Processing batch 30006/30798\n",
            "Batch 30006 Loss: 0.11485908925533295\n",
            "Epoch 3, Processing batch 30007/30798\n",
            "Batch 30007 Loss: 0.0015263011446222663\n",
            "Epoch 3, Processing batch 30008/30798\n",
            "Batch 30008 Loss: 1.6918895244598389\n",
            "Epoch 3, Processing batch 30009/30798\n",
            "Batch 30009 Loss: 3.3713314533233643\n",
            "Epoch 3, Processing batch 30010/30798\n",
            "Batch 30010 Loss: 0.7971360087394714\n",
            "Epoch 3, Processing batch 30011/30798\n",
            "Batch 30011 Loss: 0.0284896157681942\n",
            "Epoch 3, Processing batch 30012/30798\n",
            "Batch 30012 Loss: 0.1206616759300232\n",
            "Epoch 3, Processing batch 30013/30798\n",
            "Batch 30013 Loss: 0.03036484867334366\n",
            "Epoch 3, Processing batch 30014/30798\n",
            "Batch 30014 Loss: 0.8774389028549194\n",
            "Epoch 3, Processing batch 30015/30798\n",
            "Batch 30015 Loss: 0.21536089479923248\n",
            "Epoch 3, Processing batch 30016/30798\n",
            "Batch 30016 Loss: 0.052618976682424545\n",
            "Epoch 3, Processing batch 30017/30798\n",
            "Batch 30017 Loss: 0.13706330955028534\n",
            "Epoch 3, Processing batch 30018/30798\n",
            "Batch 30018 Loss: 0.8183156251907349\n",
            "Epoch 3, Processing batch 30019/30798\n",
            "Batch 30019 Loss: 0.09467032551765442\n",
            "Epoch 3, Processing batch 30020/30798\n",
            "Batch 30020 Loss: 0.05628274008631706\n",
            "Epoch 3, Processing batch 30021/30798\n",
            "Batch 30021 Loss: 7.2355122566223145\n",
            "Epoch 3, Processing batch 30022/30798\n",
            "Batch 30022 Loss: 0.03202199935913086\n",
            "Epoch 3, Processing batch 30023/30798\n",
            "Batch 30023 Loss: 0.26660826802253723\n",
            "Epoch 3, Processing batch 30024/30798\n",
            "Batch 30024 Loss: 0.012359879910945892\n",
            "Epoch 3, Processing batch 30025/30798\n",
            "Batch 30025 Loss: 0.0881476029753685\n",
            "Epoch 3, Processing batch 30026/30798\n",
            "Batch 30026 Loss: 0.05484510213136673\n",
            "Epoch 3, Processing batch 30027/30798\n",
            "Batch 30027 Loss: 0.2407981902360916\n",
            "Epoch 3, Processing batch 30028/30798\n",
            "Batch 30028 Loss: 0.15269918739795685\n",
            "Epoch 3, Processing batch 30029/30798\n",
            "Batch 30029 Loss: 0.003703330410644412\n",
            "Epoch 3, Processing batch 30030/30798\n",
            "Batch 30030 Loss: 0.7197858095169067\n",
            "Epoch 3, Processing batch 30031/30798\n",
            "Batch 30031 Loss: 1.4901667833328247\n",
            "Epoch 3, Processing batch 30032/30798\n",
            "Batch 30032 Loss: 0.08076173067092896\n",
            "Epoch 3, Processing batch 30033/30798\n",
            "Batch 30033 Loss: 1.0986690521240234\n",
            "Epoch 3, Processing batch 30034/30798\n",
            "Batch 30034 Loss: 2.8413472175598145\n",
            "Epoch 3, Processing batch 30035/30798\n",
            "Batch 30035 Loss: 0.005092968698590994\n",
            "Epoch 3, Processing batch 30036/30798\n",
            "Batch 30036 Loss: 0.032112967222929\n",
            "Epoch 3, Processing batch 30037/30798\n",
            "Batch 30037 Loss: 0.0014733048155903816\n",
            "Epoch 3, Processing batch 30038/30798\n",
            "Batch 30038 Loss: 0.71446293592453\n",
            "Epoch 3, Processing batch 30039/30798\n",
            "Batch 30039 Loss: 0.0031842640601098537\n",
            "Epoch 3, Processing batch 30040/30798\n",
            "Batch 30040 Loss: 0.025204090401530266\n",
            "Epoch 3, Processing batch 30041/30798\n",
            "Batch 30041 Loss: 0.041433218866586685\n",
            "Epoch 3, Processing batch 30042/30798\n",
            "Batch 30042 Loss: 2.3217360973358154\n",
            "Epoch 3, Processing batch 30043/30798\n",
            "Batch 30043 Loss: 0.054975200444459915\n",
            "Epoch 3, Processing batch 30044/30798\n",
            "Batch 30044 Loss: 0.16773861646652222\n",
            "Epoch 3, Processing batch 30045/30798\n",
            "Batch 30045 Loss: 0.11552060395479202\n",
            "Epoch 3, Processing batch 30046/30798\n",
            "Batch 30046 Loss: 0.36544784903526306\n",
            "Epoch 3, Processing batch 30047/30798\n",
            "Batch 30047 Loss: 0.009209178388118744\n",
            "Epoch 3, Processing batch 30048/30798\n",
            "Batch 30048 Loss: 1.3832720518112183\n",
            "Epoch 3, Processing batch 30049/30798\n",
            "Batch 30049 Loss: 0.17146529257297516\n",
            "Epoch 3, Processing batch 30050/30798\n",
            "Batch 30050 Loss: 0.09381495416164398\n",
            "Epoch 3, Processing batch 30051/30798\n",
            "Batch 30051 Loss: 0.0416756309568882\n",
            "Epoch 3, Processing batch 30052/30798\n",
            "Batch 30052 Loss: 0.22868101298809052\n",
            "Epoch 3, Processing batch 30053/30798\n",
            "Batch 30053 Loss: 0.24728770554065704\n",
            "Epoch 3, Processing batch 30054/30798\n",
            "Batch 30054 Loss: 0.1348222941160202\n",
            "Epoch 3, Processing batch 30055/30798\n",
            "Batch 30055 Loss: 0.016483278945088387\n",
            "Epoch 3, Processing batch 30056/30798\n",
            "Batch 30056 Loss: 0.2680031955242157\n",
            "Epoch 3, Processing batch 30057/30798\n",
            "Batch 30057 Loss: 0.006229681894183159\n",
            "Epoch 3, Processing batch 30058/30798\n",
            "Batch 30058 Loss: 0.02504495531320572\n",
            "Epoch 3, Processing batch 30059/30798\n",
            "Batch 30059 Loss: 0.1735384166240692\n",
            "Epoch 3, Processing batch 30060/30798\n",
            "Batch 30060 Loss: 0.009768188931047916\n",
            "Epoch 3, Processing batch 30061/30798\n",
            "Batch 30061 Loss: 1.1714146137237549\n",
            "Epoch 3, Processing batch 30062/30798\n",
            "Batch 30062 Loss: 0.1301962286233902\n",
            "Epoch 3, Processing batch 30063/30798\n",
            "Batch 30063 Loss: 0.3323347866535187\n",
            "Epoch 3, Processing batch 30064/30798\n",
            "Batch 30064 Loss: 0.1468050628900528\n",
            "Epoch 3, Processing batch 30065/30798\n",
            "Batch 30065 Loss: 0.9507639408111572\n",
            "Epoch 3, Processing batch 30066/30798\n",
            "Batch 30066 Loss: 0.04842405766248703\n",
            "Epoch 3, Processing batch 30067/30798\n",
            "Batch 30067 Loss: 0.34202414751052856\n",
            "Epoch 3, Processing batch 30068/30798\n",
            "Batch 30068 Loss: 0.005495314486324787\n",
            "Epoch 3, Processing batch 30069/30798\n",
            "Batch 30069 Loss: 0.02130303345620632\n",
            "Epoch 3, Processing batch 30070/30798\n",
            "Batch 30070 Loss: 0.03834439441561699\n",
            "Epoch 3, Processing batch 30071/30798\n",
            "Batch 30071 Loss: 0.24408411979675293\n",
            "Epoch 3, Processing batch 30072/30798\n",
            "Batch 30072 Loss: 0.1605253964662552\n",
            "Epoch 3, Processing batch 30073/30798\n",
            "Batch 30073 Loss: 0.10400664806365967\n",
            "Epoch 3, Processing batch 30074/30798\n",
            "Batch 30074 Loss: 0.35962679982185364\n",
            "Epoch 3, Processing batch 30075/30798\n",
            "Batch 30075 Loss: 0.025455011054873466\n",
            "Epoch 3, Processing batch 30076/30798\n",
            "Batch 30076 Loss: 0.10432673990726471\n",
            "Epoch 3, Processing batch 30077/30798\n",
            "Batch 30077 Loss: 0.25987958908081055\n",
            "Epoch 3, Processing batch 30078/30798\n",
            "Batch 30078 Loss: 0.683837890625\n",
            "Epoch 3, Processing batch 30079/30798\n",
            "Batch 30079 Loss: 0.05382538586854935\n",
            "Epoch 3, Processing batch 30080/30798\n",
            "Batch 30080 Loss: 0.08917348086833954\n",
            "Epoch 3, Processing batch 30081/30798\n",
            "Batch 30081 Loss: 0.07317222654819489\n",
            "Epoch 3, Processing batch 30082/30798\n",
            "Batch 30082 Loss: 0.11753951758146286\n",
            "Epoch 3, Processing batch 30083/30798\n",
            "Batch 30083 Loss: 0.702759861946106\n",
            "Epoch 3, Processing batch 30084/30798\n",
            "Batch 30084 Loss: 0.5135905742645264\n",
            "Epoch 3, Processing batch 30085/30798\n",
            "Batch 30085 Loss: 0.08569961786270142\n",
            "Epoch 3, Processing batch 30086/30798\n",
            "Batch 30086 Loss: 0.15845102071762085\n",
            "Epoch 3, Processing batch 30087/30798\n",
            "Batch 30087 Loss: 0.09536141157150269\n",
            "Epoch 3, Processing batch 30088/30798\n",
            "Batch 30088 Loss: 0.05403336510062218\n",
            "Epoch 3, Processing batch 30089/30798\n",
            "Batch 30089 Loss: 0.017065204679965973\n",
            "Epoch 3, Processing batch 30090/30798\n",
            "Batch 30090 Loss: 4.32224702835083\n",
            "Epoch 3, Processing batch 30091/30798\n",
            "Batch 30091 Loss: 0.0459296815097332\n",
            "Epoch 3, Processing batch 30092/30798\n",
            "Batch 30092 Loss: 0.01675201952457428\n",
            "Epoch 3, Processing batch 30093/30798\n",
            "Batch 30093 Loss: 0.09108317643404007\n",
            "Epoch 3, Processing batch 30094/30798\n",
            "Batch 30094 Loss: 0.1275911033153534\n",
            "Epoch 3, Processing batch 30095/30798\n",
            "Batch 30095 Loss: 1.3201044797897339\n",
            "Epoch 3, Processing batch 30096/30798\n",
            "Batch 30096 Loss: 0.10722724348306656\n",
            "Epoch 3, Processing batch 30097/30798\n",
            "Batch 30097 Loss: 0.009585152380168438\n",
            "Epoch 3, Processing batch 30098/30798\n",
            "Batch 30098 Loss: 0.14371086657047272\n",
            "Epoch 3, Processing batch 30099/30798\n",
            "Batch 30099 Loss: 0.33606478571891785\n",
            "Epoch 3, Processing batch 30100/30798\n",
            "Batch 30100 Loss: 0.03456081449985504\n",
            "Epoch 3, Processing batch 30101/30798\n",
            "Batch 30101 Loss: 0.12412363290786743\n",
            "Epoch 3, Processing batch 30102/30798\n",
            "Batch 30102 Loss: 0.06425682455301285\n",
            "Epoch 3, Processing batch 30103/30798\n",
            "Batch 30103 Loss: 0.03307370841503143\n",
            "Epoch 3, Processing batch 30104/30798\n",
            "Batch 30104 Loss: 0.28840917348861694\n",
            "Epoch 3, Processing batch 30105/30798\n",
            "Batch 30105 Loss: 0.1667717695236206\n",
            "Epoch 3, Processing batch 30106/30798\n",
            "Batch 30106 Loss: 0.04980289936065674\n",
            "Epoch 3, Processing batch 30107/30798\n",
            "Batch 30107 Loss: 0.003794461954385042\n",
            "Epoch 3, Processing batch 30108/30798\n",
            "Batch 30108 Loss: 0.005005168728530407\n",
            "Epoch 3, Processing batch 30109/30798\n",
            "Batch 30109 Loss: 0.08610620349645615\n",
            "Epoch 3, Processing batch 30110/30798\n",
            "Batch 30110 Loss: 0.21696564555168152\n",
            "Epoch 3, Processing batch 30111/30798\n",
            "Batch 30111 Loss: 1.3772978782653809\n",
            "Epoch 3, Processing batch 30112/30798\n",
            "Batch 30112 Loss: 0.009742885828018188\n",
            "Epoch 3, Processing batch 30113/30798\n",
            "Batch 30113 Loss: 0.1205512210726738\n",
            "Epoch 3, Processing batch 30114/30798\n",
            "Batch 30114 Loss: 0.017231708392500877\n",
            "Epoch 3, Processing batch 30115/30798\n",
            "Batch 30115 Loss: 2.0320193767547607\n",
            "Epoch 3, Processing batch 30116/30798\n",
            "Batch 30116 Loss: 0.11634773015975952\n",
            "Epoch 3, Processing batch 30117/30798\n",
            "Batch 30117 Loss: 0.05726424232125282\n",
            "Epoch 3, Processing batch 30118/30798\n",
            "Batch 30118 Loss: 0.3861888647079468\n",
            "Epoch 3, Processing batch 30119/30798\n",
            "Batch 30119 Loss: 0.030944235622882843\n",
            "Epoch 3, Processing batch 30120/30798\n",
            "Batch 30120 Loss: 0.04758679121732712\n",
            "Epoch 3, Processing batch 30121/30798\n",
            "Batch 30121 Loss: 0.007481993176043034\n",
            "Epoch 3, Processing batch 30122/30798\n",
            "Batch 30122 Loss: 0.09964191913604736\n",
            "Epoch 3, Processing batch 30123/30798\n",
            "Batch 30123 Loss: 0.15378469228744507\n",
            "Epoch 3, Processing batch 30124/30798\n",
            "Batch 30124 Loss: 0.1930154711008072\n",
            "Epoch 3, Processing batch 30125/30798\n",
            "Batch 30125 Loss: 0.4610615372657776\n",
            "Epoch 3, Processing batch 30126/30798\n",
            "Batch 30126 Loss: 0.693412721157074\n",
            "Epoch 3, Processing batch 30127/30798\n",
            "Batch 30127 Loss: 0.18537503480911255\n",
            "Epoch 3, Processing batch 30128/30798\n",
            "Batch 30128 Loss: 0.038114503026008606\n",
            "Epoch 3, Processing batch 30129/30798\n",
            "Batch 30129 Loss: 0.009841520339250565\n",
            "Epoch 3, Processing batch 30130/30798\n",
            "Batch 30130 Loss: 0.10220606625080109\n",
            "Epoch 3, Processing batch 30131/30798\n",
            "Batch 30131 Loss: 0.03229885175824165\n",
            "Epoch 3, Processing batch 30132/30798\n",
            "Batch 30132 Loss: 0.9080182313919067\n",
            "Epoch 3, Processing batch 30133/30798\n",
            "Batch 30133 Loss: 1.1298214197158813\n",
            "Epoch 3, Processing batch 30134/30798\n",
            "Batch 30134 Loss: 0.22398866713047028\n",
            "Epoch 3, Processing batch 30135/30798\n",
            "Batch 30135 Loss: 0.04713595658540726\n",
            "Epoch 3, Processing batch 30136/30798\n",
            "Batch 30136 Loss: 0.5532958507537842\n",
            "Epoch 3, Processing batch 30137/30798\n",
            "Batch 30137 Loss: 1.2309138774871826\n",
            "Epoch 3, Processing batch 30138/30798\n",
            "Batch 30138 Loss: 0.26871562004089355\n",
            "Epoch 3, Processing batch 30139/30798\n",
            "Batch 30139 Loss: 1.8849276304244995\n",
            "Epoch 3, Processing batch 30140/30798\n",
            "Batch 30140 Loss: 0.07819630205631256\n",
            "Epoch 3, Processing batch 30141/30798\n",
            "Batch 30141 Loss: 0.11981915682554245\n",
            "Epoch 3, Processing batch 30142/30798\n",
            "Batch 30142 Loss: 0.24470362067222595\n",
            "Epoch 3, Processing batch 30143/30798\n",
            "Batch 30143 Loss: 0.0709758996963501\n",
            "Epoch 3, Processing batch 30144/30798\n",
            "Batch 30144 Loss: 0.3951238989830017\n",
            "Epoch 3, Processing batch 30145/30798\n",
            "Batch 30145 Loss: 0.17132467031478882\n",
            "Epoch 3, Processing batch 30146/30798\n",
            "Batch 30146 Loss: 0.8947098851203918\n",
            "Epoch 3, Processing batch 30147/30798\n",
            "Batch 30147 Loss: 1.511760950088501\n",
            "Epoch 3, Processing batch 30148/30798\n",
            "Batch 30148 Loss: 0.0670594647526741\n",
            "Epoch 3, Processing batch 30149/30798\n",
            "Batch 30149 Loss: 0.13139113783836365\n",
            "Epoch 3, Processing batch 30150/30798\n",
            "Batch 30150 Loss: 1.7487561702728271\n",
            "Epoch 3, Processing batch 30151/30798\n",
            "Batch 30151 Loss: 0.5087593793869019\n",
            "Epoch 3, Processing batch 30152/30798\n",
            "Batch 30152 Loss: 0.7002649903297424\n",
            "Epoch 3, Processing batch 30153/30798\n",
            "Batch 30153 Loss: 0.086275614798069\n",
            "Epoch 3, Processing batch 30154/30798\n",
            "Batch 30154 Loss: 0.42345330119132996\n",
            "Epoch 3, Processing batch 30155/30798\n",
            "Batch 30155 Loss: 1.1504257917404175\n",
            "Epoch 3, Processing batch 30156/30798\n",
            "Batch 30156 Loss: 0.19825182855129242\n",
            "Epoch 3, Processing batch 30157/30798\n",
            "Batch 30157 Loss: 1.6709871292114258\n",
            "Epoch 3, Processing batch 30158/30798\n",
            "Batch 30158 Loss: 0.039194557815790176\n",
            "Epoch 3, Processing batch 30159/30798\n",
            "Batch 30159 Loss: 2.031855821609497\n",
            "Epoch 3, Processing batch 30160/30798\n",
            "Batch 30160 Loss: 1.2921745777130127\n",
            "Epoch 3, Processing batch 30161/30798\n",
            "Batch 30161 Loss: 0.010880351066589355\n",
            "Epoch 3, Processing batch 30162/30798\n",
            "Batch 30162 Loss: 0.31625837087631226\n",
            "Epoch 3, Processing batch 30163/30798\n",
            "Batch 30163 Loss: 0.4103257656097412\n",
            "Epoch 3, Processing batch 30164/30798\n",
            "Batch 30164 Loss: 0.07477030158042908\n",
            "Epoch 3, Processing batch 30165/30798\n",
            "Batch 30165 Loss: 0.004568682052195072\n",
            "Epoch 3, Processing batch 30166/30798\n",
            "Batch 30166 Loss: 0.017138758674263954\n",
            "Epoch 3, Processing batch 30167/30798\n",
            "Batch 30167 Loss: 0.13332079350948334\n",
            "Epoch 3, Processing batch 30168/30798\n",
            "Batch 30168 Loss: 0.06166691333055496\n",
            "Epoch 3, Processing batch 30169/30798\n",
            "Batch 30169 Loss: 0.023314977064728737\n",
            "Epoch 3, Processing batch 30170/30798\n",
            "Batch 30170 Loss: 0.048499852418899536\n",
            "Epoch 3, Processing batch 30171/30798\n",
            "Batch 30171 Loss: 0.09996900707483292\n",
            "Epoch 3, Processing batch 30172/30798\n",
            "Batch 30172 Loss: 0.024839326739311218\n",
            "Epoch 3, Processing batch 30173/30798\n",
            "Batch 30173 Loss: 0.15029793977737427\n",
            "Epoch 3, Processing batch 30174/30798\n",
            "Batch 30174 Loss: 0.004091557580977678\n",
            "Epoch 3, Processing batch 30175/30798\n",
            "Batch 30175 Loss: 0.6635872721672058\n",
            "Epoch 3, Processing batch 30176/30798\n",
            "Batch 30176 Loss: 1.0537105798721313\n",
            "Epoch 3, Processing batch 30177/30798\n",
            "Batch 30177 Loss: 0.022816935554146767\n",
            "Epoch 3, Processing batch 30178/30798\n",
            "Batch 30178 Loss: 0.22535543143749237\n",
            "Epoch 3, Processing batch 30179/30798\n",
            "Batch 30179 Loss: 0.03363099694252014\n",
            "Epoch 3, Processing batch 30180/30798\n",
            "Batch 30180 Loss: 0.04423948749899864\n",
            "Epoch 3, Processing batch 30181/30798\n",
            "Batch 30181 Loss: 0.1360764354467392\n",
            "Epoch 3, Processing batch 30182/30798\n",
            "Batch 30182 Loss: 0.08731988817453384\n",
            "Epoch 3, Processing batch 30183/30798\n",
            "Batch 30183 Loss: 0.015082134865224361\n",
            "Epoch 3, Processing batch 30184/30798\n",
            "Batch 30184 Loss: 0.13015638291835785\n",
            "Epoch 3, Processing batch 30185/30798\n",
            "Batch 30185 Loss: 0.07857851684093475\n",
            "Epoch 3, Processing batch 30186/30798\n",
            "Batch 30186 Loss: 0.21448828279972076\n",
            "Epoch 3, Processing batch 30187/30798\n",
            "Batch 30187 Loss: 0.13116692006587982\n",
            "Epoch 3, Processing batch 30188/30798\n",
            "Batch 30188 Loss: 0.8061876893043518\n",
            "Epoch 3, Processing batch 30189/30798\n",
            "Batch 30189 Loss: 0.09618744999170303\n",
            "Epoch 3, Processing batch 30190/30798\n",
            "Batch 30190 Loss: 0.3477077782154083\n",
            "Epoch 3, Processing batch 30191/30798\n",
            "Batch 30191 Loss: 0.16456957161426544\n",
            "Epoch 3, Processing batch 30192/30798\n",
            "Batch 30192 Loss: 0.011154860258102417\n",
            "Epoch 3, Processing batch 30193/30798\n",
            "Batch 30193 Loss: 0.14124220609664917\n",
            "Epoch 3, Processing batch 30194/30798\n",
            "Batch 30194 Loss: 0.02011708915233612\n",
            "Epoch 3, Processing batch 30195/30798\n",
            "Batch 30195 Loss: 1.298190951347351\n",
            "Epoch 3, Processing batch 30196/30798\n",
            "Batch 30196 Loss: 0.04862748831510544\n",
            "Epoch 3, Processing batch 30197/30798\n",
            "Batch 30197 Loss: 0.9462977051734924\n",
            "Epoch 3, Processing batch 30198/30798\n",
            "Batch 30198 Loss: 1.819872260093689\n",
            "Epoch 3, Processing batch 30199/30798\n",
            "Batch 30199 Loss: 0.030275210738182068\n",
            "Epoch 3, Processing batch 30200/30798\n",
            "Batch 30200 Loss: 0.03411266952753067\n",
            "Epoch 3, Processing batch 30201/30798\n",
            "Batch 30201 Loss: 0.004123893566429615\n",
            "Epoch 3, Processing batch 30202/30798\n",
            "Batch 30202 Loss: 0.03203316032886505\n",
            "Epoch 3, Processing batch 30203/30798\n",
            "Batch 30203 Loss: 0.05871458351612091\n",
            "Epoch 3, Processing batch 30204/30798\n",
            "Batch 30204 Loss: 0.024574674665927887\n",
            "Epoch 3, Processing batch 30205/30798\n",
            "Batch 30205 Loss: 1.4746081829071045\n",
            "Epoch 3, Processing batch 30206/30798\n",
            "Batch 30206 Loss: 2.2105319499969482\n",
            "Epoch 3, Processing batch 30207/30798\n",
            "Batch 30207 Loss: 0.00416343379765749\n",
            "Epoch 3, Processing batch 30208/30798\n",
            "Batch 30208 Loss: 0.06601754575967789\n",
            "Epoch 3, Processing batch 30209/30798\n",
            "Batch 30209 Loss: 0.09895052015781403\n",
            "Epoch 3, Processing batch 30210/30798\n",
            "Batch 30210 Loss: 0.1333005577325821\n",
            "Epoch 3, Processing batch 30211/30798\n",
            "Batch 30211 Loss: 1.58770751953125\n",
            "Epoch 3, Processing batch 30212/30798\n",
            "Batch 30212 Loss: 0.02708660624921322\n",
            "Epoch 3, Processing batch 30213/30798\n",
            "Batch 30213 Loss: 0.18496640026569366\n",
            "Epoch 3, Processing batch 30214/30798\n",
            "Batch 30214 Loss: 0.81304532289505\n",
            "Epoch 3, Processing batch 30215/30798\n",
            "Batch 30215 Loss: 0.8931148648262024\n",
            "Epoch 3, Processing batch 30216/30798\n",
            "Batch 30216 Loss: 0.16557611525058746\n",
            "Epoch 3, Processing batch 30217/30798\n",
            "Batch 30217 Loss: 0.155985489487648\n",
            "Epoch 3, Processing batch 30218/30798\n",
            "Batch 30218 Loss: 2.0425357818603516\n",
            "Epoch 3, Processing batch 30219/30798\n",
            "Batch 30219 Loss: 0.1197185143828392\n",
            "Epoch 3, Processing batch 30220/30798\n",
            "Batch 30220 Loss: 0.25599613785743713\n",
            "Epoch 3, Processing batch 30221/30798\n",
            "Batch 30221 Loss: 0.563156247138977\n",
            "Epoch 3, Processing batch 30222/30798\n",
            "Batch 30222 Loss: 0.004259841982275248\n",
            "Epoch 3, Processing batch 30223/30798\n",
            "Batch 30223 Loss: 0.07956616580486298\n",
            "Epoch 3, Processing batch 30224/30798\n",
            "Batch 30224 Loss: 0.06935374438762665\n",
            "Epoch 3, Processing batch 30225/30798\n",
            "Batch 30225 Loss: 0.034519679844379425\n",
            "Epoch 3, Processing batch 30226/30798\n",
            "Batch 30226 Loss: 0.1402008980512619\n",
            "Epoch 3, Processing batch 30227/30798\n",
            "Batch 30227 Loss: 2.6891582012176514\n",
            "Epoch 3, Processing batch 30228/30798\n",
            "Batch 30228 Loss: 0.14239461719989777\n",
            "Epoch 3, Processing batch 30229/30798\n",
            "Batch 30229 Loss: 0.49410203099250793\n",
            "Epoch 3, Processing batch 30230/30798\n",
            "Batch 30230 Loss: 0.02845384180545807\n",
            "Epoch 3, Processing batch 30231/30798\n",
            "Batch 30231 Loss: 0.005299337208271027\n",
            "Epoch 3, Processing batch 30232/30798\n",
            "Batch 30232 Loss: 3.0987441539764404\n",
            "Epoch 3, Processing batch 30233/30798\n",
            "Batch 30233 Loss: 0.4949907064437866\n",
            "Epoch 3, Processing batch 30234/30798\n",
            "Batch 30234 Loss: 0.11398892104625702\n",
            "Epoch 3, Processing batch 30235/30798\n",
            "Batch 30235 Loss: 0.1147959753870964\n",
            "Epoch 3, Processing batch 30236/30798\n",
            "Batch 30236 Loss: 0.4032793641090393\n",
            "Epoch 3, Processing batch 30237/30798\n",
            "Batch 30237 Loss: 0.0392858162522316\n",
            "Epoch 3, Processing batch 30238/30798\n",
            "Batch 30238 Loss: 0.6151105165481567\n",
            "Epoch 3, Processing batch 30239/30798\n",
            "Batch 30239 Loss: 0.39099252223968506\n",
            "Epoch 3, Processing batch 30240/30798\n",
            "Batch 30240 Loss: 0.459139883518219\n",
            "Epoch 3, Processing batch 30241/30798\n",
            "Batch 30241 Loss: 0.018732577562332153\n",
            "Epoch 3, Processing batch 30242/30798\n",
            "Batch 30242 Loss: 0.12944714725017548\n",
            "Epoch 3, Processing batch 30243/30798\n",
            "Batch 30243 Loss: 0.21819429099559784\n",
            "Epoch 3, Processing batch 30244/30798\n",
            "Batch 30244 Loss: 0.008436965756118298\n",
            "Epoch 3, Processing batch 30245/30798\n",
            "Batch 30245 Loss: 0.32553189992904663\n",
            "Epoch 3, Processing batch 30246/30798\n",
            "Batch 30246 Loss: 0.1142844632267952\n",
            "Epoch 3, Processing batch 30247/30798\n",
            "Batch 30247 Loss: 0.8270958662033081\n",
            "Epoch 3, Processing batch 30248/30798\n",
            "Batch 30248 Loss: 0.04700611159205437\n",
            "Epoch 3, Processing batch 30249/30798\n",
            "Batch 30249 Loss: 0.05171646177768707\n",
            "Epoch 3, Processing batch 30250/30798\n",
            "Batch 30250 Loss: 0.07515840232372284\n",
            "Epoch 3, Processing batch 30251/30798\n",
            "Batch 30251 Loss: 0.7428475618362427\n",
            "Epoch 3, Processing batch 30252/30798\n",
            "Batch 30252 Loss: 0.09318891167640686\n",
            "Epoch 3, Processing batch 30253/30798\n",
            "Batch 30253 Loss: 0.6833955645561218\n",
            "Epoch 3, Processing batch 30254/30798\n",
            "Batch 30254 Loss: 0.8551640510559082\n",
            "Epoch 3, Processing batch 30255/30798\n",
            "Batch 30255 Loss: 0.14857016503810883\n",
            "Epoch 3, Processing batch 30256/30798\n",
            "Batch 30256 Loss: 0.19690050184726715\n",
            "Epoch 3, Processing batch 30257/30798\n",
            "Batch 30257 Loss: 0.13421079516410828\n",
            "Epoch 3, Processing batch 30258/30798\n",
            "Batch 30258 Loss: 0.13711999356746674\n",
            "Epoch 3, Processing batch 30259/30798\n",
            "Batch 30259 Loss: 0.09410373866558075\n",
            "Epoch 3, Processing batch 30260/30798\n",
            "Batch 30260 Loss: 0.014463244937360287\n",
            "Epoch 3, Processing batch 30261/30798\n",
            "Batch 30261 Loss: 0.11871819198131561\n",
            "Epoch 3, Processing batch 30262/30798\n",
            "Batch 30262 Loss: 0.0063063702546060085\n",
            "Epoch 3, Processing batch 30263/30798\n",
            "Batch 30263 Loss: 0.10471145808696747\n",
            "Epoch 3, Processing batch 30264/30798\n",
            "Batch 30264 Loss: 0.06474580615758896\n",
            "Epoch 3, Processing batch 30265/30798\n",
            "Batch 30265 Loss: 0.37291333079338074\n",
            "Epoch 3, Processing batch 30266/30798\n",
            "Batch 30266 Loss: 0.6186683773994446\n",
            "Epoch 3, Processing batch 30267/30798\n",
            "Batch 30267 Loss: 0.7093721628189087\n",
            "Epoch 3, Processing batch 30268/30798\n",
            "Batch 30268 Loss: 0.6669716835021973\n",
            "Epoch 3, Processing batch 30269/30798\n",
            "Batch 30269 Loss: 0.21704460680484772\n",
            "Epoch 3, Processing batch 30270/30798\n",
            "Batch 30270 Loss: 0.8205481171607971\n",
            "Epoch 3, Processing batch 30271/30798\n",
            "Batch 30271 Loss: 0.4936358332633972\n",
            "Epoch 3, Processing batch 30272/30798\n",
            "Batch 30272 Loss: 0.27910521626472473\n",
            "Epoch 3, Processing batch 30273/30798\n",
            "Batch 30273 Loss: 0.0031565504614263773\n",
            "Epoch 3, Processing batch 30274/30798\n",
            "Batch 30274 Loss: 0.006877736188471317\n",
            "Epoch 3, Processing batch 30275/30798\n",
            "Batch 30275 Loss: 0.0072542461566627026\n",
            "Epoch 3, Processing batch 30276/30798\n",
            "Batch 30276 Loss: 4.491161823272705\n",
            "Epoch 3, Processing batch 30277/30798\n",
            "Batch 30277 Loss: 0.06325209885835648\n",
            "Epoch 3, Processing batch 30278/30798\n",
            "Batch 30278 Loss: 0.6560179591178894\n",
            "Epoch 3, Processing batch 30279/30798\n",
            "Batch 30279 Loss: 0.07967910915613174\n",
            "Epoch 3, Processing batch 30280/30798\n",
            "Batch 30280 Loss: 0.6691375970840454\n",
            "Epoch 3, Processing batch 30281/30798\n",
            "Batch 30281 Loss: 0.12694485485553741\n",
            "Epoch 3, Processing batch 30282/30798\n",
            "Batch 30282 Loss: 1.0066925287246704\n",
            "Epoch 3, Processing batch 30283/30798\n",
            "Batch 30283 Loss: 0.0024564219638705254\n",
            "Epoch 3, Processing batch 30284/30798\n",
            "Batch 30284 Loss: 0.1532338708639145\n",
            "Epoch 3, Processing batch 30285/30798\n",
            "Batch 30285 Loss: 0.5867276787757874\n",
            "Epoch 3, Processing batch 30286/30798\n",
            "Batch 30286 Loss: 0.20295198261737823\n",
            "Epoch 3, Processing batch 30287/30798\n",
            "Batch 30287 Loss: 0.6432381868362427\n",
            "Epoch 3, Processing batch 30288/30798\n",
            "Batch 30288 Loss: 0.5035616755485535\n",
            "Epoch 3, Processing batch 30289/30798\n",
            "Batch 30289 Loss: 1.0237255096435547\n",
            "Epoch 3, Processing batch 30290/30798\n",
            "Batch 30290 Loss: 0.01293124258518219\n",
            "Epoch 3, Processing batch 30291/30798\n",
            "Batch 30291 Loss: 0.016186293214559555\n",
            "Epoch 3, Processing batch 30292/30798\n",
            "Batch 30292 Loss: 0.015546649694442749\n",
            "Epoch 3, Processing batch 30293/30798\n",
            "Batch 30293 Loss: 0.027366816997528076\n",
            "Epoch 3, Processing batch 30294/30798\n",
            "Batch 30294 Loss: 0.19640648365020752\n",
            "Epoch 3, Processing batch 30295/30798\n",
            "Batch 30295 Loss: 0.22909604012966156\n",
            "Epoch 3, Processing batch 30296/30798\n",
            "Batch 30296 Loss: 1.137129783630371\n",
            "Epoch 3, Processing batch 30297/30798\n",
            "Batch 30297 Loss: 0.1299610435962677\n",
            "Epoch 3, Processing batch 30298/30798\n",
            "Batch 30298 Loss: 0.053832489997148514\n",
            "Epoch 3, Processing batch 30299/30798\n",
            "Batch 30299 Loss: 0.19460389018058777\n",
            "Epoch 3, Processing batch 30300/30798\n",
            "Batch 30300 Loss: 0.03868134319782257\n",
            "Epoch 3, Processing batch 30301/30798\n",
            "Batch 30301 Loss: 0.4771811366081238\n",
            "Epoch 3, Processing batch 30302/30798\n",
            "Batch 30302 Loss: 0.04886789619922638\n",
            "Epoch 3, Processing batch 30303/30798\n",
            "Batch 30303 Loss: 0.04520033299922943\n",
            "Epoch 3, Processing batch 30304/30798\n",
            "Batch 30304 Loss: 0.03745180740952492\n",
            "Epoch 3, Processing batch 30305/30798\n",
            "Batch 30305 Loss: 0.010642106644809246\n",
            "Epoch 3, Processing batch 30306/30798\n",
            "Batch 30306 Loss: 0.02657865546643734\n",
            "Epoch 3, Processing batch 30307/30798\n",
            "Batch 30307 Loss: 0.009357865899801254\n",
            "Epoch 3, Processing batch 30308/30798\n",
            "Batch 30308 Loss: 0.0026966342702507973\n",
            "Epoch 3, Processing batch 30309/30798\n",
            "Batch 30309 Loss: 0.8245479464530945\n",
            "Epoch 3, Processing batch 30310/30798\n",
            "Batch 30310 Loss: 0.24752922356128693\n",
            "Epoch 3, Processing batch 30311/30798\n",
            "Batch 30311 Loss: 0.2167949080467224\n",
            "Epoch 3, Processing batch 30312/30798\n",
            "Batch 30312 Loss: 0.24654555320739746\n",
            "Epoch 3, Processing batch 30313/30798\n",
            "Batch 30313 Loss: 0.2763841152191162\n",
            "Epoch 3, Processing batch 30314/30798\n",
            "Batch 30314 Loss: 0.06094826012849808\n",
            "Epoch 3, Processing batch 30315/30798\n",
            "Batch 30315 Loss: 0.049513064324855804\n",
            "Epoch 3, Processing batch 30316/30798\n",
            "Batch 30316 Loss: 0.06814848631620407\n",
            "Epoch 3, Processing batch 30317/30798\n",
            "Batch 30317 Loss: 1.2392942905426025\n",
            "Epoch 3, Processing batch 30318/30798\n",
            "Batch 30318 Loss: 0.5487421751022339\n",
            "Epoch 3, Processing batch 30319/30798\n",
            "Batch 30319 Loss: 2.899538278579712\n",
            "Epoch 3, Processing batch 30320/30798\n",
            "Batch 30320 Loss: 0.03241332992911339\n",
            "Epoch 3, Processing batch 30321/30798\n",
            "Batch 30321 Loss: 0.1989654153585434\n",
            "Epoch 3, Processing batch 30322/30798\n",
            "Batch 30322 Loss: 0.18254846334457397\n",
            "Epoch 3, Processing batch 30323/30798\n",
            "Batch 30323 Loss: 0.5654741525650024\n",
            "Epoch 3, Processing batch 30324/30798\n",
            "Batch 30324 Loss: 0.022999780252575874\n",
            "Epoch 3, Processing batch 30325/30798\n",
            "Batch 30325 Loss: 0.18635639548301697\n",
            "Epoch 3, Processing batch 30326/30798\n",
            "Batch 30326 Loss: 0.28047311305999756\n",
            "Epoch 3, Processing batch 30327/30798\n",
            "Batch 30327 Loss: 0.309611439704895\n",
            "Epoch 3, Processing batch 30328/30798\n",
            "Batch 30328 Loss: 2.197176218032837\n",
            "Epoch 3, Processing batch 30329/30798\n",
            "Batch 30329 Loss: 0.7638238072395325\n",
            "Epoch 3, Processing batch 30330/30798\n",
            "Batch 30330 Loss: 0.061864495277404785\n",
            "Epoch 3, Processing batch 30331/30798\n",
            "Batch 30331 Loss: 1.3891892433166504\n",
            "Epoch 3, Processing batch 30332/30798\n",
            "Batch 30332 Loss: 0.19411972165107727\n",
            "Epoch 3, Processing batch 30333/30798\n",
            "Batch 30333 Loss: 0.25948387384414673\n",
            "Epoch 3, Processing batch 30334/30798\n",
            "Batch 30334 Loss: 1.8998454809188843\n",
            "Epoch 3, Processing batch 30335/30798\n",
            "Batch 30335 Loss: 0.07691637426614761\n",
            "Epoch 3, Processing batch 30336/30798\n",
            "Batch 30336 Loss: 0.008993023075163364\n",
            "Epoch 3, Processing batch 30337/30798\n",
            "Batch 30337 Loss: 0.025005988776683807\n",
            "Epoch 3, Processing batch 30338/30798\n",
            "Batch 30338 Loss: 2.634770631790161\n",
            "Epoch 3, Processing batch 30339/30798\n",
            "Batch 30339 Loss: 1.297075867652893\n",
            "Epoch 3, Processing batch 30340/30798\n",
            "Batch 30340 Loss: 1.1403145790100098\n",
            "Epoch 3, Processing batch 30341/30798\n",
            "Batch 30341 Loss: 0.9638421535491943\n",
            "Epoch 3, Processing batch 30342/30798\n",
            "Batch 30342 Loss: 0.0018969515804201365\n",
            "Epoch 3, Processing batch 30343/30798\n",
            "Batch 30343 Loss: 0.0072142886929214\n",
            "Epoch 3, Processing batch 30344/30798\n",
            "Batch 30344 Loss: 1.2066357135772705\n",
            "Epoch 3, Processing batch 30345/30798\n",
            "Batch 30345 Loss: 0.2436901479959488\n",
            "Epoch 3, Processing batch 30346/30798\n",
            "Batch 30346 Loss: 1.5130937099456787\n",
            "Epoch 3, Processing batch 30347/30798\n",
            "Batch 30347 Loss: 0.06750772148370743\n",
            "Epoch 3, Processing batch 30348/30798\n",
            "Batch 30348 Loss: 0.01820554956793785\n",
            "Epoch 3, Processing batch 30349/30798\n",
            "Batch 30349 Loss: 0.24196283519268036\n",
            "Epoch 3, Processing batch 30350/30798\n",
            "Batch 30350 Loss: 0.0020010373555123806\n",
            "Epoch 3, Processing batch 30351/30798\n",
            "Batch 30351 Loss: 0.5061907768249512\n",
            "Epoch 3, Processing batch 30352/30798\n",
            "Batch 30352 Loss: 0.034652478992938995\n",
            "Epoch 3, Processing batch 30353/30798\n",
            "Batch 30353 Loss: 0.14810289442539215\n",
            "Epoch 3, Processing batch 30354/30798\n",
            "Batch 30354 Loss: 0.6369374394416809\n",
            "Epoch 3, Processing batch 30355/30798\n",
            "Batch 30355 Loss: 0.28156447410583496\n",
            "Epoch 3, Processing batch 30356/30798\n",
            "Batch 30356 Loss: 2.869777202606201\n",
            "Epoch 3, Processing batch 30357/30798\n",
            "Batch 30357 Loss: 0.5186024904251099\n",
            "Epoch 3, Processing batch 30358/30798\n",
            "Batch 30358 Loss: 0.12930691242218018\n",
            "Epoch 3, Processing batch 30359/30798\n",
            "Batch 30359 Loss: 0.31581175327301025\n",
            "Epoch 3, Processing batch 30360/30798\n",
            "Batch 30360 Loss: 0.12589582800865173\n",
            "Epoch 3, Processing batch 30361/30798\n",
            "Batch 30361 Loss: 0.08391517400741577\n",
            "Epoch 3, Processing batch 30362/30798\n",
            "Batch 30362 Loss: 0.7661107778549194\n",
            "Epoch 3, Processing batch 30363/30798\n",
            "Batch 30363 Loss: 0.017803547903895378\n",
            "Epoch 3, Processing batch 30364/30798\n",
            "Batch 30364 Loss: 0.17127929627895355\n",
            "Epoch 3, Processing batch 30365/30798\n",
            "Batch 30365 Loss: 0.005002493970096111\n",
            "Epoch 3, Processing batch 30366/30798\n",
            "Batch 30366 Loss: 1.1765143871307373\n",
            "Epoch 3, Processing batch 30367/30798\n",
            "Batch 30367 Loss: 0.03834228590130806\n",
            "Epoch 3, Processing batch 30368/30798\n",
            "Batch 30368 Loss: 0.009639736264944077\n",
            "Epoch 3, Processing batch 30369/30798\n",
            "Batch 30369 Loss: 0.974443793296814\n",
            "Epoch 3, Processing batch 30370/30798\n",
            "Batch 30370 Loss: 0.7543722987174988\n",
            "Epoch 3, Processing batch 30371/30798\n",
            "Batch 30371 Loss: 0.42224758863449097\n",
            "Epoch 3, Processing batch 30372/30798\n",
            "Batch 30372 Loss: 1.4503765106201172\n",
            "Epoch 3, Processing batch 30373/30798\n",
            "Batch 30373 Loss: 0.2491093873977661\n",
            "Epoch 3, Processing batch 30374/30798\n",
            "Batch 30374 Loss: 0.04610675945878029\n",
            "Epoch 3, Processing batch 30375/30798\n",
            "Batch 30375 Loss: 0.16096317768096924\n",
            "Epoch 3, Processing batch 30376/30798\n",
            "Batch 30376 Loss: 0.07072870433330536\n",
            "Epoch 3, Processing batch 30377/30798\n",
            "Batch 30377 Loss: 0.3409661054611206\n",
            "Epoch 3, Processing batch 30378/30798\n",
            "Batch 30378 Loss: 0.020353933796286583\n",
            "Epoch 3, Processing batch 30379/30798\n",
            "Batch 30379 Loss: 0.11573228240013123\n",
            "Epoch 3, Processing batch 30380/30798\n",
            "Batch 30380 Loss: 0.5594561100006104\n",
            "Epoch 3, Processing batch 30381/30798\n",
            "Batch 30381 Loss: 1.7403937578201294\n",
            "Epoch 3, Processing batch 30382/30798\n",
            "Batch 30382 Loss: 0.9519153237342834\n",
            "Epoch 3, Processing batch 30383/30798\n",
            "Batch 30383 Loss: 0.017066679894924164\n",
            "Epoch 3, Processing batch 30384/30798\n",
            "Batch 30384 Loss: 1.3458459377288818\n",
            "Epoch 3, Processing batch 30385/30798\n",
            "Batch 30385 Loss: 0.03926157206296921\n",
            "Epoch 3, Processing batch 30386/30798\n",
            "Batch 30386 Loss: 0.2068614363670349\n",
            "Epoch 3, Processing batch 30387/30798\n",
            "Batch 30387 Loss: 0.5094648599624634\n",
            "Epoch 3, Processing batch 30388/30798\n",
            "Batch 30388 Loss: 0.22893090546131134\n",
            "Epoch 3, Processing batch 30389/30798\n",
            "Batch 30389 Loss: 0.1942458599805832\n",
            "Epoch 3, Processing batch 30390/30798\n",
            "Batch 30390 Loss: 1.5261316299438477\n",
            "Epoch 3, Processing batch 30391/30798\n",
            "Batch 30391 Loss: 0.07326442748308182\n",
            "Epoch 3, Processing batch 30392/30798\n",
            "Batch 30392 Loss: 1.5023595094680786\n",
            "Epoch 3, Processing batch 30393/30798\n",
            "Batch 30393 Loss: 1.9708760976791382\n",
            "Epoch 3, Processing batch 30394/30798\n",
            "Batch 30394 Loss: 0.09845443814992905\n",
            "Epoch 3, Processing batch 30395/30798\n",
            "Batch 30395 Loss: 0.10541793704032898\n",
            "Epoch 3, Processing batch 30396/30798\n",
            "Batch 30396 Loss: 0.7494609355926514\n",
            "Epoch 3, Processing batch 30397/30798\n",
            "Batch 30397 Loss: 0.20721353590488434\n",
            "Epoch 3, Processing batch 30398/30798\n",
            "Batch 30398 Loss: 0.0703200250864029\n",
            "Epoch 3, Processing batch 30399/30798\n",
            "Batch 30399 Loss: 0.11528816819190979\n",
            "Epoch 3, Processing batch 30400/30798\n",
            "Batch 30400 Loss: 0.07611234486103058\n",
            "Epoch 3, Processing batch 30401/30798\n",
            "Batch 30401 Loss: 0.17793701589107513\n",
            "Epoch 3, Processing batch 30402/30798\n",
            "Batch 30402 Loss: 0.2203839123249054\n",
            "Epoch 3, Processing batch 30403/30798\n",
            "Batch 30403 Loss: 0.04328886792063713\n",
            "Epoch 3, Processing batch 30404/30798\n",
            "Batch 30404 Loss: 0.17638897895812988\n",
            "Epoch 3, Processing batch 30405/30798\n",
            "Batch 30405 Loss: 0.03775933012366295\n",
            "Epoch 3, Processing batch 30406/30798\n",
            "Batch 30406 Loss: 0.04200011119246483\n",
            "Epoch 3, Processing batch 30407/30798\n",
            "Batch 30407 Loss: 0.03644832968711853\n",
            "Epoch 3, Processing batch 30408/30798\n",
            "Batch 30408 Loss: 1.356256365776062\n",
            "Epoch 3, Processing batch 30409/30798\n",
            "Batch 30409 Loss: 0.024018172174692154\n",
            "Epoch 3, Processing batch 30410/30798\n",
            "Batch 30410 Loss: 0.0024608445819467306\n",
            "Epoch 3, Processing batch 30411/30798\n",
            "Batch 30411 Loss: 0.8535662293434143\n",
            "Epoch 3, Processing batch 30412/30798\n",
            "Batch 30412 Loss: 0.14220522344112396\n",
            "Epoch 3, Processing batch 30413/30798\n",
            "Batch 30413 Loss: 2.953279495239258\n",
            "Epoch 3, Processing batch 30414/30798\n",
            "Batch 30414 Loss: 0.9387895464897156\n",
            "Epoch 3, Processing batch 30415/30798\n",
            "Batch 30415 Loss: 0.1455504298210144\n",
            "Epoch 3, Processing batch 30416/30798\n",
            "Batch 30416 Loss: 0.8764427304267883\n",
            "Epoch 3, Processing batch 30417/30798\n",
            "Batch 30417 Loss: 0.01902354694902897\n",
            "Epoch 3, Processing batch 30418/30798\n",
            "Batch 30418 Loss: 0.16509152948856354\n",
            "Epoch 3, Processing batch 30419/30798\n",
            "Batch 30419 Loss: 0.05914897099137306\n",
            "Epoch 3, Processing batch 30420/30798\n",
            "Batch 30420 Loss: 0.3758803904056549\n",
            "Epoch 3, Processing batch 30421/30798\n",
            "Batch 30421 Loss: 0.03184439241886139\n",
            "Epoch 3, Processing batch 30422/30798\n",
            "Batch 30422 Loss: 1.0858328342437744\n",
            "Epoch 3, Processing batch 30423/30798\n",
            "Batch 30423 Loss: 0.0453103706240654\n",
            "Epoch 3, Processing batch 30424/30798\n",
            "Batch 30424 Loss: 0.00785042904317379\n",
            "Epoch 3, Processing batch 30425/30798\n",
            "Batch 30425 Loss: 1.3362102508544922\n",
            "Epoch 3, Processing batch 30426/30798\n",
            "Batch 30426 Loss: 0.0111389746889472\n",
            "Epoch 3, Processing batch 30427/30798\n",
            "Batch 30427 Loss: 0.0763503685593605\n",
            "Epoch 3, Processing batch 30428/30798\n",
            "Batch 30428 Loss: 0.12254313379526138\n",
            "Epoch 3, Processing batch 30429/30798\n",
            "Batch 30429 Loss: 0.05278177186846733\n",
            "Epoch 3, Processing batch 30430/30798\n",
            "Batch 30430 Loss: 0.1192120835185051\n",
            "Epoch 3, Processing batch 30431/30798\n",
            "Batch 30431 Loss: 0.023739665746688843\n",
            "Epoch 3, Processing batch 30432/30798\n",
            "Batch 30432 Loss: 0.18000003695487976\n",
            "Epoch 3, Processing batch 30433/30798\n",
            "Batch 30433 Loss: 0.22324375808238983\n",
            "Epoch 3, Processing batch 30434/30798\n",
            "Batch 30434 Loss: 0.16046541929244995\n",
            "Epoch 3, Processing batch 30435/30798\n",
            "Batch 30435 Loss: 0.005732397083193064\n",
            "Epoch 3, Processing batch 30436/30798\n",
            "Batch 30436 Loss: 3.7519757747650146\n",
            "Epoch 3, Processing batch 30437/30798\n",
            "Batch 30437 Loss: 0.008084761910140514\n",
            "Epoch 3, Processing batch 30438/30798\n",
            "Batch 30438 Loss: 0.001263821846805513\n",
            "Epoch 3, Processing batch 30439/30798\n",
            "Batch 30439 Loss: 0.11184970289468765\n",
            "Epoch 3, Processing batch 30440/30798\n",
            "Batch 30440 Loss: 0.22392262518405914\n",
            "Epoch 3, Processing batch 30441/30798\n",
            "Batch 30441 Loss: 1.1548601388931274\n",
            "Epoch 3, Processing batch 30442/30798\n",
            "Batch 30442 Loss: 0.06836819648742676\n",
            "Epoch 3, Processing batch 30443/30798\n",
            "Batch 30443 Loss: 0.17013290524482727\n",
            "Epoch 3, Processing batch 30444/30798\n",
            "Batch 30444 Loss: 0.2134641408920288\n",
            "Epoch 3, Processing batch 30445/30798\n",
            "Batch 30445 Loss: 0.24012818932533264\n",
            "Epoch 3, Processing batch 30446/30798\n",
            "Batch 30446 Loss: 0.49147945642471313\n",
            "Epoch 3, Processing batch 30447/30798\n",
            "Batch 30447 Loss: 0.128695547580719\n",
            "Epoch 3, Processing batch 30448/30798\n",
            "Batch 30448 Loss: 0.22521910071372986\n",
            "Epoch 3, Processing batch 30449/30798\n",
            "Batch 30449 Loss: 0.10640142112970352\n",
            "Epoch 3, Processing batch 30450/30798\n",
            "Batch 30450 Loss: 0.15471990406513214\n",
            "Epoch 3, Processing batch 30451/30798\n",
            "Batch 30451 Loss: 0.5121818780899048\n",
            "Epoch 3, Processing batch 30452/30798\n",
            "Batch 30452 Loss: 0.09928414225578308\n",
            "Epoch 3, Processing batch 30453/30798\n",
            "Batch 30453 Loss: 0.10886678099632263\n",
            "Epoch 3, Processing batch 30454/30798\n",
            "Batch 30454 Loss: 0.13143743574619293\n",
            "Epoch 3, Processing batch 30455/30798\n",
            "Batch 30455 Loss: 0.18374118208885193\n",
            "Epoch 3, Processing batch 30456/30798\n",
            "Batch 30456 Loss: 0.0982033833861351\n",
            "Epoch 3, Processing batch 30457/30798\n",
            "Batch 30457 Loss: 0.0960899367928505\n",
            "Epoch 3, Processing batch 30458/30798\n",
            "Batch 30458 Loss: 0.4369664788246155\n",
            "Epoch 3, Processing batch 30459/30798\n",
            "Batch 30459 Loss: 1.9760973453521729\n",
            "Epoch 3, Processing batch 30460/30798\n",
            "Batch 30460 Loss: 0.013790952041745186\n",
            "Epoch 3, Processing batch 30461/30798\n",
            "Batch 30461 Loss: 0.5650003552436829\n",
            "Epoch 3, Processing batch 30462/30798\n",
            "Batch 30462 Loss: 0.06641034036874771\n",
            "Epoch 3, Processing batch 30463/30798\n",
            "Batch 30463 Loss: 0.2858569324016571\n",
            "Epoch 3, Processing batch 30464/30798\n",
            "Batch 30464 Loss: 0.06317125260829926\n",
            "Epoch 3, Processing batch 30465/30798\n",
            "Batch 30465 Loss: 0.6481066942214966\n",
            "Epoch 3, Processing batch 30466/30798\n",
            "Batch 30466 Loss: 0.007487289607524872\n",
            "Epoch 3, Processing batch 30467/30798\n",
            "Batch 30467 Loss: 0.4306788444519043\n",
            "Epoch 3, Processing batch 30468/30798\n",
            "Batch 30468 Loss: 0.08761772513389587\n",
            "Epoch 3, Processing batch 30469/30798\n",
            "Batch 30469 Loss: 0.4587634801864624\n",
            "Epoch 3, Processing batch 30470/30798\n",
            "Batch 30470 Loss: 0.006266411859542131\n",
            "Epoch 3, Processing batch 30471/30798\n",
            "Batch 30471 Loss: 0.17809969186782837\n",
            "Epoch 3, Processing batch 30472/30798\n",
            "Batch 30472 Loss: 0.45834609866142273\n",
            "Epoch 3, Processing batch 30473/30798\n",
            "Batch 30473 Loss: 0.21759480237960815\n",
            "Epoch 3, Processing batch 30474/30798\n",
            "Batch 30474 Loss: 0.4572839140892029\n",
            "Epoch 3, Processing batch 30475/30798\n",
            "Batch 30475 Loss: 1.055259108543396\n",
            "Epoch 3, Processing batch 30476/30798\n",
            "Batch 30476 Loss: 0.07964817434549332\n",
            "Epoch 3, Processing batch 30477/30798\n",
            "Batch 30477 Loss: 0.158601313829422\n",
            "Epoch 3, Processing batch 30478/30798\n",
            "Batch 30478 Loss: 0.8040420413017273\n",
            "Epoch 3, Processing batch 30479/30798\n",
            "Batch 30479 Loss: 0.0273163840174675\n",
            "Epoch 3, Processing batch 30480/30798\n",
            "Batch 30480 Loss: 0.021731985732913017\n",
            "Epoch 3, Processing batch 30481/30798\n",
            "Batch 30481 Loss: 0.010960401967167854\n",
            "Epoch 3, Processing batch 30482/30798\n",
            "Batch 30482 Loss: 0.0026263147592544556\n",
            "Epoch 3, Processing batch 30483/30798\n",
            "Batch 30483 Loss: 0.01461120881140232\n",
            "Epoch 3, Processing batch 30484/30798\n",
            "Batch 30484 Loss: 0.08978717029094696\n",
            "Epoch 3, Processing batch 30485/30798\n",
            "Batch 30485 Loss: 0.23400279879570007\n",
            "Epoch 3, Processing batch 30486/30798\n",
            "Batch 30486 Loss: 0.053137049078941345\n",
            "Epoch 3, Processing batch 30487/30798\n",
            "Batch 30487 Loss: 0.0031310366466641426\n",
            "Epoch 3, Processing batch 30488/30798\n",
            "Batch 30488 Loss: 0.00383255397900939\n",
            "Epoch 3, Processing batch 30489/30798\n",
            "Batch 30489 Loss: 1.5790404081344604\n",
            "Epoch 3, Processing batch 30490/30798\n",
            "Batch 30490 Loss: 0.24910804629325867\n",
            "Epoch 3, Processing batch 30491/30798\n",
            "Batch 30491 Loss: 0.23944377899169922\n",
            "Epoch 3, Processing batch 30492/30798\n",
            "Batch 30492 Loss: 0.059695154428482056\n",
            "Epoch 3, Processing batch 30493/30798\n",
            "Batch 30493 Loss: 0.08589769899845123\n",
            "Epoch 3, Processing batch 30494/30798\n",
            "Batch 30494 Loss: 0.004635879769921303\n",
            "Epoch 3, Processing batch 30495/30798\n",
            "Batch 30495 Loss: 0.1739242523908615\n",
            "Epoch 3, Processing batch 30496/30798\n",
            "Batch 30496 Loss: 0.4650033116340637\n",
            "Epoch 3, Processing batch 30497/30798\n",
            "Batch 30497 Loss: 0.44625401496887207\n",
            "Epoch 3, Processing batch 30498/30798\n",
            "Batch 30498 Loss: 0.01897266134619713\n",
            "Epoch 3, Processing batch 30499/30798\n",
            "Batch 30499 Loss: 0.03601742163300514\n",
            "Epoch 3, Processing batch 30500/30798\n",
            "Batch 30500 Loss: 0.18105514347553253\n",
            "Epoch 3, Processing batch 30501/30798\n",
            "Batch 30501 Loss: 0.06067538261413574\n",
            "Epoch 3, Processing batch 30502/30798\n",
            "Batch 30502 Loss: 2.6771230697631836\n",
            "Epoch 3, Processing batch 30503/30798\n",
            "Batch 30503 Loss: 0.6207634210586548\n",
            "Epoch 3, Processing batch 30504/30798\n",
            "Batch 30504 Loss: 0.005359942559152842\n",
            "Epoch 3, Processing batch 30505/30798\n",
            "Batch 30505 Loss: 0.01253704633563757\n",
            "Epoch 3, Processing batch 30506/30798\n",
            "Batch 30506 Loss: 1.1042815446853638\n",
            "Epoch 3, Processing batch 30507/30798\n",
            "Batch 30507 Loss: 0.4836861789226532\n",
            "Epoch 3, Processing batch 30508/30798\n",
            "Batch 30508 Loss: 0.8843275308609009\n",
            "Epoch 3, Processing batch 30509/30798\n",
            "Batch 30509 Loss: 0.21917511522769928\n",
            "Epoch 3, Processing batch 30510/30798\n",
            "Batch 30510 Loss: 0.09550897777080536\n",
            "Epoch 3, Processing batch 30511/30798\n",
            "Batch 30511 Loss: 0.032934918999671936\n",
            "Epoch 3, Processing batch 30512/30798\n",
            "Batch 30512 Loss: 0.12622854113578796\n",
            "Epoch 3, Processing batch 30513/30798\n",
            "Batch 30513 Loss: 0.03635232895612717\n",
            "Epoch 3, Processing batch 30514/30798\n",
            "Batch 30514 Loss: 0.6090094447135925\n",
            "Epoch 3, Processing batch 30515/30798\n",
            "Batch 30515 Loss: 0.07682347297668457\n",
            "Epoch 3, Processing batch 30516/30798\n",
            "Batch 30516 Loss: 0.1082853376865387\n",
            "Epoch 3, Processing batch 30517/30798\n",
            "Batch 30517 Loss: 1.6552622318267822\n",
            "Epoch 3, Processing batch 30518/30798\n",
            "Batch 30518 Loss: 0.07394757121801376\n",
            "Epoch 3, Processing batch 30519/30798\n",
            "Batch 30519 Loss: 2.4139087200164795\n",
            "Epoch 3, Processing batch 30520/30798\n",
            "Batch 30520 Loss: 0.09318844974040985\n",
            "Epoch 3, Processing batch 30521/30798\n",
            "Batch 30521 Loss: 0.18732589483261108\n",
            "Epoch 3, Processing batch 30522/30798\n",
            "Batch 30522 Loss: 0.18992656469345093\n",
            "Epoch 3, Processing batch 30523/30798\n",
            "Batch 30523 Loss: 0.016609609127044678\n",
            "Epoch 3, Processing batch 30524/30798\n",
            "Batch 30524 Loss: 0.524215042591095\n",
            "Epoch 3, Processing batch 30525/30798\n",
            "Batch 30525 Loss: 0.9525690078735352\n",
            "Epoch 3, Processing batch 30526/30798\n",
            "Batch 30526 Loss: 0.32538849115371704\n",
            "Epoch 3, Processing batch 30527/30798\n",
            "Batch 30527 Loss: 0.0014042854309082031\n",
            "Epoch 3, Processing batch 30528/30798\n",
            "Batch 30528 Loss: 0.6136230230331421\n",
            "Epoch 3, Processing batch 30529/30798\n",
            "Batch 30529 Loss: 0.010713702999055386\n",
            "Epoch 3, Processing batch 30530/30798\n",
            "Batch 30530 Loss: 0.20530956983566284\n",
            "Epoch 3, Processing batch 30531/30798\n",
            "Batch 30531 Loss: 0.23882120847702026\n",
            "Epoch 3, Processing batch 30532/30798\n",
            "Batch 30532 Loss: 0.16118918359279633\n",
            "Epoch 3, Processing batch 30533/30798\n",
            "Batch 30533 Loss: 0.009794759564101696\n",
            "Epoch 3, Processing batch 30534/30798\n",
            "Batch 30534 Loss: 0.025603091344237328\n",
            "Epoch 3, Processing batch 30535/30798\n",
            "Batch 30535 Loss: 0.1444125771522522\n",
            "Epoch 3, Processing batch 30536/30798\n",
            "Batch 30536 Loss: 1.7570099830627441\n",
            "Epoch 3, Processing batch 30537/30798\n",
            "Batch 30537 Loss: 0.20523132383823395\n",
            "Epoch 3, Processing batch 30538/30798\n",
            "Batch 30538 Loss: 1.3422431945800781\n",
            "Epoch 3, Processing batch 30539/30798\n",
            "Batch 30539 Loss: 0.14783120155334473\n",
            "Epoch 3, Processing batch 30540/30798\n",
            "Batch 30540 Loss: 1.5358095169067383\n",
            "Epoch 3, Processing batch 30541/30798\n",
            "Batch 30541 Loss: 0.021213438361883163\n",
            "Epoch 3, Processing batch 30542/30798\n",
            "Batch 30542 Loss: 0.0013250907650217414\n",
            "Epoch 3, Processing batch 30543/30798\n",
            "Batch 30543 Loss: 0.7886397838592529\n",
            "Epoch 3, Processing batch 30544/30798\n",
            "Batch 30544 Loss: 0.45969900488853455\n",
            "Epoch 3, Processing batch 30545/30798\n",
            "Batch 30545 Loss: 2.272623062133789\n",
            "Epoch 3, Processing batch 30546/30798\n",
            "Batch 30546 Loss: 0.018567800521850586\n",
            "Epoch 3, Processing batch 30547/30798\n",
            "Batch 30547 Loss: 0.05672932043671608\n",
            "Epoch 3, Processing batch 30548/30798\n",
            "Batch 30548 Loss: 0.0776517242193222\n",
            "Epoch 3, Processing batch 30549/30798\n",
            "Batch 30549 Loss: 0.006795234978199005\n",
            "Epoch 3, Processing batch 30550/30798\n",
            "Batch 30550 Loss: 0.11612305790185928\n",
            "Epoch 3, Processing batch 30551/30798\n",
            "Batch 30551 Loss: 0.23251041769981384\n",
            "Epoch 3, Processing batch 30552/30798\n",
            "Batch 30552 Loss: 0.024792414158582687\n",
            "Epoch 3, Processing batch 30553/30798\n",
            "Batch 30553 Loss: 1.4706982374191284\n",
            "Epoch 3, Processing batch 30554/30798\n",
            "Batch 30554 Loss: 0.078748919069767\n",
            "Epoch 3, Processing batch 30555/30798\n",
            "Batch 30555 Loss: 0.004038877785205841\n",
            "Epoch 3, Processing batch 30556/30798\n",
            "Batch 30556 Loss: 0.9605191946029663\n",
            "Epoch 3, Processing batch 30557/30798\n",
            "Batch 30557 Loss: 0.05740763247013092\n",
            "Epoch 3, Processing batch 30558/30798\n",
            "Batch 30558 Loss: 3.359619617462158\n",
            "Epoch 3, Processing batch 30559/30798\n",
            "Batch 30559 Loss: 0.06472684442996979\n",
            "Epoch 3, Processing batch 30560/30798\n",
            "Batch 30560 Loss: 0.18084484338760376\n",
            "Epoch 3, Processing batch 30561/30798\n",
            "Batch 30561 Loss: 0.23720751702785492\n",
            "Epoch 3, Processing batch 30562/30798\n",
            "Batch 30562 Loss: 0.056974880397319794\n",
            "Epoch 3, Processing batch 30563/30798\n",
            "Batch 30563 Loss: 0.011528638191521168\n",
            "Epoch 3, Processing batch 30564/30798\n",
            "Batch 30564 Loss: 0.16386930644512177\n",
            "Epoch 3, Processing batch 30565/30798\n",
            "Batch 30565 Loss: 0.10185602307319641\n",
            "Epoch 3, Processing batch 30566/30798\n",
            "Batch 30566 Loss: 0.017323412001132965\n",
            "Epoch 3, Processing batch 30567/30798\n",
            "Batch 30567 Loss: 0.2805541753768921\n",
            "Epoch 3, Processing batch 30568/30798\n",
            "Batch 30568 Loss: 0.09621424973011017\n",
            "Epoch 3, Processing batch 30569/30798\n",
            "Batch 30569 Loss: 1.0210422277450562\n",
            "Epoch 3, Processing batch 30570/30798\n",
            "Batch 30570 Loss: 0.14088961482048035\n",
            "Epoch 3, Processing batch 30571/30798\n",
            "Batch 30571 Loss: 2.5554747581481934\n",
            "Epoch 3, Processing batch 30572/30798\n",
            "Batch 30572 Loss: 0.08146580308675766\n",
            "Epoch 3, Processing batch 30573/30798\n",
            "Batch 30573 Loss: 0.16761839389801025\n",
            "Epoch 3, Processing batch 30574/30798\n",
            "Batch 30574 Loss: 0.003517473815008998\n",
            "Epoch 3, Processing batch 30575/30798\n",
            "Batch 30575 Loss: 0.023464035242795944\n",
            "Epoch 3, Processing batch 30576/30798\n",
            "Batch 30576 Loss: 0.0090691689401865\n",
            "Epoch 3, Processing batch 30577/30798\n",
            "Batch 30577 Loss: 0.04497186094522476\n",
            "Epoch 3, Processing batch 30578/30798\n",
            "Batch 30578 Loss: 0.02779250405728817\n",
            "Epoch 3, Processing batch 30579/30798\n",
            "Batch 30579 Loss: 2.1307170391082764\n",
            "Epoch 3, Processing batch 30580/30798\n",
            "Batch 30580 Loss: 0.5971367359161377\n",
            "Epoch 3, Processing batch 30581/30798\n",
            "Batch 30581 Loss: 0.9409893155097961\n",
            "Epoch 3, Processing batch 30582/30798\n",
            "Batch 30582 Loss: 0.06304711103439331\n",
            "Epoch 3, Processing batch 30583/30798\n",
            "Batch 30583 Loss: 0.0031783897429704666\n",
            "Epoch 3, Processing batch 30584/30798\n",
            "Batch 30584 Loss: 0.4645978808403015\n",
            "Epoch 3, Processing batch 30585/30798\n",
            "Batch 30585 Loss: 0.05175815150141716\n",
            "Epoch 3, Processing batch 30586/30798\n",
            "Batch 30586 Loss: 0.04103754088282585\n",
            "Epoch 3, Processing batch 30587/30798\n",
            "Batch 30587 Loss: 0.1307961344718933\n",
            "Epoch 3, Processing batch 30588/30798\n",
            "Batch 30588 Loss: 0.004606652073562145\n",
            "Epoch 3, Processing batch 30589/30798\n",
            "Batch 30589 Loss: 0.10011392831802368\n",
            "Epoch 3, Processing batch 30590/30798\n",
            "Batch 30590 Loss: 0.009109171107411385\n",
            "Epoch 3, Processing batch 30591/30798\n",
            "Batch 30591 Loss: 0.15809482336044312\n",
            "Epoch 3, Processing batch 30592/30798\n",
            "Batch 30592 Loss: 0.006430728826671839\n",
            "Epoch 3, Processing batch 30593/30798\n",
            "Batch 30593 Loss: 0.017828894779086113\n",
            "Epoch 3, Processing batch 30594/30798\n",
            "Batch 30594 Loss: 0.08326366543769836\n",
            "Epoch 3, Processing batch 30595/30798\n",
            "Batch 30595 Loss: 0.1971079707145691\n",
            "Epoch 3, Processing batch 30596/30798\n",
            "Batch 30596 Loss: 0.12733475863933563\n",
            "Epoch 3, Processing batch 30597/30798\n",
            "Batch 30597 Loss: 0.06669174134731293\n",
            "Epoch 3, Processing batch 30598/30798\n",
            "Batch 30598 Loss: 0.1368391364812851\n",
            "Epoch 3, Processing batch 30599/30798\n",
            "Batch 30599 Loss: 0.654484748840332\n",
            "Epoch 3, Processing batch 30600/30798\n",
            "Batch 30600 Loss: 0.02477165497839451\n",
            "Epoch 3, Processing batch 30601/30798\n",
            "Batch 30601 Loss: 0.04616228863596916\n",
            "Epoch 3, Processing batch 30602/30798\n",
            "Batch 30602 Loss: 0.5524598360061646\n",
            "Epoch 3, Processing batch 30603/30798\n",
            "Batch 30603 Loss: 0.018771298229694366\n",
            "Epoch 3, Processing batch 30604/30798\n",
            "Batch 30604 Loss: 0.1516205221414566\n",
            "Epoch 3, Processing batch 30605/30798\n",
            "Batch 30605 Loss: 0.0394132137298584\n",
            "Epoch 3, Processing batch 30606/30798\n",
            "Batch 30606 Loss: 0.20781388878822327\n",
            "Epoch 3, Processing batch 30607/30798\n",
            "Batch 30607 Loss: 0.7444098591804504\n",
            "Epoch 3, Processing batch 30608/30798\n",
            "Batch 30608 Loss: 0.06555818021297455\n",
            "Epoch 3, Processing batch 30609/30798\n",
            "Batch 30609 Loss: 0.13069723546504974\n",
            "Epoch 3, Processing batch 30610/30798\n",
            "Batch 30610 Loss: 0.9363256096839905\n",
            "Epoch 3, Processing batch 30611/30798\n",
            "Batch 30611 Loss: 0.5999178886413574\n",
            "Epoch 3, Processing batch 30612/30798\n",
            "Batch 30612 Loss: 0.10988365113735199\n",
            "Epoch 3, Processing batch 30613/30798\n",
            "Batch 30613 Loss: 0.9594111442565918\n",
            "Epoch 3, Processing batch 30614/30798\n",
            "Batch 30614 Loss: 0.19580842554569244\n",
            "Epoch 3, Processing batch 30615/30798\n",
            "Batch 30615 Loss: 0.014992829412221909\n",
            "Epoch 3, Processing batch 30616/30798\n",
            "Batch 30616 Loss: 0.31816989183425903\n",
            "Epoch 3, Processing batch 30617/30798\n",
            "Batch 30617 Loss: 0.07445335388183594\n",
            "Epoch 3, Processing batch 30618/30798\n",
            "Batch 30618 Loss: 0.2666754424571991\n",
            "Epoch 3, Processing batch 30619/30798\n",
            "Batch 30619 Loss: 0.07651316374540329\n",
            "Epoch 3, Processing batch 30620/30798\n",
            "Batch 30620 Loss: 0.32524001598358154\n",
            "Epoch 3, Processing batch 30621/30798\n",
            "Batch 30621 Loss: 0.17154176533222198\n",
            "Epoch 3, Processing batch 30622/30798\n",
            "Batch 30622 Loss: 0.018445709720253944\n",
            "Epoch 3, Processing batch 30623/30798\n",
            "Batch 30623 Loss: 1.1694903373718262\n",
            "Epoch 3, Processing batch 30624/30798\n",
            "Batch 30624 Loss: 1.8045803308486938\n",
            "Epoch 3, Processing batch 30625/30798\n",
            "Batch 30625 Loss: 1.0737440586090088\n",
            "Epoch 3, Processing batch 30626/30798\n",
            "Batch 30626 Loss: 0.35433122515678406\n",
            "Epoch 3, Processing batch 30627/30798\n",
            "Batch 30627 Loss: 0.03976210951805115\n",
            "Epoch 3, Processing batch 30628/30798\n",
            "Batch 30628 Loss: 0.41421395540237427\n",
            "Epoch 3, Processing batch 30629/30798\n",
            "Batch 30629 Loss: 0.15650157630443573\n",
            "Epoch 3, Processing batch 30630/30798\n",
            "Batch 30630 Loss: 0.3531656861305237\n",
            "Epoch 3, Processing batch 30631/30798\n",
            "Batch 30631 Loss: 0.45607829093933105\n",
            "Epoch 3, Processing batch 30632/30798\n",
            "Batch 30632 Loss: 0.012520440854132175\n",
            "Epoch 3, Processing batch 30633/30798\n",
            "Batch 30633 Loss: 0.053433097898960114\n",
            "Epoch 3, Processing batch 30634/30798\n",
            "Batch 30634 Loss: 0.01976589858531952\n",
            "Epoch 3, Processing batch 30635/30798\n",
            "Batch 30635 Loss: 0.6749630570411682\n",
            "Epoch 3, Processing batch 30636/30798\n",
            "Batch 30636 Loss: 0.22463122010231018\n",
            "Epoch 3, Processing batch 30637/30798\n",
            "Batch 30637 Loss: 0.03145689517259598\n",
            "Epoch 3, Processing batch 30638/30798\n",
            "Batch 30638 Loss: 0.6545457243919373\n",
            "Epoch 3, Processing batch 30639/30798\n",
            "Batch 30639 Loss: 0.020120806992053986\n",
            "Epoch 3, Processing batch 30640/30798\n",
            "Batch 30640 Loss: 0.006980146747082472\n",
            "Epoch 3, Processing batch 30641/30798\n",
            "Batch 30641 Loss: 0.08808580785989761\n",
            "Epoch 3, Processing batch 30642/30798\n",
            "Batch 30642 Loss: 0.010602829977869987\n",
            "Epoch 3, Processing batch 30643/30798\n",
            "Batch 30643 Loss: 0.30606377124786377\n",
            "Epoch 3, Processing batch 30644/30798\n",
            "Batch 30644 Loss: 0.019541757181286812\n",
            "Epoch 3, Processing batch 30645/30798\n",
            "Batch 30645 Loss: 0.03613213449716568\n",
            "Epoch 3, Processing batch 30646/30798\n",
            "Batch 30646 Loss: 0.0010675390949472785\n",
            "Epoch 3, Processing batch 30647/30798\n",
            "Batch 30647 Loss: 0.14320184290409088\n",
            "Epoch 3, Processing batch 30648/30798\n",
            "Batch 30648 Loss: 0.004778696224093437\n",
            "Epoch 3, Processing batch 30649/30798\n",
            "Batch 30649 Loss: 0.2756347954273224\n",
            "Epoch 3, Processing batch 30650/30798\n",
            "Batch 30650 Loss: 0.5042865872383118\n",
            "Epoch 3, Processing batch 30651/30798\n",
            "Batch 30651 Loss: 1.354662299156189\n",
            "Epoch 3, Processing batch 30652/30798\n",
            "Batch 30652 Loss: 0.2373359054327011\n",
            "Epoch 3, Processing batch 30653/30798\n",
            "Batch 30653 Loss: 0.035981159657239914\n",
            "Epoch 3, Processing batch 30654/30798\n",
            "Batch 30654 Loss: 0.7394787073135376\n",
            "Epoch 3, Processing batch 30655/30798\n",
            "Batch 30655 Loss: 0.0284663587808609\n",
            "Epoch 3, Processing batch 30656/30798\n",
            "Batch 30656 Loss: 1.8347195386886597\n",
            "Epoch 3, Processing batch 30657/30798\n",
            "Batch 30657 Loss: 1.004073977470398\n",
            "Epoch 3, Processing batch 30658/30798\n",
            "Batch 30658 Loss: 0.032743047922849655\n",
            "Epoch 3, Processing batch 30659/30798\n",
            "Batch 30659 Loss: 0.0814991444349289\n",
            "Epoch 3, Processing batch 30660/30798\n",
            "Batch 30660 Loss: 0.3068704605102539\n",
            "Epoch 3, Processing batch 30661/30798\n",
            "Batch 30661 Loss: 0.022651618346571922\n",
            "Epoch 3, Processing batch 30662/30798\n",
            "Batch 30662 Loss: 0.49130523204803467\n",
            "Epoch 3, Processing batch 30663/30798\n",
            "Batch 30663 Loss: 0.00833219289779663\n",
            "Epoch 3, Processing batch 30664/30798\n",
            "Batch 30664 Loss: 2.929485559463501\n",
            "Epoch 3, Processing batch 30665/30798\n",
            "Batch 30665 Loss: 0.09348263591527939\n",
            "Epoch 3, Processing batch 30666/30798\n",
            "Batch 30666 Loss: 0.986240804195404\n",
            "Epoch 3, Processing batch 30667/30798\n",
            "Batch 30667 Loss: 0.13235163688659668\n",
            "Epoch 3, Processing batch 30668/30798\n",
            "Batch 30668 Loss: 0.8203495740890503\n",
            "Epoch 3, Processing batch 30669/30798\n",
            "Batch 30669 Loss: 1.542452096939087\n",
            "Epoch 3, Processing batch 30670/30798\n",
            "Batch 30670 Loss: 0.0013045917730778456\n",
            "Epoch 3, Processing batch 30671/30798\n",
            "Batch 30671 Loss: 1.0587608814239502\n",
            "Epoch 3, Processing batch 30672/30798\n",
            "Batch 30672 Loss: 1.0063529014587402\n",
            "Epoch 3, Processing batch 30673/30798\n",
            "Batch 30673 Loss: 0.9912741184234619\n",
            "Epoch 3, Processing batch 30674/30798\n",
            "Batch 30674 Loss: 2.4342329502105713\n",
            "Epoch 3, Processing batch 30675/30798\n",
            "Batch 30675 Loss: 0.7341393232345581\n",
            "Epoch 3, Processing batch 30676/30798\n",
            "Batch 30676 Loss: 0.06842537224292755\n",
            "Epoch 3, Processing batch 30677/30798\n",
            "Batch 30677 Loss: 2.4646034240722656\n",
            "Epoch 3, Processing batch 30678/30798\n",
            "Batch 30678 Loss: 0.018043138086795807\n",
            "Epoch 3, Processing batch 30679/30798\n",
            "Batch 30679 Loss: 0.4475160241127014\n",
            "Epoch 3, Processing batch 30680/30798\n",
            "Batch 30680 Loss: 0.022967476397752762\n",
            "Epoch 3, Processing batch 30681/30798\n",
            "Batch 30681 Loss: 0.00901356153190136\n",
            "Epoch 3, Processing batch 30682/30798\n",
            "Batch 30682 Loss: 0.033599935472011566\n",
            "Epoch 3, Processing batch 30683/30798\n",
            "Batch 30683 Loss: 0.29322248697280884\n",
            "Epoch 3, Processing batch 30684/30798\n",
            "Batch 30684 Loss: 0.1430584341287613\n",
            "Epoch 3, Processing batch 30685/30798\n",
            "Batch 30685 Loss: 0.02179882302880287\n",
            "Epoch 3, Processing batch 30686/30798\n",
            "Batch 30686 Loss: 0.0118265924975276\n",
            "Epoch 3, Processing batch 30687/30798\n",
            "Batch 30687 Loss: 2.6188929080963135\n",
            "Epoch 3, Processing batch 30688/30798\n",
            "Batch 30688 Loss: 0.00576720992103219\n",
            "Epoch 3, Processing batch 30689/30798\n",
            "Batch 30689 Loss: 0.002648070454597473\n",
            "Epoch 3, Processing batch 30690/30798\n",
            "Batch 30690 Loss: 0.13819371163845062\n",
            "Epoch 3, Processing batch 30691/30798\n",
            "Batch 30691 Loss: 0.3035205006599426\n",
            "Epoch 3, Processing batch 30692/30798\n",
            "Batch 30692 Loss: 0.1034863218665123\n",
            "Epoch 3, Processing batch 30693/30798\n",
            "Batch 30693 Loss: 1.405998945236206\n",
            "Epoch 3, Processing batch 30694/30798\n",
            "Batch 30694 Loss: 0.021349899470806122\n",
            "Epoch 3, Processing batch 30695/30798\n",
            "Batch 30695 Loss: 1.4558169841766357\n",
            "Epoch 3, Processing batch 30696/30798\n",
            "Batch 30696 Loss: 0.8114227056503296\n",
            "Epoch 3, Processing batch 30697/30798\n",
            "Batch 30697 Loss: 0.9093111157417297\n",
            "Epoch 3, Processing batch 30698/30798\n",
            "Batch 30698 Loss: 0.007349531166255474\n",
            "Epoch 3, Processing batch 30699/30798\n",
            "Batch 30699 Loss: 0.10957933962345123\n",
            "Epoch 3, Processing batch 30700/30798\n",
            "Batch 30700 Loss: 0.13109049201011658\n",
            "Epoch 3, Processing batch 30701/30798\n",
            "Batch 30701 Loss: 0.32642364501953125\n",
            "Epoch 3, Processing batch 30702/30798\n",
            "Batch 30702 Loss: 0.15944600105285645\n",
            "Epoch 3, Processing batch 30703/30798\n",
            "Batch 30703 Loss: 0.573421061038971\n",
            "Epoch 3, Processing batch 30704/30798\n",
            "Batch 30704 Loss: 0.1451588124036789\n",
            "Epoch 3, Processing batch 30705/30798\n",
            "Batch 30705 Loss: 0.08561781048774719\n",
            "Epoch 3, Processing batch 30706/30798\n",
            "Batch 30706 Loss: 0.09415850043296814\n",
            "Epoch 3, Processing batch 30707/30798\n",
            "Batch 30707 Loss: 0.008440009318292141\n",
            "Epoch 3, Processing batch 30708/30798\n",
            "Batch 30708 Loss: 0.19587016105651855\n",
            "Epoch 3, Processing batch 30709/30798\n",
            "Batch 30709 Loss: 0.05569007247686386\n",
            "Epoch 3, Processing batch 30710/30798\n",
            "Batch 30710 Loss: 0.05218992382287979\n",
            "Epoch 3, Processing batch 30711/30798\n",
            "Batch 30711 Loss: 1.172046184539795\n",
            "Epoch 3, Processing batch 30712/30798\n",
            "Batch 30712 Loss: 0.09380441159009933\n",
            "Epoch 3, Processing batch 30713/30798\n",
            "Batch 30713 Loss: 0.1908959299325943\n",
            "Epoch 3, Processing batch 30714/30798\n",
            "Batch 30714 Loss: 0.06982588768005371\n",
            "Epoch 3, Processing batch 30715/30798\n",
            "Batch 30715 Loss: 2.187304973602295\n",
            "Epoch 3, Processing batch 30716/30798\n",
            "Batch 30716 Loss: 0.023189907893538475\n",
            "Epoch 3, Processing batch 30717/30798\n",
            "Batch 30717 Loss: 0.2605351209640503\n",
            "Epoch 3, Processing batch 30718/30798\n",
            "Batch 30718 Loss: 0.054756056517362595\n",
            "Epoch 3, Processing batch 30719/30798\n",
            "Batch 30719 Loss: 0.7274546027183533\n",
            "Epoch 3, Processing batch 30720/30798\n",
            "Batch 30720 Loss: 0.41196882724761963\n",
            "Epoch 3, Processing batch 30721/30798\n",
            "Batch 30721 Loss: 0.015228671953082085\n",
            "Epoch 3, Processing batch 30722/30798\n",
            "Batch 30722 Loss: 0.06094346195459366\n",
            "Epoch 3, Processing batch 30723/30798\n",
            "Batch 30723 Loss: 0.04018421471118927\n",
            "Epoch 3, Processing batch 30724/30798\n",
            "Batch 30724 Loss: 0.8446714878082275\n",
            "Epoch 3, Processing batch 30725/30798\n",
            "Batch 30725 Loss: 0.037193261086940765\n",
            "Epoch 3, Processing batch 30726/30798\n",
            "Batch 30726 Loss: 0.1654852032661438\n",
            "Epoch 3, Processing batch 30727/30798\n",
            "Batch 30727 Loss: 0.972995400428772\n",
            "Epoch 3, Processing batch 30728/30798\n",
            "Batch 30728 Loss: 0.026524968445301056\n",
            "Epoch 3, Processing batch 30729/30798\n",
            "Batch 30729 Loss: 0.20823243260383606\n",
            "Epoch 3, Processing batch 30730/30798\n",
            "Batch 30730 Loss: 0.041282687336206436\n",
            "Epoch 3, Processing batch 30731/30798\n",
            "Batch 30731 Loss: 0.03873734921216965\n",
            "Epoch 3, Processing batch 30732/30798\n",
            "Batch 30732 Loss: 0.024087388068437576\n",
            "Epoch 3, Processing batch 30733/30798\n",
            "Batch 30733 Loss: 0.1473814994096756\n",
            "Epoch 3, Processing batch 30734/30798\n",
            "Batch 30734 Loss: 0.8087648153305054\n",
            "Epoch 3, Processing batch 30735/30798\n",
            "Batch 30735 Loss: 0.13567431271076202\n",
            "Epoch 3, Processing batch 30736/30798\n",
            "Batch 30736 Loss: 0.09974241256713867\n",
            "Epoch 3, Processing batch 30737/30798\n",
            "Batch 30737 Loss: 1.166796326637268\n",
            "Epoch 3, Processing batch 30738/30798\n",
            "Batch 30738 Loss: 0.05526692047715187\n",
            "Epoch 3, Processing batch 30739/30798\n",
            "Batch 30739 Loss: 0.028550323098897934\n",
            "Epoch 3, Processing batch 30740/30798\n",
            "Batch 30740 Loss: 0.40596696734428406\n",
            "Epoch 3, Processing batch 30741/30798\n",
            "Batch 30741 Loss: 0.09038957953453064\n",
            "Epoch 3, Processing batch 30742/30798\n",
            "Batch 30742 Loss: 0.27504467964172363\n",
            "Epoch 3, Processing batch 30743/30798\n",
            "Batch 30743 Loss: 0.12400492280721664\n",
            "Epoch 3, Processing batch 30744/30798\n",
            "Batch 30744 Loss: 0.14531922340393066\n",
            "Epoch 3, Processing batch 30745/30798\n",
            "Batch 30745 Loss: 0.03304930776357651\n",
            "Epoch 3, Processing batch 30746/30798\n",
            "Batch 30746 Loss: 0.5482650995254517\n",
            "Epoch 3, Processing batch 30747/30798\n",
            "Batch 30747 Loss: 1.2013152837753296\n",
            "Epoch 3, Processing batch 30748/30798\n",
            "Batch 30748 Loss: 0.02304604835808277\n",
            "Epoch 3, Processing batch 30749/30798\n",
            "Batch 30749 Loss: 0.1608189195394516\n",
            "Epoch 3, Processing batch 30750/30798\n",
            "Batch 30750 Loss: 0.6010530591011047\n",
            "Epoch 3, Processing batch 30751/30798\n",
            "Batch 30751 Loss: 0.027399815618991852\n",
            "Epoch 3, Processing batch 30752/30798\n",
            "Batch 30752 Loss: 0.05189640820026398\n",
            "Epoch 3, Processing batch 30753/30798\n",
            "Batch 30753 Loss: 0.03996773436665535\n",
            "Epoch 3, Processing batch 30754/30798\n",
            "Batch 30754 Loss: 0.040020864456892014\n",
            "Epoch 3, Processing batch 30755/30798\n",
            "Batch 30755 Loss: 0.1398259401321411\n",
            "Epoch 3, Processing batch 30756/30798\n",
            "Batch 30756 Loss: 0.23696202039718628\n",
            "Epoch 3, Processing batch 30757/30798\n",
            "Batch 30757 Loss: 0.017395133152604103\n",
            "Epoch 3, Processing batch 30758/30798\n",
            "Batch 30758 Loss: 0.012192590162158012\n",
            "Epoch 3, Processing batch 30759/30798\n",
            "Batch 30759 Loss: 0.08885780721902847\n",
            "Epoch 3, Processing batch 30760/30798\n",
            "Batch 30760 Loss: 0.0033613364212214947\n",
            "Epoch 3, Processing batch 30761/30798\n",
            "Batch 30761 Loss: 0.0846809446811676\n",
            "Epoch 3, Processing batch 30762/30798\n",
            "Batch 30762 Loss: 0.014408441260457039\n",
            "Epoch 3, Processing batch 30763/30798\n",
            "Batch 30763 Loss: 0.0034868104849010706\n",
            "Epoch 3, Processing batch 30764/30798\n",
            "Batch 30764 Loss: 0.41696634888648987\n",
            "Epoch 3, Processing batch 30765/30798\n",
            "Batch 30765 Loss: 0.3289443850517273\n",
            "Epoch 3, Processing batch 30766/30798\n",
            "Batch 30766 Loss: 0.18786591291427612\n",
            "Epoch 3, Processing batch 30767/30798\n",
            "Batch 30767 Loss: 0.6774464845657349\n",
            "Epoch 3, Processing batch 30768/30798\n",
            "Batch 30768 Loss: 0.04831767454743385\n",
            "Epoch 3, Processing batch 30769/30798\n",
            "Batch 30769 Loss: 0.1587364375591278\n",
            "Epoch 3, Processing batch 30770/30798\n",
            "Batch 30770 Loss: 0.11420579999685287\n",
            "Epoch 3, Processing batch 30771/30798\n",
            "Batch 30771 Loss: 0.15239089727401733\n",
            "Epoch 3, Processing batch 30772/30798\n",
            "Batch 30772 Loss: 0.053309693932533264\n",
            "Epoch 3, Processing batch 30773/30798\n",
            "Batch 30773 Loss: 0.22362768650054932\n",
            "Epoch 3, Processing batch 30774/30798\n",
            "Batch 30774 Loss: 0.19229985773563385\n",
            "Epoch 3, Processing batch 30775/30798\n",
            "Batch 30775 Loss: 0.6078937649726868\n",
            "Epoch 3, Processing batch 30776/30798\n",
            "Batch 30776 Loss: 0.02572392113506794\n",
            "Epoch 3, Processing batch 30777/30798\n",
            "Batch 30777 Loss: 1.0153658390045166\n",
            "Epoch 3, Processing batch 30778/30798\n",
            "Batch 30778 Loss: 0.3364659547805786\n",
            "Epoch 3, Processing batch 30779/30798\n",
            "Batch 30779 Loss: 0.21481572091579437\n",
            "Epoch 3, Processing batch 30780/30798\n",
            "Batch 30780 Loss: 0.07030139118432999\n",
            "Epoch 3, Processing batch 30781/30798\n",
            "Batch 30781 Loss: 0.5973571538925171\n",
            "Epoch 3, Processing batch 30782/30798\n",
            "Batch 30782 Loss: 0.1526055932044983\n",
            "Epoch 3, Processing batch 30783/30798\n",
            "Batch 30783 Loss: 0.09088388830423355\n",
            "Epoch 3, Processing batch 30784/30798\n",
            "Batch 30784 Loss: 0.012428762391209602\n",
            "Epoch 3, Processing batch 30785/30798\n",
            "Batch 30785 Loss: 0.8347916007041931\n",
            "Epoch 3, Processing batch 30786/30798\n",
            "Batch 30786 Loss: 0.013491146266460419\n",
            "Epoch 3, Processing batch 30787/30798\n",
            "Batch 30787 Loss: 0.12101311981678009\n",
            "Epoch 3, Processing batch 30788/30798\n",
            "Batch 30788 Loss: 0.15993501245975494\n",
            "Epoch 3, Processing batch 30789/30798\n",
            "Batch 30789 Loss: 1.902651309967041\n",
            "Epoch 3, Processing batch 30790/30798\n",
            "Batch 30790 Loss: 0.006353492848575115\n",
            "Epoch 3, Processing batch 30791/30798\n",
            "Batch 30791 Loss: 0.009759553708136082\n",
            "Epoch 3, Processing batch 30792/30798\n",
            "Batch 30792 Loss: 0.1104658842086792\n",
            "Epoch 3, Processing batch 30793/30798\n",
            "Batch 30793 Loss: 0.01738739386200905\n",
            "Epoch 3, Processing batch 30794/30798\n",
            "Batch 30794 Loss: 0.08568492531776428\n",
            "Epoch 3, Processing batch 30795/30798\n",
            "Batch 30795 Loss: 0.21690815687179565\n",
            "Epoch 3, Processing batch 30796/30798\n",
            "Batch 30796 Loss: 0.42033928632736206\n",
            "Epoch 3, Processing batch 30797/30798\n",
            "Batch 30797 Loss: 0.5274982452392578\n",
            "Epoch 3, Processing batch 30798/30798\n",
            "Batch 30798 Loss: 0.045567598193883896\n",
            "Epoch 3 Loss: 0.36722784841181794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the final model and tokenizer\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/MLBD_Project/multi_task_distilbert_final.pth')\n",
        "tokenizer.save_pretrained('/content/drive/MyDrive/MLBD_Project/tokenizer_final')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBzV5qwyOn1o",
        "outputId": "1b59c6aa-6e63-455d-aca6-bfdaede97ac2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/MLBD_Project/tokenizer_final/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/MLBD_Project/tokenizer_final/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/MLBD_Project/tokenizer_final/vocab.txt',\n",
              " '/content/drive/MyDrive/MLBD_Project/tokenizer_final/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference function with confidence scores\n",
        "def predict_with_confidence(model, tokenizer, text, tasks, device):\n",
        "    model.eval()\n",
        "    inputs = tokenizer(text, return_tensors='pt', max_length=128, padding='max_length', truncation=True)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    predictions = {}\n",
        "    confidences = {}\n",
        "    for task, output in outputs.items():\n",
        "        if tasks[task]['type'] == 'binary':\n",
        "            prob = torch.sigmoid(output).item()\n",
        "            predictions[task] = int(prob > 0.5)\n",
        "            confidences[task] = prob if predictions[task] == 1 else 1 - prob\n",
        "        elif tasks[task]['type'] == 'multi-class':\n",
        "            probs = torch.softmax(output, dim=1)\n",
        "            class_idx = torch.argmax(probs, dim=1).item()\n",
        "            predictions[task] = tasks[task]['classes'][class_idx]\n",
        "            confidences[task] = probs[0, class_idx].item()\n",
        "        elif tasks[task]['type'] == 'multi-label':\n",
        "            probs = torch.sigmoid(output)\n",
        "            preds = (probs > 0.5).int().tolist()[0]\n",
        "            predictions[task] = {col: pred for col, pred in zip(tasks[task]['columns'], preds)}\n",
        "            confidences[task] = {col: prob.item() if pred == 1 else 1 - prob.item() for col, pred, prob in zip(tasks[task]['columns'], preds, probs[0])}\n",
        "    return predictions, confidences\n"
      ],
      "metadata": {
        "id": "xu9eAkrSOrXZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model and tokenizer for inference\n",
        "def load_model_and_predict(model_path, tokenizer_path, text, tasks, device):\n",
        "    distilbert_model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "    model = MultiTaskDistilBERT(distilbert_model, tasks)\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    tokenizer = DistilBertTokenizer.from_pretrained(tokenizer_path)\n",
        "    return predict_with_confidence(model, tokenizer, text, tasks, device)"
      ],
      "metadata": {
        "id": "62OZfwumOv3W"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_texts = [\n",
        "        \"This video is amazing! I loved every minute of it.\",\n",
        "        \"Check out my channel for free iPhone giveaway! Click the link now!\",\n",
        "        \"You are so stupid and ugly, nobody likes you.\",\n",
        "        \"I respectfully disagree with your opinion on this matter.\"\n",
        "    ]"
      ],
      "metadata": {
        "id": "LhA2pNsJ2LNP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for text in sample_texts:\n",
        "    predictions, confidences = predict_with_confidence(model, tokenizer, text, tasks, device)\n",
        "    print(f\"Text: {text}\")\n",
        "    print(\"Predictions:\", predictions)\n",
        "    print(\"Confidences:\", confidences)\n",
        "    print(\"-\" * 20)  # Separator for clarity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSWhiWdW22Tf",
        "outputId": "5c43ac2e-cb20-479b-de56-bfc31afaf2fa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: This video is amazing! I loved every minute of it.\n",
            "Predictions: {'spam': 0, 'sentiment': 'Positive', 'toxicity': {'toxic': 0, 'severe_toxic': 0, 'obscene': 0, 'threat': 0, 'insult': 0, 'identity_hate': 0}, 'hate_speech': 'normal'}\n",
            "Confidences: {'spam': 0.9995343281771056, 'sentiment': 0.5267459154129028, 'toxicity': {'toxic': 0.9986151882912964, 'severe_toxic': 0.9998073807946639, 'obscene': 0.9994457864086144, 'threat': 0.9998818508465774, 'insult': 0.9996507137548178, 'identity_hate': 0.9998153176129563}, 'hate_speech': 0.9656565189361572}\n",
            "--------------------\n",
            "Text: Check out my channel for free iPhone giveaway! Click the link now!\n",
            "Predictions: {'spam': 1, 'sentiment': 'Irrelevant', 'toxicity': {'toxic': 0, 'severe_toxic': 0, 'obscene': 0, 'threat': 0, 'insult': 0, 'identity_hate': 0}, 'hate_speech': 'normal'}\n",
            "Confidences: {'spam': 0.9995025396347046, 'sentiment': 0.9373131990432739, 'toxicity': {'toxic': 0.9962404500693083, 'severe_toxic': 0.9849546300247312, 'obscene': 0.9940718002617359, 'threat': 0.9843379464000463, 'insult': 0.9946929980069399, 'identity_hate': 0.9862555339932442}, 'hate_speech': 0.6647014021873474}\n",
            "--------------------\n",
            "Text: You are so stupid and ugly, nobody likes you.\n",
            "Predictions: {'spam': 0, 'sentiment': 'Irrelevant', 'toxicity': {'toxic': 1, 'severe_toxic': 0, 'obscene': 0, 'threat': 0, 'insult': 1, 'identity_hate': 0}, 'hate_speech': 'offensive'}\n",
            "Confidences: {'spam': 0.9997211721492931, 'sentiment': 0.9709267616271973, 'toxicity': {'toxic': 0.9556857347488403, 'severe_toxic': 0.953732080757618, 'obscene': 0.5171190500259399, 'threat': 0.9837568160146475, 'insult': 0.7843158841133118, 'identity_hate': 0.9309996217489243}, 'hate_speech': 0.7097065448760986}\n",
            "--------------------\n",
            "Text: I respectfully disagree with your opinion on this matter.\n",
            "Predictions: {'spam': 0, 'sentiment': 'Negative', 'toxicity': {'toxic': 0, 'severe_toxic': 0, 'obscene': 0, 'threat': 0, 'insult': 0, 'identity_hate': 0}, 'hate_speech': 'normal'}\n",
            "Confidences: {'spam': 0.9999939245049063, 'sentiment': 0.4674355685710907, 'toxicity': {'toxic': 0.9997297131340019, 'severe_toxic': 0.99999196011413, 'obscene': 0.9999491363669222, 'threat': 0.9999890035041972, 'insult': 0.9999580192561552, 'identity_hate': 0.9999780608668516}, 'hate_speech': 0.9767888784408569}\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yVE8a3xo3De4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}